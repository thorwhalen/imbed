{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll prepare and analyze ai prompt data.\n",
    "\n",
    "We'll be taking data from the following sources:\n",
    "\n",
    "[LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset](https://huggingface.co/papers/2309.11998)\n",
    "\n",
    "[prompt-injections](https://huggingface.co/datasets/deepset/prompt-injections)\n",
    "\n",
    "[awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts/blob/main/prompts.csv) (just 169 of them)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lmsys/lmsys-chat-1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset('lmsys/lmsys-chat-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation_id', 'model', 'conversation', 'turn', 'language', 'openai_moderation', 'redacted'],\n",
       "        num_rows: 1000000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_id': '33f01939a744455c869cb234afca47f1',\n",
       " 'model': 'wizardlm-13b',\n",
       " 'conversation': [{'content': 'how can identity protection services help protect me against identity theft',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Identity protection services can help protect you against identity theft in several ways:\\n\\n1. Monitoring: Many identity protection services monitor your credit reports, public records, and other sources for signs of identity theft. If they detect any suspicious activity, they will alert you so you can take action.\\n2. Credit freeze: Some identity protection services can help you freeze your credit, which makes it more difficult for thieves to open new accounts in your name.\\n3. Identity theft insurance: Some identity protection services offer insurance that can help you recover financially if you become a victim of identity theft.\\n4. Assistance: Many identity protection services offer assistance if you become a victim of identity theft. They can help you file a police report, contact credit bureaus, and other steps to help you restore your identity.\\n\\nOverall, identity protection services can provide you with peace of mind and help you take proactive steps to protect your identity. However, it's important to note that no service can completely guarantee that you will never become a victim of identity theft. It's still important to take steps to protect your own identity, such as being cautious with personal information and regularly monitoring your credit reports.\",\n",
       "   'role': 'assistant'}],\n",
       " 'turn': 1,\n",
       " 'language': 'English',\n",
       " 'openai_moderation': [{'categories': {'harassment': False,\n",
       "    'harassment/threatening': False,\n",
       "    'hate': False,\n",
       "    'hate/threatening': False,\n",
       "    'self-harm': False,\n",
       "    'self-harm/instructions': False,\n",
       "    'self-harm/intent': False,\n",
       "    'sexual': False,\n",
       "    'sexual/minors': False,\n",
       "    'violence': False,\n",
       "    'violence/graphic': False},\n",
       "   'category_scores': {'harassment': 9.212334e-07,\n",
       "    'harassment/threatening': 3.6271535e-07,\n",
       "    'hate': 8.254962e-07,\n",
       "    'hate/threatening': 1.331843e-08,\n",
       "    'self-harm': 1.9257865e-07,\n",
       "    'self-harm/instructions': 6.5028324e-08,\n",
       "    'self-harm/intent': 2.7525962e-07,\n",
       "    'sexual': 2.564017e-06,\n",
       "    'sexual/minors': 4.523274e-07,\n",
       "    'violence': 2.2942773e-05,\n",
       "    'violence/graphic': 1.9713439e-06},\n",
       "   'flagged': False},\n",
       "  {'categories': {'harassment': False,\n",
       "    'harassment/threatening': False,\n",
       "    'hate': False,\n",
       "    'hate/threatening': False,\n",
       "    'self-harm': False,\n",
       "    'self-harm/instructions': False,\n",
       "    'self-harm/intent': False,\n",
       "    'sexual': False,\n",
       "    'sexual/minors': False,\n",
       "    'violence': False,\n",
       "    'violence/graphic': False},\n",
       "   'category_scores': {'harassment': 1.5205982e-06,\n",
       "    'harassment/threatening': 1.27367e-07,\n",
       "    'hate': 1.4930811e-07,\n",
       "    'hate/threatening': 2.457626e-09,\n",
       "    'self-harm': 3.2069583e-08,\n",
       "    'self-harm/instructions': 2.7247233e-07,\n",
       "    'self-harm/intent': 2.2881606e-07,\n",
       "    'sexual': 3.3542372e-05,\n",
       "    'sexual/minors': 8.75301e-07,\n",
       "    'violence': 0.00010941078,\n",
       "    'violence/graphic': 6.069021e-06},\n",
       "   'flagged': False}],\n",
       " 'redacted': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(d)) == d[0]\n",
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33f01939a744455c869cb234afca47f1</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>[{'content': 'how can identity protection serv...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1e230e55efea4edab95db9cb87f6a9cb</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Beside OFAC's selective sanction...</td>\n",
       "      <td>6</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f623736051f4a48a506fd5933563cfd</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'You are the text completion mode...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5c923a7fa3f4893beb432b4a06ef222</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>[{'content': 'The sum of the perimeters of thr...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ad66650dced4b728de1d14bb04657c1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'What is the type of the variable...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>756a592c70864f5da4327c82d1998155</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Métodos de treinamento de funçõe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>42458cc230c34c02ad2fede8190434d5</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'hello', 'role': 'user'}, {'conte...</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>f3e0b1837dd74305bec5eac0d78d0ec7</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': '### Instruction: Extract causal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>4dbf614bd1d949348236f3dcbe42fd6f</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Buongiorno ', 'role': 'user'}, {...</td>\n",
       "      <td>2</td>\n",
       "      <td>Italian</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>24a805330e9f419fabcc861ffeb65973</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'can you help me format the follo...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id           model  \\\n",
       "0       33f01939a744455c869cb234afca47f1    wizardlm-13b   \n",
       "1       1e230e55efea4edab95db9cb87f6a9cb      vicuna-13b   \n",
       "2       0f623736051f4a48a506fd5933563cfd      vicuna-13b   \n",
       "3       e5c923a7fa3f4893beb432b4a06ef222          palm-2   \n",
       "4       8ad66650dced4b728de1d14bb04657c1      vicuna-13b   \n",
       "...                                  ...             ...   \n",
       "999995  756a592c70864f5da4327c82d1998155      vicuna-13b   \n",
       "999996  42458cc230c34c02ad2fede8190434d5      vicuna-13b   \n",
       "999997  f3e0b1837dd74305bec5eac0d78d0ec7      vicuna-13b   \n",
       "999998  4dbf614bd1d949348236f3dcbe42fd6f      vicuna-13b   \n",
       "999999  24a805330e9f419fabcc861ffeb65973  fastchat-t5-3b   \n",
       "\n",
       "                                             conversation  turn    language  \\\n",
       "0       [{'content': 'how can identity protection serv...     1     English   \n",
       "1       [{'content': 'Beside OFAC's selective sanction...     6     English   \n",
       "2       [{'content': 'You are the text completion mode...     1     English   \n",
       "3       [{'content': 'The sum of the perimeters of thr...     2     English   \n",
       "4       [{'content': 'What is the type of the variable...     1     English   \n",
       "...                                                   ...   ...         ...   \n",
       "999995  [{'content': 'Métodos de treinamento de funçõe...     1  Portuguese   \n",
       "999996  [{'content': 'hello', 'role': 'user'}, {'conte...     3     English   \n",
       "999997  [{'content': '### Instruction: Extract causal ...     1     English   \n",
       "999998  [{'content': 'Buongiorno ', 'role': 'user'}, {...     2     Italian   \n",
       "999999  [{'content': 'can you help me format the follo...     1     English   \n",
       "\n",
       "                                        openai_moderation  redacted  \n",
       "0       [{'categories': {'harassment': False, 'harassm...     False  \n",
       "1       [{'categories': {'harassment': False, 'harassm...     False  \n",
       "2       [{'categories': {'harassment': False, 'harassm...     False  \n",
       "3       [{'categories': {'harassment': False, 'harassm...     False  \n",
       "4       [{'categories': {'harassment': False, 'harassm...     False  \n",
       "...                                                   ...       ...  \n",
       "999995  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "999996  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "999997  [{'categories': {'harassment': False, 'harassm...      True  \n",
       "999998  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "999999  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "\n",
       "[1000000 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777453, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df = df[df['language'] == 'English']\n",
    "en_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266260, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redacted_df = en_df[en_df.redacted == True]\n",
    "redacted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id                       e3addcd33c9d42b2be07c4bbbf9ce92e\n",
       "model                                                 llama-2-13b-chat\n",
       "conversation         [{'content': 'how many floors does the burj al...\n",
       "turn                                                                 6\n",
       "language                                                       English\n",
       "openai_moderation    [{'categories': {'harassment': False, 'harassm...\n",
       "redacted                                                          True\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 1\n",
    "item = redacted_df.iloc[idx]\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'content': 'how many floors does the burj al arab have', 'role': 'user'},\n",
       "       {'content': \"Hello! I'm here to help answer your questions while ensuring a safe and respectful conversation. To the best of my knowledge, the Burj Al Arab has 154 floors. However, I would like to clarify that providing exact information on building floor counts can be challenging due to various reasons such as changes in construction, renovations, or inconsistent sources. If you have any further questions or concerns, please feel free to ask, and I'll do my best to assist you with accurate and helpful information.\", 'role': 'assistant'},\n",
       "       {'content': 'doesnt it have 56 floors and 202 rooms', 'role': 'user'},\n",
       "       {'content': \"Thank you for bringing that to my attention! You are correct, the Burj Al Arab has 56 floors and 202 rooms. I apologize for any confusion my previous response may have caused. It's important to ensure the accuracy of the information we provide, and I appreciate your help in doing so. Thank you for your question!\", 'role': 'assistant'},\n",
       "       {'content': 'so if i ask you now how many rooms and how many floors', 'role': 'user'},\n",
       "       {'content': 'Sure! To answer your questions:\\n\\n* The Burj Al Arab has 202 rooms.\\n* The Burj Al Arab has 56 floors.', 'role': 'assistant'},\n",
       "       {'content': 'if i ask in ten minutes will you still remember', 'role': 'user'},\n",
       "       {'content': \"I'm a large language model, I don't have a memory in the classical sense, so I may not be able to remember information from previous questions after a certain amount of time has passed. However, I can still try my best to provide accurate information based on my training data.\\n\\nIf you ask me a question about the Burj Al Arab in ten minutes, I will do my best to provide the same information as I would now, which is:\\n\\n* The Burj Al Arab has 202 rooms.\\n* The Burj Al Arab has 56 floors.\\n\\nPlease keep in mind that my ability to remember information may be limited by the time that has passed since the previous question, and my responses may not be as accurate or detailed as those provided earlier.\", 'role': 'assistant'},\n",
       "       {'content': 'can you describe the delux NAME_1', 'role': 'user'},\n",
       "       {'content': \"Sure, I can provide a description of the Delux NAME_1 at the Burj Al Arab!\\n\\nThe Delux NAME_1 is one of the most luxurious and spacious accommodations offered at the iconic Burj Al Arab hotel in Dubai. Located on the upper floors of the hotel, this suite offers breathtaking views of the Arabian Gulf and the Dubai skyline.\\n\\nThe Delux NAME_1 features a large living room, a formal dining area, a gourmet kitchen, and a spacious bedroom with a large bathroom. The suite is tastefully decorated with elegant furnishings, rich fabrics, and luxurious finishes.\\n\\nSome of the amenities and features of the Delux NAME_1 include:\\n\\n* A spacious living room with a comfortable seating area, a large flat-screen TV, and floor-to-ceiling windows that offer stunning views of the city skyline\\n* A formal dining area with a beautifully set table for eight guests, perfect for hosting special occasions or business meetings\\n* A gourmet kitchen with high-end appliances, ample counter space, and a breakfast bar\\n* A spacious bedroom with a king-size bed, a large flat-screen TV, and a luxurious bathroom with a deep-soaking tub, a walk-in shower, and double sinks\\n* A private balcony with outdoor seating and breathtaking views of the Arabian Gulf\\n* A personal butler service to ensure that your every need is met during your stay\\n* Access to the hotel's exclusive amenities, including the private beach, the spa, and the fitness center\\n\\nOverall, the Delux NAME_1 at the Burj Al Arab is an opulent and spacious accommodation that offers the ultimate in luxury and comfort. It is the perfect choice for discerning travelers who desire the finest amenities and unparalleled service during their stay in Dubai.\", 'role': 'assistant'},\n",
       "       {'content': 'can you describe the balcony in detail and bedroom in lots of detail', 'role': 'user'},\n",
       "       {'content': 'Certainly! Here are detailed descriptions of the balcony and bedroom in the Delux NAME_1 at the Burj Al Arab:\\n\\nBalcony:\\n\\n* The balcony is a spacious outdoor area that provides stunning views of the Arabian Gulf and the Dubai skyline.\\n* The balcony is furnished with comfortable seating, including a sofa, armchairs, and a coffee table.\\n* The balcony is also equipped with a dining table and chairs, perfect for enjoying breakfast or a romantic dinner under the stars.\\n* The balcony is surrounded by a beautiful balustrade, providing privacy and unobstructed views of the surrounding area.\\n* The balcony is illuminated by soft, warm lighting, creating a magical ambiance in the evening.\\n\\nBedroom:\\n\\n* The bedroom is a spacious and luxurious space that is designed to provide the ultimate in comfort and relaxation.\\n* The bedroom is furnished with a beautifully designed king-size bed, adorned with luxurious bedding and pillows.\\n* The bedroom is equipped with a large flat-screen TV, providing entertainment and relaxation options.\\n* The bedroom also features a comfortable seating area, perfect for reading or enjoying a drink before bed.\\n* The bedroom is illuminated by soft, warm lighting, creating a cozy and inviting ambiance.\\n* The bedroom is also equipped with a personal safe, providing a secure place to store your valuables.\\n\\nBathroom:\\n\\n* The bathroom is a spacious and luxurious space that is designed to provide the ultimate in comfort and relaxation.\\n* The bathroom features a deep-soaking tub, perfect for unwinding after a long day of exploring Dubai.\\n* The bathroom also features a walk-in shower, equipped with a rainfall showerhead and a handheld showerhead.\\n* The bathroom is adorned with beautiful marble and granite finishes, adding to the luxurious ambiance.\\n* The bathroom is also equipped with double sinks, providing ample space for getting ready in the morning.\\n* The bathroom is illuminated by', 'role': 'assistant'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = item.conversation\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many floors does the burj al arab have\n"
     ]
    }
   ],
   "source": [
    "print(t[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 6.587166e-06, 'harassment/threatening': 1.0686675e-06, 'hate': 3.4843295e-05, 'hate/threatening': 1.5625018e-06, 'self-harm': 4.3865374e-08, 'self-harm/instructions': 1.424871e-07, 'self-harm/intent': 3.9984065e-09, 'sexual': 4.001021e-06, 'sexual/minors': 9.46124e-08, 'violence': 4.016162e-05, 'violence/graphic': 2.5418642e-06}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 8.359951e-07, 'harassment/threatening': 6.2792076e-08, 'hate': 2.4000903e-07, 'hate/threatening': 3.0021885e-09, 'self-harm': 1.5459794e-07, 'self-harm/instructions': 7.689732e-07, 'self-harm/intent': 5.123899e-07, 'sexual': 6.4560125e-05, 'sexual/minors': 1.9663212e-06, 'violence': 1.3412247e-05, 'violence/graphic': 3.7306785e-07}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 7.5664884e-06, 'harassment/threatening': 3.9536732e-07, 'hate': 2.8686604e-06, 'hate/threatening': 4.388527e-09, 'self-harm': 9.0108925e-09, 'self-harm/instructions': 1.9230807e-08, 'self-harm/intent': 9.118879e-10, 'sexual': 4.5971005e-06, 'sexual/minors': 4.83575e-08, 'violence': 3.4179295e-05, 'violence/graphic': 2.3320833e-06}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 2.8000684e-06, 'harassment/threatening': 2.7828442e-08, 'hate': 1.3466644e-06, 'hate/threatening': 6.041083e-09, 'self-harm': 1.08850395e-08, 'self-harm/instructions': 3.376992e-08, 'self-harm/intent': 4.0287906e-09, 'sexual': 0.00013263861, 'sexual/minors': 1.7253555e-07, 'violence': 0.000103147264, 'violence/graphic': 4.7872805e-07}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 6.4429014e-06, 'harassment/threatening': 2.0500938e-06, 'hate': 2.2934266e-06, 'hate/threatening': 2.631272e-07, 'self-harm': 5.030013e-09, 'self-harm/instructions': 9.076288e-08, 'self-harm/intent': 5.516501e-09, 'sexual': 1.42753315e-05, 'sexual/minors': 1.6383672e-07, 'violence': 6.716612e-05, 'violence/graphic': 1.0229597e-06}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 1.7064387e-07, 'harassment/threatening': 4.3674403e-10, 'hate': 4.2200574e-07, 'hate/threatening': 1.4962134e-10, 'self-harm': 7.918544e-09, 'self-harm/instructions': 8.132611e-08, 'self-harm/intent': 2.813363e-10, 'sexual': 1.0263926e-06, 'sexual/minors': 9.126418e-09, 'violence': 4.971877e-06, 'violence/graphic': 6.6902834e-07}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 1.9995174e-05, 'harassment/threatening': 4.1206436e-06, 'hate': 3.3436743e-07, 'hate/threatening': 1.1889074e-07, 'self-harm': 2.4175658e-06, 'self-harm/instructions': 9.503979e-08, 'self-harm/intent': 5.8082314e-06, 'sexual': 1.2372993e-05, 'sexual/minors': 2.9907858e-07, 'violence': 4.264885e-05, 'violence/graphic': 1.4416479e-06}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 1.678596e-06, 'harassment/threatening': 2.2538954e-08, 'hate': 1.2018697e-06, 'hate/threatening': 2.8569943e-08, 'self-harm': 9.507025e-08, 'self-harm/instructions': 3.5848682e-08, 'self-harm/intent': 1.4901833e-07, 'sexual': 4.0843483e-05, 'sexual/minors': 3.0551246e-07, 'violence': 2.6868875e-05, 'violence/graphic': 5.139916e-06}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 2.0898328e-06, 'harassment/threatening': 1.4917829e-07, 'hate': 5.950161e-06, 'hate/threatening': 5.4117862e-08, 'self-harm': 1.0747371e-09, 'self-harm/instructions': 3.100658e-08, 'self-harm/intent': 1.1327809e-08, 'sexual': 2.039854e-05, 'sexual/minors': 7.2361973e-07, 'violence': 4.5196822e-07, 'violence/graphic': 3.3307305e-07}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 3.6009456e-07, 'harassment/threatening': 1.8108485e-08, 'hate': 4.257591e-08, 'hate/threatening': 2.5166377e-08, 'self-harm': 4.1742304e-08, 'self-harm/instructions': 4.409377e-09, 'self-harm/intent': 2.611762e-09, 'sexual': 8.478604e-05, 'sexual/minors': 3.9383035e-08, 'violence': 2.7367543e-05, 'violence/graphic': 8.088066e-07}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 6.909264e-05, 'harassment/threatening': 3.0872718e-05, 'hate': 2.2612474e-05, 'hate/threatening': 2.3422105e-07, 'self-harm': 1.5243121e-07, 'self-harm/instructions': 8.057266e-08, 'self-harm/intent': 2.255287e-07, 'sexual': 1.2949885e-05, 'sexual/minors': 1.3908073e-05, 'violence': 0.0002017584, 'violence/graphic': 2.5977092e-06}, 'flagged': False},\n",
       "       {'categories': {'harassment': False, 'harassment/threatening': False, 'hate': False, 'hate/threatening': False, 'self-harm': False, 'self-harm/instructions': False, 'self-harm/intent': False, 'sexual': False, 'sexual/minors': False, 'violence': False, 'violence/graphic': False}, 'category_scores': {'harassment': 1.9616555e-06, 'harassment/threatening': 2.4400774e-07, 'hate': 1.7112366e-06, 'hate/threatening': 1.8826814e-06, 'self-harm': 4.995395e-07, 'self-harm/instructions': 4.2235542e-06, 'self-harm/intent': 2.3727637e-08, 'sexual': 0.00028297675, 'sexual/minors': 8.6720576e-07, 'violence': 0.0003933837, 'violence/graphic': 1.8958518e-06}, 'flagged': False}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['openai_moderation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I'm not understanding what redacted means, since I'm not seeing any True value in moderation categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "for t in chain.from_iterable(redacted_df.openai_moderation):\n",
    "    if any(t['categories'].values()):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': {'harassment': False,\n",
       "  'harassment/threatening': False,\n",
       "  'hate': False,\n",
       "  'hate/threatening': False,\n",
       "  'self-harm': False,\n",
       "  'self-harm/instructions': False,\n",
       "  'self-harm/intent': False,\n",
       "  'sexual': True,\n",
       "  'sexual/minors': False,\n",
       "  'violence': False,\n",
       "  'violence/graphic': False},\n",
       " 'category_scores': {'harassment': 0.0013585809,\n",
       "  'harassment/threatening': 4.9479375e-05,\n",
       "  'hate': 6.851206e-06,\n",
       "  'hate/threatening': 3.1813063e-06,\n",
       "  'self-harm': 0.00013223867,\n",
       "  'self-harm/instructions': 2.55278e-05,\n",
       "  'self-harm/intent': 8.220527e-05,\n",
       "  'sexual': 0.8748679,\n",
       "  'sexual/minors': 2.4269992e-05,\n",
       "  'violence': 0.028668432,\n",
       "  'violence/graphic': 1.6416767e-06},\n",
       " 'flagged': True}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out datasets and huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import list_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list_datasets(search='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(id='teven/prompted_examples', author='teven', sha='e7bc1a91071997b635c35156c27db40e0968428a', created_at=datetime.datetime(2022, 3, 2, 23, 29, 22, tzinfo=datetime.timezone.utc), last_modified=datetime.datetime(2021, 12, 6, 15, 54, 19, tzinfo=datetime.timezone.utc), private=False, gated=False, disabled=False, downloads=52, likes=1, paperswithcode_id=None, tags=['croissant', 'region:us'], card_data=None, siblings=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('lmsys/lmsys-chat-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversation_id', 'model', 'conversation', 'turn', 'language', 'openai_moderation', 'redacted'],\n",
       "    num_rows: 1000000\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__ior__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__ror__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_values_features',\n",
       " '_check_values_type',\n",
       " 'align_labels_with_mapping',\n",
       " 'cache_files',\n",
       " 'cast',\n",
       " 'cast_column',\n",
       " 'class_encode_column',\n",
       " 'cleanup_cache_files',\n",
       " 'clear',\n",
       " 'column_names',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'filter',\n",
       " 'flatten',\n",
       " 'flatten_indices',\n",
       " 'formatted_as',\n",
       " 'from_csv',\n",
       " 'from_json',\n",
       " 'from_parquet',\n",
       " 'from_text',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'load_from_disk',\n",
       " 'map',\n",
       " 'num_columns',\n",
       " 'num_rows',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'prepare_for_task',\n",
       " 'push_to_hub',\n",
       " 'remove_columns',\n",
       " 'rename_column',\n",
       " 'rename_columns',\n",
       " 'reset_format',\n",
       " 'save_to_disk',\n",
       " 'select_columns',\n",
       " 'set_format',\n",
       " 'set_transform',\n",
       " 'setdefault',\n",
       " 'shape',\n",
       " 'shuffle',\n",
       " 'sort',\n",
       " 'unique',\n",
       " 'update',\n",
       " 'values',\n",
       " 'with_format',\n",
       " 'with_transform']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
