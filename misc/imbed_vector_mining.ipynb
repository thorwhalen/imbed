{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the work-in-progress (WIP) scrap for the `imbed` project.\n",
    "\n",
    "It is not meant to be run by all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometries of Meaning\n",
    "\n",
    "See [this dicussion](https://github.com/thorwhalen/imbed/discussions/8) for research elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text-embedding-3-small'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import oa\n",
    "dir(oa)\n",
    "oa.DFLT_EMBEDDINGS_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-dimensional geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for dimension: 2\n",
      "Running experiment for dimension: 3\n",
      "Running experiment for dimension: 5\n",
      "Running experiment for dimension: 10\n",
      "Running experiment for dimension: 20\n",
      "Running experiment for dimension: 50\n",
      "Running experiment for dimension: 100\n",
      "Running experiment for dimension: 200\n",
      "Running experiment for dimension: 500\n",
      "Running experiment for dimension: 1000\n",
      "Running experiment for dimension: 2000\n",
      "Running experiment for dimension: 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>distance_variance</th>\n",
       "      <th>mean_cosine_similarity</th>\n",
       "      <th>cosine_similarity_variance</th>\n",
       "      <th>mean_norm</th>\n",
       "      <th>norm_variance</th>\n",
       "      <th>fraction_near_surface</th>\n",
       "      <th>fraction_near_corners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.036880</td>\n",
       "      <td>0.243316</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.760363</td>\n",
       "      <td>0.080944</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.324622</td>\n",
       "      <td>0.248944</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.333168</td>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.077264</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.763877</td>\n",
       "      <td>0.246771</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.200111</td>\n",
       "      <td>1.268053</td>\n",
       "      <td>0.071192</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2.528192</td>\n",
       "      <td>0.239534</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.099983</td>\n",
       "      <td>1.801721</td>\n",
       "      <td>0.069381</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>3.612528</td>\n",
       "      <td>0.235981</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>2.564314</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>5.753723</td>\n",
       "      <td>0.234546</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>4.074517</td>\n",
       "      <td>0.066812</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>8.145333</td>\n",
       "      <td>0.232957</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>5.763922</td>\n",
       "      <td>0.066146</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>11.530204</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>8.156026</td>\n",
       "      <td>0.067879</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>18.253276</td>\n",
       "      <td>0.234217</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>12.908884</td>\n",
       "      <td>0.067405</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>25.815978</td>\n",
       "      <td>0.234039</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>18.256126</td>\n",
       "      <td>0.067403</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000</td>\n",
       "      <td>36.507085</td>\n",
       "      <td>0.233204</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>25.815444</td>\n",
       "      <td>0.066709</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3000</td>\n",
       "      <td>44.721530</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>31.623681</td>\n",
       "      <td>0.064480</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dimension  mean_distance  ...  fraction_near_surface  fraction_near_corners\n",
       "0           2       1.036880  ...                 0.0088                 0.0058\n",
       "1           3       1.324622  ...                 0.0012                 0.0004\n",
       "2           5       1.763877  ...                 0.0014                 0.0000\n",
       "3          10       2.528192  ...                 0.0014                 0.0000\n",
       "4          20       3.612528  ...                 0.0026                 0.0000\n",
       "5          50       5.753723  ...                 0.0074                 0.0000\n",
       "6         100       8.145333  ...                 0.0060                 0.0000\n",
       "7         200      11.530204  ...                 0.0364                 0.0000\n",
       "8         500      18.253276  ...                 0.2740                 0.0000\n",
       "9        1000      25.815978  ...                 0.3538                 0.0000\n",
       "10       2000      36.507085  ...                 0.9600                 0.0000\n",
       "11       3000      44.721530  ...                 0.9958                 0.0000\n",
       "\n",
       "[12 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from idiom.high_dimensional_stats import run_high_dim_experiment\n",
    "\n",
    "df = run_high_dim_experiment()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='dimension'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGwCAYAAAAJ/wd3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACe4ElEQVR4nOzdd1xV9RvA8c9l771liiwB90JTcRRaWpqpGZWaltvMStPKHJVmziwbWmqp2TL7lSsztzjSJBcoKOBgKCIbLtx7fn+gt0hScHBBnvfr5esl55x7znPP5XKf+x3PV6UoioIQQgghRDUx0HcAQgghhKhbJPkQQgghRLWS5EMIIYQQ1UqSDyGEEEJUK0k+hBBCCFGtJPkQQgghRLWS5EMIIYQQ1cpI3wH8m1ar5eLFi1hbW6NSqfQdjhBCCCEqQVEUcnNz8fDwwMDg5m0bNS75uHjxIl5eXvoOQwghhBC34dy5c3h6et70mBqXfFhbWwNlwdvY2Og5GiGEEEJURk5ODl5eXrrP8ZupccnH9a4WGxsbST6EEEKIWqYyQyZkwKkQQgghqpUkH0IIIYSoVpJ8CCGEEKJa1bgxH5Wl0WgoKSnRdxhCiGuMjY0xNDTUdxhCiFqg1iUfiqKQlpbG1atX9R2KEOJf7OzscHNzkxo9QoibqnXJx/XEw8XFBQsLC/kjJ0QNoCgKBQUFZGRkAODu7q7niIQQNVmtSj40Go0u8XB0dNR3OEKIfzA3NwcgIyMDFxcX6YIRQvynWjXg9PoYDwsLCz1HIoSoyPX3pozHEkLcTK1KPq6TrhYhaiZ5bwohKqNWJh9CCCGEqL0k+RBCCCFEtZLkQ1TJ8uXLsbOz0/08depUmjRpord4hBBC1D6SfIg78sorr7B169ZKHSuJihBC6F96ThFxaTl6jaFWTbUVNY+VlRVWVlb6DkMIIcRNKIrC3sRMVu5L5tcT6TT3sefbYRF6i6fWt3woikKBulQv/xRFqXSckZGRjBkzhnHjxmFvb4+rqytLliwhPz+fwYMHY21tTYMGDdi4caPuMceOHaN79+5YWVnh6urKM888w+XLl3X7N23axAMPPICdnR2Ojo706NGDxMRE3f6kpCRUKhVr166lU6dOWFhY0LhxY2JiYiod9/Lly/H29sbCwoLevXuTmZlZbv+/WzO2b99Oq1atsLS0xM7Ojnbt2pGcnMzy5cuZNm0asbGxqFQqVCoVy5cvB2DevHmEh4djaWmJl5cXI0eOJC8vr1wMdnZ2bN68mZCQEKysrOjWrRupqanlYvniiy8IDQ3F1NQUd3d3Ro8erdt39epVhg4dirOzMzY2NnTu3JnY2NhK3wchhKiNrhaoWbrrDF3m7iB66X42HktDo1VAgUK1Rm9x1fqWj8ISDQ2nbNbLtU9Mj8LCpPK3cMWKFUyYMIEDBw7wzTffMGLECH788Ud69+7N5MmTmT9/Ps888wwpKSmo1Wo6d+7M0KFDmT9/PoWFhUycOJF+/frx+++/A5Cfn8/48eNp1KgReXl5TJkyhd69e3PkyBEMDP7OK19//XXmzJlDQEAAr7/+OgMGDCAhIQEjo5vHvn//foYMGcLMmTPp1asXmzZt4q233vrP40tLS+nVqxfPP/88X3/9NWq1mgMHDqBSqejfvz/Hjh1j06ZN/PbbbwDY2toCYGBgwAcffICfnx9nzpxh5MiRTJgwgcWLF+vOXVBQwJw5c/jqq68wMDDg6aef5pVXXmHVqlUAfPzxx4wfP55Zs2bRvXt3srOz2bNnj+7xffv2xdzcnI0bN2Jra8unn35Kly5dOHXqFA4ODpV+DYUQoqZTFIXY89ms3JfMz7EXKS7VAmBlakTvpvWIbuNNsJuNXmNUKVX5+l4NcnJysLW1JTs7Gxub8jenqKiIs2fP4ufnh5mZGQAF6tJakXxERkai0WjYtWsXUFat1dbWlscff5wvv/wSKCsd7+7uTkxMDL/99hu7du1i8+a/n9v58+fx8vIiPj6ewMDAG65x+fJlnJ2dOXr0KGFhYSQlJeHn58fSpUsZMmRIWcwnThAaGsrJkycJDg6+acxPPfUU2dnZrF+/XrftySefZNOmTbq1daZOncq6des4cuQIV65cwdHRke3bt9OxY8cbzvfPY2/m+++/Z/jw4bpWnuXLlzN48GASEhLw9/cHYPHixUyfPp20tDQA6tWrx+DBg3n77bdvON/u3bt55JFHyMjIwNTUVLe9QYMGTJgwgRdeeOGm8YjKq+g9KoSoHgXqUv535CIr9ydz7MLfYzpC3G14uo03jzWph5XpvWtzuNnn97/V+pYPc2NDTkyP0tu1q6JRo0a6/xsaGuLo6Eh4eLhum6urK1BWnjo2NpZt27ZVOJ4iMTGRwMBATp8+zZQpU9i/fz+XL19Gqy3LblNSUggLC6vwutfX3MjIyLhl8nHy5El69+5dbltERASbNm2q8HgHBwcGDRpEVFQUDz74IF27dqVfv363XOfjt99+Y+bMmcTFxZGTk0NpaSlFRUUUFBToKmZaWFjoEo/rz+P6OiIZGRlcvHiRLl26VHj+2NhY8vLybijJX1hYWK6bSgghaqPT6bms2p/CD4fPk1tUCoCJkQE9wt2JbuNDM2+7GlcAsNYnHyqVqkpdH/pkbGxc7meVSlVu2/VfDq1WS15eHj179uS999674TzXP8x79uyJj48PS5YswcPDA61WS1hYGGq1+j+v+89r3AvLli1j7NixbNq0iW+++YY33niDLVu20KZNmwqPT0pKokePHowYMYJ33nkHBwcHdu/ezZAhQ1Cr1brko6J7d73R7vqaIv8lLy8Pd3d3tm/ffsO+f04bFkKI2kJdqmXz8TRW7ktm/9kruu0+jhY81cqbvi28cLA00WOEN1c7PrXroGbNmvHDDz/g6+tb4diMzMxM4uPjWbJkCe3btwfKuhfuppCQEPbv319u2759+275uKZNm9K0aVMmTZpEREQEq1evpk2bNpiYmKDRlB/gdOjQIbRaLXPnztWNU/n222+rFKe1tTW+vr5s3bqVTp063bC/WbNmpKWlYWRkhK+vb5XOLYQQNcn5rAK+PpDCNwfPczmvGAADFXQJceXpNj60b+CEgUHNauWoiCQfNdSoUaNYsmQJAwYMYMKECTg4OJCQkMCaNWtYunQp9vb2ODo68tlnn+Hu7k5KSgqvvfbaXY1h7NixtGvXjjlz5vDYY4+xefPm/+xyATh79iyfffYZjz76KB4eHsTHx3P69GmeffZZAHx9fTl79ixHjhzB09NTN8OnpKSERYsW0bNnT/bs2cMnn3xS5VinTp3K8OHDcXFxoXv37uTm5rJnzx7GjBlD165diYiIoFevXsyePZvAwEAuXrzI+vXr6d27Ny1atLjteySEEPeaRquw89QlVu5LZlt8BtprIzVdrE15sqUXT7byxsPu5i3ANU2tn2p7v/Lw8GDPnj1oNBoeeughwsPDGTduHHZ2dhgYGGBgYMCaNWs4dOgQYWFhvPTSS7z//vt3NYY2bdqwZMkSFi5cSOPGjfn111954403/vN4CwsL4uLi6NOnD4GBgbzwwguMGjWKYcOGAdCnTx+6detGp06dcHZ25uuvv6Zx48bMmzeP9957j7CwMFatWsXMmTOrHOvAgQNZsGABixcvJjQ0lB49enD69GmgrItmw4YNdOjQgcGDBxMYGMiTTz5JcnKybpyNEELUNJfzilm8PYGO729j8PKDbI0rSzza+juyOLoZe17rzPiHgmpd4gH3wWwXIUTNIe9RIe6Moij8kZzFyn3JbDyahlpTNj7PxsyIJ5p7Ed3GG3/nmlnYsU7NdhFCCCFqu9yiEtb9eYGV+1KIT8/VbW/saUt0Gx96NvLA3KRqMyxrMkk+6rDu3bvr6o782+TJk5k8eXI1RySEEHXLiYs5rNyfzLo/L1BwreKombEBjzWux9NtfAj3tNVzhPeGJB912NKlSyksLKxwn1T9FEKIe6OoRMOGo6ms3JfM4ZSruu3+zpY83caHx5t5Ymtu/N8nuA9I8lGH1atXT98hCCFEnZGcmc+q/Sl898c5sgpKADAyUBEV5sbTrX1oU9+hxhUDu1ck+RBCCCHukVKNlq1xGazcl8yu038vDOpha8ZTrb3p19ILF+u6Nzhbkg8hhBDiLkvPKWLNgXOsOZhCanYRACoVdAhw5uk2PnQOdsGwFhQDu1ck+RBCCCHuAkVR2JuYycp9yWw5kU7ptWpgDpYm9G3hSXQrH7wdLfQcZc0gyYcQQghxB7ILSvju0DlW70/hzOV83fYWPvY83caH7uFumBrdP9Nk7wZJPoQQQojbEHvuKl/tS+bn2IsUl5YVA7M0MaR3s3pEt/YhxP3mhbbqMkk+9CgyMpImTZqwYMECfH19GTduHOPGjdN3WLXO9u3b6dSpE1lZWbJKrRDinipQl/Jz7EVW7kvh6IVs3fZgN2uebuNDr6b1sDKVj9ZbkTtUQxw8eBBLS8tKHSuJSnlt27YlNTUVW9v7sxiPEEL/EjJyWbkvhR8Onye3qBQAE0MDHmnkztNtvGnmbV9npsneDZJ81BDOzs76DqFWKikpwcTEBDc3N32HIoS4z6hLtfx6Io2V+5LZd+aKbru3gwXRrb3p28ILB0sTPUZYe9X+VW0VBdT5+vlXhTX58vPzefbZZ7GyssLd3Z25c+eW2+/r68uCBQuuPSWFqVOn4u3tjampKR4eHowdOxYo66pJTk7mpZdeQqVS6TLtzMxMBgwYQL169bCwsCA8PJyvv/663DUiIyMZO3YsEyZMwMHBATc3N6ZOnVrumKtXrzJs2DBcXV0xMzMjLCyMX375Rbd/9+7dtG/fHnNzc7y8vBg7diz5+fncyuTJk2nduvUN2xs3bsz06dOBstafBx98ECcnJ2xtbenYsSOHDx8ud7xKpeLjjz/m0UcfxdLSknfeeYft27ejUqm4evVqrbgXQoia7cLVQuZsjqftrN8ZvfpP9p25goEKHmzoyornWrH9lUiGdfSXxOMO1P6Wj5ICeNdDP9eefBFMKtdV8uqrr7Jjxw5++uknXFxcmDx5MocPH6ZJkyY3HPvDDz8wf/581qxZQ2hoKGlpacTGxgKwdu1aGjduzAsvvMDzzz+ve0xRURHNmzdn4sSJ2NjYsH79ep555hn8/f1p1aqV7rgVK1Ywfvx49u/fT0xMDIMGDaJdu3Y8+OCDaLVaunfvTm5uLitXrsTf358TJ05gaFg2SjsxMZFu3brx9ttv88UXX3Dp0iVGjx7N6NGjWbZs2U2ff3R0NDNnziQxMRF/f38Ajh8/zl9//cUPP/wAQG5uLgMHDmTRokUoisLcuXN5+OGHOX36NNbW1rpzTZ06lVmzZrFgwQKMjIw4c+ZMuWvV9HshhKh5tFqFHacvsWpfMr9fW7oewNnalAEtvXiylXetXLq+plIpShW+vleDmy3JW+Fy3er8Gp985OXl4ejoyMqVK+nbty8AV65cwdPTkxdeeOGGAafz5s3j008/5dixYxgb31jfv7JjPnr06EFwcDBz5swByr7tazSacovJtWrVis6dOzNr1ix+/fVXunfvzsmTJwkMDLzhfEOHDsXQ0JBPP/1Ut2337t107NiR/Pz8Wy6h3qRJE/r06cObb74JlLWG/P777+zbt6/C47VaLXZ2dqxevZoePXoAZS0f48aNY/78+brjKjPgtKbdi/tVhe9RIWqwzLxivv3jPKsPJHPuyt9rXUXUd+TpNj48FOqKsWHt7ySoDjf7/P632t/yYWxRlgTo69qVkJiYiFqtLtft4ODgQFBQUIXH9+3blwULFlC/fn26devGww8/TM+ePTEy+u+XS6PR8O677/Ltt99y4cIF1Go1xcXFWFiUj7FRo0blfnZ3dycjIwOAI0eO4OnpWeGHLUBsbCx//fUXq1at0m1TFAWtVsvZs2cJCQm56X2Ijo7miy++4M0330RRFL7++mvGjx+v25+ens4bb7zB9u3bycjIQKPRUFBQQEpKSrnztGjR4qbXqQ33QgihP4qi8EdyFiv3JbPxaBpqTdk0WRszI/o09yS6tQ8NXKz0HOX9rfYnHypVpbs+agsvLy/i4+P57bff2LJlCyNHjuT9999nx44dFbaEALz//vssXLiQBQsWEB4ejqWlJePGjUOtVpc77t+PV6lUaLVlbzxz85s3Kebl5TFs2DDd+JN/8vb2vuXzGjBgABMnTuTw4cMUFhZy7tw5+vfvr9s/cOBAMjMzWbhwIT4+PpiamhIREXHDc7jVrKDacC+EENUvt6iEdX9eYNX+FOLScnXbG3na8nRrH3o29sDcRIqBVYfan3zUAv7+/hgbG7N//37dB1NWVhanTp2iY8eOFT7G3Nycnj170rNnT0aNGkVwcDBHjx6lWbNmmJiYoNFoyh2/Z88eHnvsMZ5++mmgrMvi1KlTNGzYsNJxNmrUiPPnz3Pq1KkKv/E3a9aMEydO0KBBg0qf8588PT3p2LEjq1atorCwkAcffBAXF5dyz2Hx4sU8/PDDAJw7d47Lly//1+n+U224F0KI6nPiYg4r9yfz058XyFeX/e00Mzbg0cYePN3Gh0aedvoNsA6S5KMaWFlZMWTIEF599VUcHR1xcXHh9ddfx8Cg4n7E5cuXo9FoaN26NRYWFqxcuRJzc3N8fHyAsjEfO3fu5Mknn8TU1BQnJycCAgL4/vvv2bt3L/b29sybN4/09PQqfeB27NiRDh060KdPH+bNm0eDBg2Ii4tDpVLRrVs3Jk6cSJs2bRg9ejRDhw7F0tKSEydOsGXLFj788MNKXSM6Opq33noLtVpdbtwGQEBAAF999RUtWrQgJyeHV1999ZYtEBWpLfdCCHHvFJVo2HgslZX7UjiUnKXbXt/Zkqdb+9CnmSe2FhW3JIt7T0bRVJP333+f9u3b07NnT7p27coDDzxA8+bNKzzWzs6OJUuW0K5dOxo1asRvv/3Gzz//jKOjIwDTp08nKSkJf39/XX2QN954g2bNmhEVFUVkZCRubm706tWrynH+8MMPtGzZkgEDBtCwYUMmTJiga2Vp1KgRO3bs4NSpU7Rv356mTZsyZcoUPDwqP+D3iSeeIDMzk4KCghvi+/zzz8nKyqJZs2Y888wzjB07tlzLSGXVlnshhLj7kjPzmbnhJBEzt/LSN7EcSs7CyEDFI+HurH6+NVvHd+S5B/wk8dCz2j/bRQhRY8h7VOhDqUbL73EZrNyfws5Tl3TbPWzNGNDKm/4tvXCxkd/He61uzXYRQghRJ2XkFLHm4Dm+PpBCanYRUDYHoUOAM0+38aFTkDNGMk22RpLkQ9wVu3btonv37v+5Py8vrxqjEULcrxRFISYxk5X7k/n1eDql16qBOVia0LeFJ9GtfPB2rFwZBKE/d5R8zJo1i0mTJvHiiy/qSoMXFRXx8ssvs2bNGoqLi4mKimLx4sW4urrejXhFDdWiRQuOHDmi7zCEEPep7IISvj98nlX7kzlz6e9lDJr72PNMGx+6hblhZizTZGuL204+Dh48yKeffnpDoaaXXnqJ9evX891332Fra8vo0aN5/PHH2bNnzx0HK2ouc3NzmXYqhLjrYs9dZeW+ZH7+6yJFJWV1eCxNDOnVtB5Pt/EhxP3mYwtEzXRbyUdeXh7R0dEsWbKEt99+W7c9Ozubzz//nNWrV9O5c2cAli1bRkhICPv27aNNmzY3nKu4uJji4mLdzzk5ObcTkhBCiPtEoVrDz7EXWbk/mb/OZ+u2B7tZE93Gh95N62FlKqMGarPbevVGjRrFI488QteuXcslH4cOHaKkpISuXbvqtgUHB+Pt7U1MTEyFycfMmTOZNm3a7YQhhBDiPpKQkceq/cn8cOg8OUWlAJgYGvBwuBtPt/GhuY+9biVvUbtVOflYs2YNhw8f5uDBgzfsS0tLw8TE5IbFvVxdXUlLS6vwfJMmTSq3vkdOTg5eXl5VDUsIIUQtVKLR8uvxdFbuSybmTKZuu5eDOdGtfejb3BNHK1M9RijuhSolH+fOnePFF19ky5Ytd20Ov6mpKaam8oslhBB1ycWrhXx9IIU1B89xKbes691ABZ2DXXm6jTcdApwxMJBWjvtVlZKPQ4cOkZGRQbNmzXTbNBoNO3fu5MMPP2Tz5s2o1WquXr1arvUjPT0dNze3uxa0EEKI2kerVdh5+hIr96Xwe1w612bJ4mxtypMtvXiylTf17Kq+pIKofapUfaVLly4cPXqUI0eO6P61aNGC6Oho3f+NjY3ZunWr7jHx8fGkpKQQERFx14MXtVdSUhIqlarGTM/19fXVTRe/XVOnTqVJkya6nwcNGnRbZd3/bfny5Td0ZQpRm1zJV/PJjkQi52xn0LKD/HayLPGIqO/IR081Y+9rnXn5oSBJPOqQKrV8WFtbExYWVm6bpaUljo6Ouu1Dhgxh/PjxODg4YGNjw5gxY4iIiKhwsKmou7y8vEhNTcXJyUnfoQBlU8ctLS3v6ByvvPIKY8aMuUsR/a1///66lX6hLMlZt25djUnchKiIoigcSs5i5b5kNhxNQ60pmyZrbWbEE809iW7tQwMXKz1HKfTlrs9Vmj9/PgYGBvTp06dckTEh/snQ0LBGdcVdX6DvTlhZWWFldXf/mJaUlGBubn5bq/sKoQ95xaWs+/MCK/clE5eWq9veyNOWp1v70LOxB+YmUgysrrvjovfbt28v11xtZmbGRx99xJUrV8jPz2ft2rX39ENGURQKSgr08q8qa/JFRkYyZswYxo0bh729Pa6urixZsoT8/HwGDx6MtbU1DRo0YOPGjbrHHDt2jO7du2NlZYWrqyvPPPMMly9f1u3ftGkTDzzwAHZ2djg6OtKjRw8SExN1+693baxdu5ZOnTphYWFB48aNiYmJqXTce/bsITIyEgsLC+zt7YmKiiIrq2x56uLiYt3Ks2ZmZjzwwAPlZkFlZWURHR2Ns7Mz5ubmBAQEsGzZsnKxXf/2vn37dlQqFVu3bqVFixZYWFjQtm1b4uPjy8Xz008/0axZM8zMzKhfvz7Tpk2jtLT0ls9DURSmTp2Kt7c3pqameHh4MHbsWN3+f3e7qFQqPv30U3r06IGFhQUhISHExMSQkJBAZGQklpaWtG3bttz9/ne3y79V9vX65ptv6NixI2ZmZqxatapct8vy5cuZNm0asbGxqFQqVCoVy5cv57nnnqNHjx7lrldSUoKLiwuff/75Le+PEHcqLi2HN9YdpfU7v/HGumPEpeViZmxA3+ae/DSqHf8b/QD9WnpJ4iGA+2Btl8LSQlqvbq2Xa+9/aj8WxpVfQ2DFihVMmDCBAwcO8M033zBixAh+/PFHevfuzeTJk5k/fz7PPPMMKSkpqNVqOnfuzNChQ5k/fz6FhYVMnDiRfv368fvvvwOQn5/P+PHjadSoEXl5eUyZMoXevXtz5MgRDAz+zitff/115syZQ0BAAK+//joDBgwgISEBI6Obv/xHjhyhS5cuPPfccyxcuBAjIyO2bdumW1Z+woQJ/PDDD6xYsQIfHx9mz55NVFQUCQkJODg48Oabb3LixAk2btyIk5MTCQkJFBYW3vSar7/+OnPnzsXZ2Znhw4fz3HPP6arj7tq1i2effZYPPviA9u3bk5iYyAsvvADAW2+9ddPz/vDDD8yfP581a9YQGhpKWloasbGxN33MjBkzmDdvHvPmzWPixIk89dRT1K9fn0mTJuHt7c1zzz3H6NGjyyWMN1PZ1+u1115j7ty5NG3aFDMzMzZv3qzb179/f44dO8amTZv47bffALC1tSUwMJAOHTqQmpqKu7s7AL/88gsFBQX079+/UvEJUVXFpRo2Hk1j5b5k/kjO0m2v72xJdGsfnmjmKUvXiwrV+uSjNmncuDFvvPEGUFbfZNasWTg5OfH8888DMGXKFD7++GP++usvfvvtN5o2bcq7776re/wXX3yBl5cXp06dIjAwkD59+pQ7/xdffIGzszMnTpwoNzbnlVde4ZFHHgFg2rRphIaGkpCQQHBw8E3jnT17Ni1atCjXbRYaGgqUfZB+/PHHLF++XLeg3JIlS9iyZQuff/45r776KikpKTRt2pQWLVoAZa0Lt/LOO+/QsWNHoOxD+JFHHqGoqAgzMzOmTZvGa6+9xsCBAwGoX78+M2bMYMKECbdMPlJSUnBzc6Nr164YGxvj7e1Nq1atbvqYwYMH069fPwAmTpxIREQEb775JlFRUQC8+OKLDB48+JbP6brKvl7jxo3j8ccfr/Ac5ubmWFlZYWRkVK5FsW3btgQFBfHVV18xYcIEoKy6cN++fe96V5AQKZkFrDqQzHd/nOdKvhoAIwMVD4W68nRrHyL8HaUYmLipWp98mBuZs/+p/Xq7dlX8cx0cQ0NDHB0dCQ8P1227vvheRkYGsbGxbNu2rcIPjsTERAIDAzl9+jRTpkxh//79XL58Ga22bEBXSkpKuQ+zf173+rfijIyMWyYfR44coW/fvhXuS0xMpKSkhHbt2um2GRsb06pVK06ePAnAiBEj6NOnD4cPH+ahhx6iV69etG3b9qbX/K9Yvb29iY2NZc+ePbzzzju6YzQaDUVFRRQUFGBh8d+tUH379mXBggXUr1+fbt268fDDD9OzZ8+btv78M5brr82/X6+ioiJycnKwsbn1+hKVfb2uJ2tVNXToUD777DMmTJhAeno6Gzdu1LWSCXGnNFqF3+MyWLkvmZ2nL3G919nd1owBrbx5sqUXLjZ3p/6TuP/V+uRDpVJVqetDn4yNyzc/qlSqctuuf1PQarXk5eXRs2dP3nvvvRvOc/1DuWfPnvj4+LBkyRI8PDzQarWEhYWhVqv/87r/vMat3Okgx+7du5OcnMyGDRvYsmULXbp0YdSoUcyZM+c/H3OzWPPy8pg2bVqFrQK3Knrn5eVFfHw8v/32G1u2bGHkyJG8//777Nix44bX5Wax3O69hMq/Xrc76+bZZ5/ltddeIyYmhr179+Ln50f79u1v61xCXJeRW8Q3B87x9YEULmYX6bZ3CHTm6dbedA52wcjwjocPijqm1icf96tmzZrxww8/4OvrW+G388zMTOLj41myZInuA2b37t13NYZGjRqxdevWCtfe8ff3x8TEhD179uDj4wOUDXA8ePAg48aN0x3n7OzMwIEDGThwIO3bt+fVV1+9afJxM82aNSM+Pv62V881NzenZ8+e9OzZk1GjRhEcHMzRo0fLFc27V+7m62ViYqIbd/NPjo6O9OrVi2XLlhETE1OlLiEh/klRFGLOZLJqXwqbj6dReq0amL2FMf1aePFUa298HO9sarqo2yT5qKFGjRrFkiVLGDBgABMmTMDBwYGEhATWrFnD0qVLsbe3x9HRkc8++wx3d3dSUlJ47bXX7moMkyZNIjw8nJEjRzJ8+HBMTEzYtm0bffv2xcnJiREjRvDqq6/i4OCAt7c3s2fPpqCggCFDhgBlY1iaN29OaGgoxcXF/PLLL4SEhNx2PFOmTKFHjx54e3vzxBNPYGBgQGxsLMeOHSu3wGFFli9fjkajoXXr1lhYWLBy5UrMzc11idO9djdfL19fX86ePcuRI0fw9PTE2tpat0TB0KFD6dGjBxqNRjc2RojKyi4s4YdD51m1P5nES/m67c197Hm6jTfdw9wxM5bZKuLOSfJRQ3l4eLBnzx4mTpzIQw89RHFxMT4+PnTr1g0DAwNUKhVr1qxh7NixhIWFERQUxAcffEBkZORdiyEwMJBff/2VyZMn06pVK8zNzWndujUDBgwAYNasWWi1Wp555hlyc3Np0aIFmzdvxt7eHij7hj5p0iSSkpIwNzenffv2rFmz5rbjiYqK4pdffmH69Om89957GBsbExwczNChQ2/5WDs7O2bNmsX48ePRaDSEh4fz888/4+joeNvxVIWBgcFde7369Omjmz599epVli1bxqBBgwDo2rUr7u7uhIaG4uHhcXefhLhvHT2fzcp9yfwUe4GikrJuREsTQ3o1rUd0ax8aetx6TJMQVaFSqlKsohrk5ORga2tLdnb2DYP4ioqKOHv2LH5+fndtYTsh7id5eXnUq1ePZcuW/eeMmXtJ3qO1R6Faw89/XWTVvmRiz2frtge7WRPdxodeTTywNpNpsqLybvb5/W/S8iHEfUCr1XL58mXmzp2LnZ0djz76qL5DEjVU4qU8Vu1L4ftD58gpKivQZ2JoQPdwN55p40NzH3uZJivuOUk+6rDu3buza9euCvdNnjyZyZMnV3NEt2/VqlUMGzaswn0+Pj4cP368miOqXikpKfj5+eHp6cny5ctvWUBO1C0lGi1bTqSzcl8yexMzddu9HMx5qpUP/Vp44mhlqscIRV0jf6HqsKVLl/5nxVEHB4dqjubOPProo7RuXXGl2/+aSns/8fX1rVK5f1E3XLxayJoDKaw5eI6M3GIADFTQOdiF6DY+dAxwxsBAWjlE9ZPkow6rV6+evkO4a6ytrbG2ttZ3GELonVarsCvhMiv3JbP12tL1AE5WpjzZ0osBrb1l6Xqhd5J8CCHEfeBKvprv/jjH6gMpJGcW6La3qe/A0218eKihGyZGUgxM1AySfAghRC2lKAqHU7JYuS+F9UdTUZeWTZO1NjOiTzNPnm7jTQMXaREUNY8kH0IIUcvkFZey7s8LrNqfwsnUHN328Hq2PN3Gm56NPbAwkT/vouaS304hhKgl4tNyWbkvmR//vEBecdk0WVMjAx5t7MHTbXxo7GWn3wCFqCRJPoQQogYrLtWw6VgaK/clczApS7e9vpMl0W18eKKZJ7YW9/+MLnF/kdFHtdzUqVNp0qSJvsMAYPv27ahUKq5evXpH5/H19WXBggW6n1UqFevWrbujcwJERkaWW/SuNqlJr7OoHmnZRczaGEfbmb/z4pojHEzKwtBARfcwN1YPbc3Wlzsy5AE/STxErSTl1Wu5vLw8iouLq22NkptRq9VcuXIFV1fXO6qQeOnSJSwtLbGwsADKko8ff/yRXr163VF8V65cwdjYWDcl19fXl3HjxtWKhKQmvc43I+/RO5ddUMLiHQks35NE8bUBpG42Zgxo5c2TrbxwtZH7KmomKa9eh1hZWWFlZaXvMICyheTc3Nzu+DzOzs53IZq/qdVqTExMal3hNCibzaDRaGrU6yzujUK1hmV7z/LJ9kRd2fMWPvY836E+XYJdMDKUhmpx/6j1v82KoqAtKNDLv6o0Gmm1WmbPnk2DBg0wNTXF29ubd955B4CjR4/SuXNnzM3NcXR05IUXXiAvL0/32O3bt9OqVSssLS2xs7OjXbt2JCcnAzc2xw8aNIhevXoxZ84c3N3dcXR0ZNSoUZSUlOiOKS4u5pVXXqFevXpYWlrSunVrtm/fXqnnkZycTM+ePbG3t8fS0pLQ0FA2bNigi/Of3S7Lly/Hzs6OX375haCgICwsLHjiiScoKChgxYoV+Pr6Ym9vz9ixY9FoNLpr/Lvb5d8mTpxIYGAgFhYW1K9fnzfffLPc87t+T5YuXVruG/g/u10iIyNJTk7mpZdeQqVSoVKpyM/Px8bGhu+//77c9datW4elpSW5ubk3vTdt27Zl4sSJ5bZdunQJY2Njdu7cCcBXX31FixYtsLa2xs3NjaeeeoqMjAzd8dfv4caNG2nevDmmpqbs3r37htf54MGDPPjggzg5OWFra0vHjh05fPhwuWurVCqWLl1K7969sbCwICAggP/973/ljjl+/Dg9evTAxsYGa2tr2rdvT2Jiom7/0qVLCQkJwczMjODgYBYvXnzTeyCqrlSjZfX+FCLnbGP2pnhyikoJcrXm84Et+G54BFGhbpJ4iPtOrW/5UAoLiW/WXC/XDjp8CNW1roFbmTRpEkuWLGH+/Pk88MADpKamEhcXR35+PlFRUURERHDw4EEyMjIYOnQoo0ePZvny5ZSWltKrVy+ef/55vv76a9RqNQcOHLhpt8a2bdtwd3dn27ZtJCQk0L9/f5o0acLzzz8PwOjRozlx4gRr1qzBw8ODH3/8kW7dunH06FECAgJu+jxGjRqFWq1m586dWFpacuLEiZt+Iy8oKOCDDz5gzZo15Obm8vjjj9O7d2/s7OzYsGEDZ86coU+fPrRr147+/ftX6l5aW1uzfPlyPDw8OHr0KM8//zzW1tZMmDBBd0xCQgI//PADa9euxdDQ8IZzrF27lsaNG/PCCy/o7oulpSVPPvkky5Yt44knntAde/3nW1VQjY6OZvbs2cyaNUv3+nzzzTd4eHjQvn17AEpKSpgxYwZBQUFkZGQwfvx4Bg0apEvgrnvttdeYM2cO9evXx97e/obkMDc3l4EDB7Jo0SIURWHu3Lk8/PDDnD59ulyc06ZNY/bs2bz//vssWrSI6OhokpOTcXBw4MKFC3To0IHIyEh+//13bGxs2LNnD6WlZd+6V61axZQpU/jwww9p2rQpf/75J88//zyWlpYMHDjwVi+TuAVFUdh4LI05m+M5czkfgHp25ox/MJBeTethKGXPxf1MqWGys7MVQMnOzr5hX2FhoXLixAmlsLBQt02Tn6+cCArWyz9Nfn6lnlNOTo5iamqqLFmy5IZ9n332mWJvb6/k5eXptq1fv14xMDBQ0tLSlMzMTAVQtm/fXuG533rrLaVx48a6nwcOHKj4+PgopaWlum19+/ZV+vfvryiKoiQnJyuGhobKhQsXyp2nS5cuyqRJk275XMLDw5WpU6dWuG/btm0KoGRlZSmKoijLli1TACUhIUF3zLBhwxQLCwslNzdXty0qKkoZNmyY7mcfHx9l/vz5up8B5ccff/zPmN5//32lefPmup/feustxdjYWMnIyCh3XMeOHZUXX3zxP6+jKIqyf/9+xdDQULl48aKiKIqSnp6uGBkZ/ef9/6eMjAzFyMhI2blzp25bRESEMnHixP98zMGDBxVAdz+u38N169aVO+7fr/O/aTQaxdraWvn555912wDljTfe0P2cl5enAMrGjRsVRVGUSZMmKX5+fopara7wnP7+/srq1avLbZsxY4YSERHxn3FU9B4VN9p9+pLSc9EuxWfiL4rPxF+UptN/VT7fdUYpKim99YOFqKFu9vn9b7W+5UNlbk7Q4UN6u3ZlnDx5kuLiYrp06VLhvsaNG2Npaanb1q5dO7RaLfHx8XTo0IFBgwYRFRXFgw8+SNeuXenXrx/u7u7/eb3Q0NBy3/bd3d05evQoUNbFo9FoCAwMLPeYyg5mHDt2LCNGjODXX3+la9eu9OnTh0aNGv3n8RYWFvj7++t+dnV1xdfXt1xriaura7muh1v55ptv+OCDD0hMTCQvL4/S0tIbBjf5+Pjc1tiRVq1aERoayooVK3jttddYuXIlPj4+dOjQ4ZaPdXZ25qGHHmLVqlW0b9+es2fPEhMTw6effqo75tChQ0ydOpXY2FiysrLQassGFKakpNCwYUPdcS1atLjptdLT03njjTfYvn07GRkZaDQaCgoKSElJKXfcP18bS0tLbGxsdPf6yJEjtG/fvsKF9/Lz80lMTGTIkCG6liGA0tJSbG1tb3kvRMWOns9m9uY4dp2+DICFiSFD29fn+fZ+WJvJrBVRd9T+5EOlqnTXh76YVzJJ+S/Lli1j7NixbNq0iW+++YY33niDLVu20KZNmwqP//eHiUql0n3I5eXlYWhoyKFDh27ojqjMgMahQ4cSFRXF+vXr+fXXX5k5cyZz585lzJgxlY7lZvHdSkxMDNHR0UybNo2oqChsbW1Zs2YNc+fOLXfcP5O5qho6dCgfffQRr732GsuWLWPw4MGVnr0THR3N2LFjWbRoEatXryY8PJzw8HAAXRdbVFQUq1atwtnZmZSUFKKiolCr1VWKf+DAgWRmZrJw4UJ8fHwwNTUlIiLihvPc7F7f7Pfy+pijJUuW3LBacEXdWOLmzl7OZ86v8az/KxUAY0MV0a19GN25AU6ylL2og2QUUzUICAjA3NycrVu33rAvJCSE2NhY8vPzddv27NmDgYEBQUFBum1NmzZl0qRJ7N27l7CwMFavXn1bsTRt2hSNRkNGRgYNGjQo96+yM1W8vLwYPnw4a9eu5eWXX2bJkiW3Fcvt2Lt3Lz4+Prz++uu0aNGCgIAA3eDbqjIxMSk30PW6p59+muTkZD744ANOnDhRpfENjz32GEVFRWzatInVq1cTHR2t2xcXF0dmZiazZs2iffv2BAcHV6nF55/27NnD2LFjefjhhwkNDcXU1JTLly9X6RyNGjVi165d5QbrXufq6oqHhwdnzpy54ffEz8/vtmKuizJyipj841G6ztvB+r9SUamgd9N6bB0fydRHQyXxEHVWrW/5qA3MzMyYOHEiEyZMwMTEhHbt2nHp0iWOHz9OdHQ0b731FgMHDmTq1KlcunSJMWPG8Mwzz+Dq6srZs2f57LPPePTRR/Hw8CA+Pp7Tp0/z7LPP3lYsgYGBREdH8+yzzzJ37lyaNm3KpUuX2Lp1K40aNeKRRx656ePHjRtH9+7dCQwMJCsri23bthESEnJbsdyOgIAAUlJSWLNmDS1btmT9+vX8+OOPt3UuX19fdu7cyZNPPompqSlOTk4A2Nvb8/jjj/Pqq6/y0EMP4enpWelzWlpa0qtXL958801OnjzJgAEDdPu8vb0xMTFh0aJFDB8+nGPHjjFjxozbij0gIEA3cyYnJ4dXX321yi1so0ePZtGiRTz55JNMmjQJW1tb9u3bR6tWrQgKCmLatGmMHTsWW1tbunXrRnFxMX/88QdZWVmMHz/+tuKuK7ILS/h0RyJf7DlLUUlZS1OnIGdejQqmocfN6x8IURdIy0c1efPNN3n55ZeZMmUKISEh9O/fn4yMDCwsLNi8eTNXrlyhZcuWPPHEE3Tp0oUPP/wQKBszERcXR58+fQgMDOSFF15g1KhRDBs27LZjWbZsGc8++ywvv/wyQUFB9OrVi4MHD+Lt7X3Lx2o0GkaNGkVISAjdunUjMDCwWqdfPvroo7z00kuMHj2aJk2asHfvXt58883bOtf06dNJSkrC39//hvEhQ4YMQa1W89xzz1X5vNHR0cTGxtK+ffty99TZ2Znly5fz3Xff0bBhQ2bNmsWcOXNuK/bPP/+crKwsmjVrxjPPPMPYsWNxcXGp0jkcHR35/fffycvLo2PHjjRv3pwlS5boumqGDh3K0qVLWbZsGeHh4XTs2JHly5dLy8dNFJVo+GxnIh1mb2Px9kSKSrQ087bjmxfasGxwK0k8hLhGKpwKUYGvvvqKl156iYsXL2JiYqLvcGqNuvoeLdVo+eHweRb8dprU7CIAAlyseDUqiAcb3lnFXyFqC6lwKsRtKigoIDU1lVmzZjFs2DBJPMRNKYrC5uNpvL85nsRLZeO2PGzNGPdgIH2aeUqtDiH+g3S7iHK6d++uK+X973/vvvuuvsO752bPnk1wcDBubm5MmjSp3L533333P+9N9+7d9RSx0JeYxEx6L97L8JWHSbyUj52FMW88EsLvr0TSr4WXJB5C3IR0u4hyLly4QGFhYYX7HBwcauX6KHfLlStXuHLlSoX7zM3NqVevXjVHVPPUhffosQvZzN4cz85TlwAwNzZkaHs/nu9QHxup1SHqMOl2EbdNPkD/W11Pvuq65Mx85v56iv/FXgTAyEDFgFbejOnSABfr+zPREuJekeRDCCFuIiO3iA9/T2D1/hRKtWUNxY829mD8g4H4Ot1+MTsh6jJJPoQQogI5RSUs2XmGpbvOUlhSVoyuQ6AzE6KCCKsnJeaFuBOSfAghxD8UlWhYuS+Zj7YlkFVQVv21sZcdE7sF0dbfSc/RCXF/kORDCCEAjVYpq9Wx5RQXr9XqqO9syYSoIKJC3aRWhxB3kSQfQog6TVEUtpxI5/3N8ZzOKFtQz83GjJceDKBPM0+MDKUigRB3myQfQog6a/+ZTN7bFMfhlKsA2JobMzLSn4FtfTEzltV7hbhXJPkQQtQ5J1NzmL0pjm3xZbU6zIwNeK6dH8M6+mNrLrU6hLjXJPkQ1a6kpES3eJkQ1enclQLmbTnFuiMXUBQwNFDRv6UXL3YJwNVGanUIUV1qfWemoiiUFGv08q8qxWEjIyMZM2YM48aNw97eHldXV5YsWUJ+fj6DBw/G2tqaBg0asHHjRt1jjh07pit37urqyjPPPMPly5d1+zdt2sQDDzyAnZ0djo6O9OjRg8TERN3+pKQkVCoVa9eupVOnTlhYWNC4cWNiYmIqFfPy5cuxs7Nj8+bNhISEYGVlRbdu3UhNTdUdo9VqmT59Op6enpiamtKkSRM2bdp0QwzffPMNHTt2xMzMjFWrVjFo0CB69erFu+++i6urK3Z2dkyfPp3S0lJeffVVHBwc8PT0ZNmyZZW+x0L8l8t5xUz933E6z93Oj3+WJR6PNHJny0sdeLd3uCQeQlSzWt/yUarW8tmLO/Ry7RcWdsTYtPL9witWrGDChAkcOHCAb775hhEjRvDjjz/Su3dvJk+ezPz583nmmWdISUlBrVbTuXNnhg4dyvz58yksLGTixIn069eP33//HYD8/HzGjx9Po0aNyMvLY8qUKfTu3ZsjR45gYPB3Xvn6668zZ84cAgICeP311xkwYAAJCQkYGd365S8oKGDOnDl89dVXGBgY8PTTT/PKK6+watUqABYuXMjcuXP59NNPadq0KV988QWPPvoox48fJyAgQHee1157jblz59K0aVPMzMzYvn07v//+O56enuzcuZM9e/YwZMgQ9u7dS4cOHdi/fz/ffPMNw4YN48EHH8TT07PS91mI63KLSliy6yxLd52hQF1Wq6N9gBOvRgXRyNNOv8EJUYfV+rVdSoo1tSL5iIyMRKPRsGvXLgA0Gg22trY8/vjjfPnllwCkpaXh7u5OTEwMv/32G7t27WLz5s26c5w/fx4vLy/i4+MJDAy84RqXL1/G2dmZo0ePEhYWRlJSEn5+fixdupQhQ4YAcOLECUJDQzl58iTBwcE3jXn58uUMHjyYhIQE/P39AVi8eDHTp08nLS0NKCvHPmrUKCZPnqx7XKtWrWjZsiUfffSRLoYFCxbw4osv6o4ZNGgQ27dv58yZM7pEKTg4GBcXF3bu3FnuHi1dupQnn3yyUvdZ6FdNWduluFTDqn0pfLgtgSv5agAaedoysVsw7RpIrQ4h7oU6tbaLkYkBLyzsqLdrV0WjRo10/zc0NMTR0ZHw8HDdNldXVwAyMjKIjY1l27ZtWFlZ3XCexMREAgMDOX36NFOmTGH//v1cvnwZrVYLQEpKCmFhYRVe193dXXeNWyUfABYWFrrE4/rjMzIygLJftIsXL9KuXbtyj2nXrh2xsbHltrVo0eKGc4eGhpZroXF1dS0X9/V7dP16QtyKRquw7s8LzNtyigtXyxZI9HOy5JWHgng4XGp1CFFT1PrkQ6VSVanrQ5/+PchSpVKV23b9D6NWqyUvL4+ePXvy3nvv3XCe6wlEz5498fHxYcmSJXh4eKDVagkLC0OtVv/ndf95jduN+XYayywtb1wD41b34/q2ysYq6i5FUfg9LoPZm+KJT88FwMXalHFdA+nbwhNjqdUhRI1S65OP+1WzZs344Ycf8PX1rXBsRmZmJvHx8SxZsoT27dsDsHv37mqN0cbGBg8PD/bs2UPHjn+3Pu3Zs4dWrVpVayyi7voj6QrvbYrjYFIWANZmRoyI9GdwWz/MTWrHFxMh6hpJPmqoUaNGsWTJEgYMGMCECRNwcHAgISGBNWvWsHTpUuzt7XF0dOSzzz7D3d2dlJQUXnvttWqP89VXX+Wtt97C39+fJk2asGzZMo4cOaIbkCrEvRKflsv7m+P47WRZt5ypkQGD2vkyoqM/dhYmeo5OCHEzknzUUNdbFCZOnMhDDz1EcXExPj4+dOvWDQMDA1QqFWvWrGHs2LGEhYURFBTEBx98QGRkZLXGOXbsWLKzs3n55ZfJyMigYcOG/O9//ys300WIu+l8VlmtjutTZg0NVPRr4cnYLgG425rrOzwhRCXU+tkuQoia416+R6/kq/nw9wRW7ktGrSkbB9Q9zI2XHwqigcuNA7OFENWrTs12EULc3/KLS1m66yxLdp0hr7gUgIj6jkzsHkwTLzv9BieEuC2SfNRh3bt319Ud+bfJkyeXq90hRHVTl2r5+kAKi34/zeW8shlcoR42TOwWTPsAJ5k2K0QtJslHHbZ06VIKCwsr3Ofg4FDN0QhRRqtV+F/sReZuiefclbLfTx9HC15+KIge4e4YGEjSIURtJ8lHHVavXj19hyCEjqIobD91idmb4jmZmgOAs7UpY7sE8GRLL6nVIcR9RJIPIYTeHU7JYtbGOA6cvQKAtakRwyP9GdzOFwsT+TMlxN2Qn11MyvFMko9lYmZlQuRTQXqLRd7VQgi9ScjIZfameH49kQ6AiZEBAyN8GBnZAHtLqdUhxJ3QahUyknJIPlaWcFxKydXtM7U0osOTgXrrxpTkQwhR7S5eLWT+llP8cPg8WgUMVPBEc09e7BpIPTup1SHE7SrKKyHlZCbJRzNJOX6FovyScvtdfKzxCXPEJ8wJfY6ekuRDCFFtsvLVLN6ewIqYZNSlZbU6HmroyqtRQQS4Wus5OiFqH0VRuHw+j+SjZa0b6Wez+Wf1LhNzI7wbOuAT5oh3qCMWNjWjRVGSDyHEPVegLuWL3Wf5dMcZcq/V6mjt58DE7sE087bXc3RC1C7qolLOnbyi604pyC6/mKhjPUtd64ZbfRsMauBgbUk+RLXx9fVl3LhxjBs3Tt+hiGpSotGy5uA5Pth6mku5xQCEuNswoVsQkYHOUqtDiEpQFIWr6QUkXWvdSE24ilbzd/OGkYkBnsEO1xIOR6wdan4FcEk+RLU5ePAglpaW+g5DVANdrY5f40nOLADAy8GcVx4KomcjD6nVIcQtlKo1nI/PIuVYJsnHM8m5XFRuv62LOT5hjviGOeEeYIuRce1awVmSj1pKrVZjYlIz+u5u5Xqszs7O+g5F3GOKolBUomHEqkPsSMwGwMnKhDGdAxjQyhsTo5rX/CtETZFzuVDXlXI+PgtNiVa3z8BIRb1Ae3xCy1o37Fwt9Bjpnav1fwkURaGkqEgv/6qyJl9kZCRjx45lwoQJODg44ObmxtSpU3X7U1JSeOyxx7CyssLGxoZ+/fqRnp6u2z916lSaNGnC0qVLyy3apVKp+PTTT+nRowcWFhaEhIQQExNDQkICkZGRWFpa0rZtWxITE28Z46lTp1CpVMTFxZXbPn/+fPz9/QHQaDQMGTIEPz8/zM3NCQoKYuHCheWOHzRoEL169eKdd97Bw8ODoKCyueS+vr4sWLBAd9y8efMIDw/H0tISLy8vRo4cSV5enm7/8uXLsbOzY/PmzYSEhGBlZUW3bt1ITU0td70vvviC0NBQTE1NcXd3Z/To0bp9V69eZejQoTg7O2NjY0Pnzp2JjY295b0QVVegLuV8VgGX89QkZORhZWrE+AcD2fFqJwa29ZXEQ4h/0ZRqOR93hT3fn2b11H189UYMO9ecIvlYJpoSLVb2poS29+DhkY0YOrcDj45tQuMuXrU+8YD7oOWjtLiYDwY+oZdrj13xPcZVWLlzxYoVjB8/nv379xMTE8OgQYNo164dXbp00SUeO3bsoLS0lFGjRtG/f3+2b9+ue3xCQgI//PADa9euxdDw7ya2GTNmMG/ePObNm8fEiRN56qmnqF+/PpMmTcLb25vnnnuO0aNHs3HjxpvGFxgYSIsWLVi1ahUzZszQbV+1ahVPPfUUAFqtFk9PT7777jscHR3Zu3cvL7zwAu7u7vTr10/3mK1bt2JjY8OWLVv+83oGBgZ88MEH+Pn5cebMGUaOHMmECRNYvHix7piCggLmzJnDV199hYGBAU8//TSvvPIKq1atAuDjjz9m/PjxzJo1i+7du5Odnc2ePXt0j+/bty/m5uZs3LgRW1tbPv30U7p06cKpU6ekhPxdUlSiIT2niOzCEpRSDSoVPN7Mk0HtA3C0MtV3eELUKPlXi0m+Vujr3MkrlBRpdPtUBirc/W11YzccPCzv23FRVUo+Pv74Yz7++GOSkpIACA0NZcqUKXTv3h0oW0775ZdfZs2aNRQXFxMVFcXixYtxdXW964HXRo0aNeKtt94CICAggA8//JCtW7cCcPToUc6ePYuXlxcAX375JaGhoRw8eJCWLVsCZd0XX3755Q3dF4MHD9Z98E+cOJGIiAjefPNNoqKiAHjxxRcZPHhwpWKMjo7mww8/1CUfp06d4tChQ6xcuRIAY2Njpk2bpjvez8+PmJgYvv3223LJh6WlJUuXLr1p19A/B576+vry9ttvM3z48HLJR0lJCZ988omu5WX06NFMnz5dt//tt9/m5Zdf5sUXX9Rtu36/du/ezYEDB8jIyMDUtOxDcM6cOaxbt47vv/+eF154oVL3RFRMXaolI7eIrPwSFMpaAW3MjDGwMWVUU3/MzCTxEEKrVUg/m0PyscskH8vk8rm8cvvNrY3LulLCnfAKscfUwlhPkVavKiUfnp6ezJo1i4CAABRFYcWKFTz22GP8+eefhIaG8tJLL7F+/Xq+++47bG1tGT16NI8//ni5b6J3m5GpKWNXfH/Pzn+ra1dFo0aNyv3s7u5ORkYGJ0+exMvLS5d4ADRs2BA7OztOnjyp+zD18fGpcNzEP897PdELDw8vt62oqIicnBxsbGxuGuOTTz7JK6+8wr59+2jTpg2rVq2iWbNmBAcH64756KOP+OKLL0hJSaGwsBC1Wk2TJk3KnSc8PPyWY1J+++03Zs6cSVxcHDk5OZSWllJUVERBQQEWFmXNihYWFrrE45/3DCAjI4OLFy/SpUuXCs8fGxtLXl4ejo6O5bYXFhZWqhtKVKxUo+VSXjGZeWq0yt9Jh5utGWhKOJsl3SuibivMU5NyvGwqbMqJTIrzS//eqQIXHxt8w8taN5y9rFHVwQHYVUo+evbsWe7nd955h48//ph9+/bh6enJ559/zurVq+ncuTMAy5YtIyQkRPdBdi+oVKoqdX3ok7Fx+YxWpVKh1Wr/4+gb/ddMkX+e93oTXUXbKnMtNzc3OnfuzOrVq2nTpg2rV69mxIgRuv1r1qzhlVdeYe7cuURERGBtbc3777/P/v37KxXrdUlJSfTo0YMRI0bwzjvv4ODgwO7duxkyZAhqtVqXfFR0z66PtTE3v3klzLy8PNzd3ct1XV1nZ2d308eKG2m1Cpfzi7mUW4xGW/YaWJoY4WZrhqVp2Z+SIk3JzU4hxH1J0V4r9HWtdSPtbA78Y0igqcXfhb68GtacQl/6dNtjPjQaDd999x35+flERERw6NAhSkpK6Nq1q+6Y4OBgvL29iYmJ+c/ko7i4mOLiYt3POTk5txtSrRUSEsK5c+c4d+6crvXjxIkTXL16lYYNG1Z7PNHR0UyYMIEBAwZw5swZnnzySd2+PXv20LZtW0aOHKnbdjutCIcOHUKr1TJ37lwMDMq+KX/77bdVOoe1tTW+vr5s3bqVTp063bC/WbNmpKWlYWRkhK+vb5VjFGW0ikJWvpqM3GJKNGUJrJmxIW42ZlibGd23fdJC3ExxYSnn/1noK+ffhb6s8LnWuuHmVzMLfelTlZOPo0ePEhERQVFREVZWVvz44480bNiQI0eOYGJicsM3SldXV9LS0v7zfDNnziw3hqAu6tq1K+Hh4URHR7NgwQJKS0sZOXIkHTt2pEWLFtUez+OPP86IESMYMWIEnTp1wsPDQ7cvICCAL7/8ks2bN+Pn58dXX33FwYMH8fPzq9I1GjRoQElJCYsWLaJnz57s2bOHTz75pMqxTp06leHDh+Pi4kL37t3Jzc1lz549jBkzhq5duxIREUGvXr2YPXs2gYGBXLx4kfXr19O7d2+93NvaRFEUsgtLSM8ppri0bFCciaEBrjZm2FkYS9Ih6hRFUchKLbiWbFwmNSEbrfYfhb5MDfEKttcNFrWyrx0t8vpS5eQjKCiII0eOkJ2dzffff8/AgQPZsWPHbQcwadIkxo8fr/s5Jyen3NiHukClUvHTTz8xZswYOnTogIGBAd26dWPRokV6icfa2pqePXvy7bff8sUXX5TbN2zYMP7880/69++PSqViwIABjBw58pYzaf6tcePGzJs3j/fee49JkybRoUMHZs6cybPPPlul8wwcOJCioiLmz5/PK6+8gpOTE088UTb7SaVSsWHDBl5//XUGDx7MpUuXcHNzo0OHDjII+hZyi0pIyy6isKQs6TAyMMDF2hQHKxMMJOkQdUSJWsOF+Czduim5V8oX+rJztdAlGx4N7DA0ltaNylIpVSlWUYGuXbvi7+9P//796dKlC1lZWeVaP3x8fBg3bhwvvfRSpc6Xk5ODra0t2dnZNwyOLCoq4uzZs+XqXAgh7p4CdSlp2UXkXVt/xUClwtnaFCcrUwwrMShO3qOitsu+VKhr3bgQfxVN6d9j5QyNDKgXZKdbpM3OpfbX27ibbvb5/W93XOdDq9VSXFxM8+bNMTY2ZuvWrfTp0weA+Ph4UlJSiIiIuNPLCCHuoeISDWnXanVAWauRo6UJztamGEtftbiPaUq1XEy4qmvduJpeUG6/lYMpvmFO+IQ5Ui/IHmPT2lXGvKaqUvIxadIkunfvjre3N7m5uaxevZrt27ezefNmbG1tGTJkCOPHj8fBwQEbGxvGjBlDRETEPZvpIqouNDSU5OTkCvd9+umnREdHV3NEQp9KNFrSc8rX6rC3MMHVxhQTI/kjK+5PeVnFpBzPJOnoZc7HZVFS/HehLwMDFe4NbPG+XujL/f4t9KVPVUo+MjIyePbZZ0lNTcXW1pZGjRqxefNmHnzwQaCsDLeBgQF9+vQpV2RM1BwbNmygpKTi6ZAyDqLuKNVquZRbvlaHtZkxbjZmmJtI0iHuL1qNlvSzOSRdm5mSef5fhb5sTMrGboQ64tXQAVPzWl/8u8a74zEfd5uM+RDi3tFqFTLzi8n4R60Oi2u1OqxM7/wPrrxHRU1RmKsm5VoZ85QTVyguKF/oy9XXRjdYtK4W+rrbqnXMhxCi5lMUhawCNek5/6jVYWSIm63U6hD3B0WrcOlcrq7uRnpSBYW+rq0I693QAXNrKfSlT5J8CHEfUxSFnKIS0rL/rtVhfK1Wh73U6hC1XHFhKedOXCmrLHr8CoX/KvTl5GWlW4LeVQp91SiSfAhxn8orKiEtp5gCdVlzs5GBCmdrMxwtTTCQJmZRCymKwpWL+brWjbTE8oW+jE0N8Qpx0E2FtbKXxQ1rKkk+hLjPFKpLScspJreobGCxgUqFk5UpztYmGBrINz9Ru5QUazgfn6WrvZF3pbjcfns3C93MFI8Gdhgaye94bSDJhxD3ieISDek5xVwtLGt6VqHCwcoEF6nVIWqZqxllZcxTjmVy4dS/Cn0ZG1Av8O8y5rbON19gUtRMknxUE0VRGDZsGN9//z1ZWVn8+eefNyxDf69s376dTp063VB9Vtw9BQUFPPPMM2zZsoXc3NxqvdclGi0ZOcVcyVfranXYmZvgamuKqdTqELWApkTLxdNXy1o3jt9Y6MvawUy3SFu9IHuMZTp4rSfJRzXZtGkTy5cvZ/v27dSvXx8nJ6d7cp3IyEiaNGnCggULdNvatm2rq80i7o0VK1awa9cu9u7di5OTU7Xca41Wy6VcNZfziv9Vq8MUcxN5a4uaLfdKkW4q7Lm4LEr/XegrwBafUCd8wh2xd7OQwdH3GfkLVU0SExNxd3enbdu2Fe5Xq9WYmNybqV8mJia4ubndk3PXJIqioNFoMDKqvl/r669bYmIiISEhhIWF3fNrltXqUHMpt4jSf9bqsDHDykze0qJm0mq0pJ3J0Q0WzbxQvtCXxfVCX+GOeAU7YCKFvu5rtb4jWFEUtGqNXv5Vtj7boEGDGDNmDCkpKahUKnx9fYmMjGT06NGMGzcOJycnoqKiAJg3bx7h4eFYWlri5eXFyJEjycsr/ybds2cPkZGRWFhYYG9vT1RUFFlZWQwaNIgdO3awcOFCVCoVKpWKpKQktm/fjkql4urVq7pz/PDDD4SGhmJqaoqvry9z584tdw1fX1/effddnnvuOaytrfH29uazzz6r1PNNSkpCpVKxdu1aOnXqhIWFBY0bNyYmJqbccbt376Z9+/aYm5vj5eXF2LFjyc/P1+3/6quvaNGiBdbW1ri5ufHUU0+RkZGh23/9eW3cuJHmzZtjamrK7t27bxpbbGwsnTp1wtraGhsbG5o3b84ff/wBwNSpU2/oCluwYAG+vr66nwcNGkSvXr1455138PDwICgoiMjISObOncvOnTtRqVRERkZWKn6A48eP06NHD2xsbLC2tqZ9+/YkJibq9i9dupSQkBDMzMwIDg7m/fkfEJ+eS2p2IaVaBVMjQ3wcLfF3tpTEQ9Q4BTlq4valsnnpMb54dTc/zj3M4c3JZYmHCtzq29D6UT/6TW7JoFnt6PxsCP5NXSTxqANq/SuslGi5OGWvXq7tMb0tqkr0PS5cuBB/f38+++wzDh48iKGhIX379mXFihWMGDGCPXv26I41MDDggw8+wM/PjzNnzjBy5EgmTJigK1N/5MgRunTpwnPPPcfChQsxMjJi27ZtaDQaFi5cyKlTpwgLC2P69OkAODs7k5SUVC6eQ4cO0a9fP6ZOnUr//v3Zu3cvI0eOxNHRkUGDBumOmzt3LjNmzGDy5Ml8//33jBgxgo4dOxIUFFSp+/P6668zZ84cAgICeP311xkwYAAJCQkYGRmRmJhIt27dePvtt/niiy+4dOkSo0ePZvTo0SxbtgyAkpISZsyYQVBQEBkZGYwfP55BgwaxYcOGctd57bXXmDNnDvXr18fe3v6mMUVHR9O0aVM+/vhjDA0NOXLkCMbGxpV6Ptdt3boVGxsbtmzZAoC7uzuvvfYax44dY+3atboWrFvFf+HCBTp06EBkZCS///47NjY27Nmzh9LSsqmxq1atYsqUKSxatIgGDcPZtfcgb7wyhmKM6fNkNK42pthbmEhztKgxFK1CRsq1Ql9HL5ORklu+0JelEd4NHfENLytjbm4lhb7qqlqffNQGtra2WFtbY2hoWK77IyAggNmzZ5c7dty4cbr/+/r68vbbbzN8+HBd8jF79mxatGhRbs2c0NBQ3f9NTEywsLC4aTfLvHnz6NKlC2+++SYAgYGBnDhxgvfff79c8vHwww8zcuRIACZOnMj8+fPZtm1bpZOPV155hUceeQSAadOmERoaSkJCAsHBwcycOZPo6Gjd8w0ICOCDDz6gY8eOfPzxx5iZmfHcc8/pzlW/fn0++OADWrZsSV5eHlZWVrp906dP160vdCspKSm8+uqrBAcH665bVZaWlixdurRcN5mFhcUN3Vu3iv+jjz7C1taWNWvW6BKgwMBA3WPeeust3pk1m8btoyhQl9Ih6hGejT/JT2tWMPnF4VKrQ9QIxQUlpJy4Qsq1waKFueXXjnLyssI3vGxVWBdfG/m9FcB9kHyojA3wmF7xOIrquPadaN68+Q3bfvvtN2bOnElcXBw5OTmUlpZSVFREQUEBFhYWHDlyhL59+97RdU+ePMljjz1Wblu7du1YsGABGo0GQ8Oy1pxGjRrp9qtUKtzc3G7oNriZfz7e3d0dKFucMDg4mNjYWP766y9WrVqlO0ZRFLRaLWfPniUkJIRDhw4xdepUYmNjycrKQqstm26XkpJCw4YNdY9r0aJFpWMaP348Q4cO5auvvqJr16707dsXf3//Sj8eIDw8vFLjc24V/5EjR2jfvn2FLS+Xs3JITExk5LAXUBkMB0ClAk1pKba2tvIHXOjNPwt9JR29TNqZHJR/Fvoy+7vQl0+oI5Z2UuhL3Kj2Jx8qVaW6PmoiS0vLcj8nJSXRo0cPRowYwTvvvIODgwO7d+9myJAhqNVqLCwsMDevvjnt//5QVKlUug/Qqj7+etfA9cfn5eUxbNgwxo4de8PjvL29yc/PJyoqiqioKFatWoWzszMpKSlERUWhVpcvofzv+3gzU6dO5amnnmL9+vVs3LiRt956izVr1tC7d28MDAxuGMdT0QrAlbleZeKv6LVUl2pIyykmMTkNgLdmL+SBtm1wtPq7Vsf15FCI6qIuKuVCfBZJ12pv5GXdWOirbLCoE+7+tlLoS9xSrU8+7ieHDh1Cq9Uyd+5cDK5Vovz222/LHdOoUSO2bt3KtGnTKjyHiYkJGo2mwn3XhYSElBtnAmWDWAMDA6vtg61Zs2acOHGCBg0aVLj/6NGjZGZmMmvWLLy8vAB0A0PvVGBgIIGBgbz00ksMGDCAZcuW0bt3b5ydnUlLS0NRFF2ydOTIkdu6Rlxc3C3jb9SoEStWrChLcAwMy5a4z1ejKAqOzi64urlTmHmRB5qH39HzFeJ2XE0v0FUVvXD6KtrSvxNzQ2MDPIP+LvRl4ySFvkTVSPJRgzRo0ICSkhIWLVpEz5492bNnD5988km5YyZNmkR4eDgjR45k+PDhmJiYsG3bNvr27YuTkxO+vr7s37+fpKQkrKyscHBwuOE6L7/8Mi1btmTGjBn079+fmJgYPvzww3LjSO61iRMn0qZNG0aPHs3QoUOxtLTkxIkTbNmyhQ8//BBvb29MTExYtGgRw4cP59ixY8yYMeOOrllYWMirr77KE088gZ+fH+fPn+fgwYP06dMHKKuRcunSJWbPns0TTzzBpk2b2Lhx4y2Xhq5IZeIfPXo0ixYtolefvjw7fBwW1tb8dfggrVu1om3zRrw9Yzpjx47F0cGebt26UVxczB9//EFWVhbjx4+/o3shxL+VlmjKCn0dLZsKm32psNx+GyczfMLKxm7UC7TDqJa2OIuaQdrGapDGjRszb9483nvvPcLCwli1ahUzZ84sd0xgYCC//vorsbGxtGrVioiICH766SddbYtXXnkFQ0NDGjZsqGvq/7dmzZrx7bffsmbNGsLCwpgyZQrTp08vN9j0XmvUqBE7duzg1KlTtG/fnqZNmzJlyhQ8PDyAslk6y5cv57vvvqNhw4bMmjWLOXPm3NE1DQ0NyczM5NlnnyUwMJB+/frRvXt3XStSSEgIixcv5qOPPqJx48YcOHCAV1555baudav4tYqC1sSKJWv+R1Z2LoOeeIQBD3diw3erqO9qh4WJEUOHDmXp0qUsW7aM8PBwOnbsyPLly/Hz87uj+yDEdblXiji28wLrF//F5y/v4ucPYvlr23myLxViYKiiXpA97Z5owFNTW/P0jAg6PBmIT5ijJB7ijqmUyharqCY5OTnY2tqSnZ19wzfOoqIizp49i5+fH2ZmZnqKUIjbpygKVwtKSM8pQq0pG/9iamSIm40pNua1f4l7eY/WbBqNlvQz2SRda924cjG/3H5L22uFvsKc8Ay2l3obokpu9vn9b/KbJUQ1UBSF3KJS0nKKKCopG5NjbGiAi40pDlKrQ9xDBTlqXVXRcyevoC4s1e1TqcCtvq1uVVgnTyv5XRTVQpIPUWXvvvsu7777boX72rdvz8aNG6s5or+FhoaSnJxc4b5PP/2U6Ojoao4I8otLScsuIl9d9kff0ECFs7UpTpamMmVW3HWKViE9OUe3KmxGcm65/WaWxniHlU2F9Q5xxMyqakX2hLgbJPkQVTZ8+HD69etX4b7qnApckQ0bNlQ4PRbA1dW1WmMpLNGQnl1ETlFZPAYqFY5WJjhbmWIkS9yLu6gov4RzJ66UJRwnbiz05extrZuZIoW+RE0gyYeoMgcHhwpn0dQEPj4++g4BdamG9JxisgrK6nmoUGFvaYyrtRnGUv9A3AWKopB5IU/XnZKWmM0/R++ZmBni1fBa60aoI5a2UuhL1CySfAhxl5RqtGT8o1YHgK25Ma42ZpgZy+wAcWfURaWcj8vSJRz5V8sX+nLwsMQntKx1w62BLYbSuiZqMEk+hLhDGq3C5bxiLuUWo72WdFiZGuFma4aFibzFxO3LSsvXJRsXT19Fq/m7ecPI2ADPYHtd64YU+hK1ifxlFOIO5BeXknKlgJJr02bNjQ1xszXDytRIZg2I21KYp+bU/nROxqSSeT6v3D4bJzN8wv9R6Eta1EQtJcmHELdBURQu5RWTnl2MgoKJkQFuNmbY3ge1OkT102i0pBy/QtzeVJKOXta1cBgYqvAIsNMNFrVztZDfL3FfkORDiCoq1Wg5n1Wom8ViZ2FCPTtzDGUGgaiizIt5xO1NJf5AOoU5fy+Y6OxtTUhbdwJaumJmKVNhxf1Hko9qoigKw4YN4/vvvycrK4s///yTJk2aVMu1t2/fTqdOncjKysLOzq5arnm/yi8u5dyVAtQaLSqVCg9bMxwspUiYqLyi/BJOH0wnLia1XA0Oc2tjAlu7ERLhjmM9Kz1GKMS9J8lHNdm0aRPLly9n+/bt1K9fHycnp3tyncjISJo0acKCBQt029q2bUtqaiq2trb35Jp1gaIoXM5Tk5ZdhIKCqZEB3g4WmMuAUlEJWq3CuZNXiItJ5eyRy2hKy8YIGRio8Al3JKStO95hjjJDRdQZ8pezmiQmJuLu7k7btm0r3K9WqzExMbkn1zYxMcHNze2enLsmURQFjUajW2TvbinVarmQVUh2YVk3i625MZ725hgaGKDRaFCpVBgY3P0PjXv5OyGqx9X0Ak7GpBK/L63c1FjHepYER7gT2MoNCxt5jUXdU+vTbEVRUKvVevlX2TX5Bg0axJgxY0hJSUGlUuHr60tkZCSjR49m3LhxODk5ERUVBcC8efMIDw/H0tISLy8vRo4cSV5e+RHve/bsITIyEgsLC+zt7YmKiiIrK4tBgwaxY8cOFi5ciEqlQqVSkZSUxPbt21GpVFy9elV3jh9++IHQ0FBMTU3x9fVl7ty55a7h6+vLu+++y3PPPYe1tTXe3t589tlnlXq+SUlJqFQq1q5dS6dOnbCwsKBx48bExMSUO2737t20b98ec3NzvLy8GDt2LPn5fy909dVXX9GiRQusra1xc3PjqaeeIiMjQ7f/+vPauHEjzZs3x9TUlN27d98yvp9//pmWLVtiZmaGk5MTvXv31u3Lysri2Wefxd7eHgsLCx6K6sZv+2LJLixBpVKx45fvaOxfj/W//ELDhg0xNTUlJSWlUvfr3Llz9OvXDzs7OxwcHHjsscdISkrS7R80aBC9evXinXfewcPDg6CgIAAWL15MQEAAZmZmuLq68sQTT1TqdRD6oS4s5fiuC/ww+xCr3trH4U3J5F8txtTSiPBIT/pNbkn/N1rRpKu3JB6izqr1LR8lJSX/uc7IvTZ58uRKfTNduHAh/v7+fPbZZxw8eBBDQ0P69u3LihUrGDFiBHv27NEda2BgwAcffICfnx9nzpxh5MiRTJgwgcWLFwNw5MgRunTpwnPPPcfChQsxMjJi27ZtaDQaFi5cyKlTpwgLC2P69OlA2dLu//yAAzh06BD9+vVj6tSp9O/fn7179zJy5EgcHR0ZNGiQ7ri5c+cyY8YMJk+ezPfff8+IESPo2LGj7kPxVl5//XXmzJlDQEAAr7/+OgMGDCAhIQEjIyMSExPp1q0bb7/9Nl988QWXLl1i9OjRjB49mmXLlgFlr+2MGTMICgoiIyOD8ePHM2jQIDZs2FDuOq+99hpz5syhfv362Nvb3zSm9evX07t3b15//XW+/PJL1Gp1ufMNGjSI06dP89NPP6E1Nuf1SZMYFv0Ev+w4gL+bLYfMjCkoKOC9995j6dKlODo64uLicsv7VVJSQlRUFBEREezatQsjIyPefvttunXrxl9//aX7Pdq6dSs2NjZs2bIFgD/++IOxY8fy1Vdf0bZtW65cucKuXbsqdf9F9VG0CudPZREXk8qZw5coLSnrVlGpwDvUkeAId/waOWFoXOu/7wlxV6iUyn59ryY3W5K3ouW61Wp1jU8+ABYsWMCCBQt0iUBkZCQ5OTkcPnz4po/7/vvvGT58OJcvXwbgqaeeIiUl5T+/4Vc05uPfA06jo6O5dOkSv/76q+6YCRMmsH79eo4fPw6UtXy0b9+er776CihrYXJzc2PatGkMHz78pjEnJSXh5+fH0qVLGTJkCAAnTpwgNDSUkydPEhwczNChQzE0NOTTTz/VPW737t107NiR/Pz8Cpdj/+OPP2jZsiW5ublYWVnpnte6det47LHHbhrTdW3btqV+/fqsXLnyhn2nT58mMDCQnbt24R3SlOzCEq5mXSGqdRjLli3jyf79Wb58OYMHD+bIkSM0btxY99hb3a+VK1fy9ttvc/LkSd3gVLVajZ2dHevWreOhhx5i0KBBbNq0iZSUFN3v1dq1axk8eDDnz5/H2tq6Us9Rnyp6j97Psi8VErcvlfiYNHKvFOm227tZEBzhTlAbNyltLuqMm31+/1utb/kwNjZm8uTJerv2nWjevPkN23777TdmzpxJXFwcOTk5lJaWUlRUREFBARYWFhw5coS+ffve0XVPnjx5w4d1u3btWLBgARqNBkPDssJFjRo10u1XqVS4ubmV6/a4lX8+3t3dHYCMjAyCg4OJjY3lr7/+YtWqVbpjFEVBq9Vy9uxZQkJCOHToEFOnTiU2NpasrCy02rJvkykpKTRs2FD3uBYtWlQ6piNHjvD8889XuO/kyZMYGRnh6BdW1s2CihDfegQHBXEqPl53nImJSbnnVtHz/ff9io2NJSEh4YYEoqioiMTERN3P4eHh5RLaBx98EB8fH+rXr0+3bt3o1q0bvXv3xsLCotLPWdxd6qJSzvx5iZN7U7l4+qpuu4m5EQEtXAhu646rr43MgBLiJmp98qFSqWrtoDxLS8tyPyclJdGjRw9GjBjBO++8g4ODA7t372bIkCGo1WosLCyqddXYfydXKpVKlwBU9fHX/xBff3xeXh7Dhg1j7NixNzzO29ub/Px8oqKiiIqKYtWqVTg7O5OSkkJUVBRqtbrc8f++jzfzX/dPURRd3Y7iUg1mJsZ4O1hgaXrjW8Tc3LzCD5ab3a+8vDyaN29eLtm6ztnZ+T+fi7W1NYcPH2b79u38+uuvTJkyhalTp3Lw4EGZNl2NFEUhNSGbkzGpJB7KoKRYU7ZDBV7B9gS3dad+Y2eMTKTiqBCVUeuTj/vJoUOH0Gq1zJ07Vzd74ttvvy13TKNGjdi6dSvTpk2r8BwmJiZoNJqbXickJKTcOBMoG8QaGBioa/W415o1a8aJEydo0KBBhfuPHj1KZmYms2bNwsvLCyjrdrlT1+/f4MGDdds0WoULVwuxdfeltLSUM8eP8FhUJ4wMDcjMzCQ+Pr5cS8vtaNasGd988w0uLi63bI78NyMjI7p27UrXrl156623sLOz4/fff+fxxx+/o5jEreVeKSJ+XyonY9LIuVSo227rbK7rVrF2uP+7l4S42yT5qEEaNGhASUkJixYtomfPnuzZs4dPPvmk3DGTJk0iPDyckSNHMnz4cExMTNi2bRt9+/bFyckJX19f9u/fT1JSElZWVjg4ONxwnZdffpmWLVsyY8YM+vfvT0xMDB9++KFuUGt1mDhxIm3atGH06NEMHToUS0tLTpw4wZYtW/jwww/x9vbGxMSERYsWMXz4cI4dO8aMGTPu+LpvvfUWXbp0wd/fnyeffJL8wmLWrP0fzw4fi69fA7o90oMpr47F1eZTrK2tee2116hXr16lx5T8l+joaN5//30ee+wxpk+fjqenJ8nJyaxdu5YJEybg6elZ4eN++eUXzpw5Q4cOHbC3t2fDhg1otdpKD/oVVVeq1nDmSFm3yvn4LLg2Ks7Y1JAGzV0IjnDHvYGtdKsIcQdk6HUN0rhxY+bNm8d7771HWFgYq1atYubMmeWOCQwM5NdffyU2NpZWrVoRERHBTz/9pKtt8corr2BoaEjDhg11XRX/1qxZM7799lvWrFlDWFgYU6ZMYfr06eVmutxrjRo1YseOHZw6dYr27dvTtGlTpkyZgoeHB1DWFbF8+XK+++47GjZsyKxZs5gzZ84dXzcyMpLvvvuO//3vfzRp0oSHHuzKkcN/YGxoQH1nS1Z/9SXNmzenR48eREREoCgKGzZsuOPxPRYWFuzcuRNvb28ef/xxQkJCGDJkCEVFRTdtCbGzs2Pt2rV07tyZkJAQPvnkE77++mtCQ0PvKB5RnqIopJ3JZtuqOJZN2M2WL05wPq4s8agXaEeXgSEMeq8dnZ8NwSPAThIPIe5QrZ/tIkRVaa91s2QVlI0dsTI1wsvBAmOpLnnHatt7NP9qMfH704iLSSUrrUC33drBjKAIN4LbuGPrLEvVC1EZdWq2ixBVUVSiIeVKAUUlGlSAi40ZLtam8k22DtGUaDn712XiYlJJOZ7J9a9fRsYG1G/mTEiEO/UC7VHJQoFC3DOSfIgqe/fdd/+ztkr79u3ZuHFjNUf0t9DQUJKTkyvcN++Dj2gb1QutomBkYIC3gzlWZrJiaF2gKAqXz+Vxcm8qpw6mUZxfqtvnVt+WkLbuNGjugom5/EkUojrIO01U2fDhw+nXr1+F+6pzKnBFNmzYQElJSbltWq1Cem4RRpZ2aBVFulnqkIIcNacOlHWrZF74u3S/pZ0pQW3KVpC1c5WaKUJUN0k+RJU5ODhUOIumJvDx8Sn3c/G1bhZbi7Lpxy7WZrjaSDfL/Uyj0ZJ8NJO4mFSSj2ai1Zb1qxgaGeDXxImQCHc8QxwwkG4VIfSmViYfNWyMrKihrhaouZBViOZaN4uXgznW0s1yT+nzvZl54Vq3yoE0CnP/bv1y8bEu61Zp4YqZpbz+QtQEtSr5uD7dsaCgQO/N+6Lm0ioKqdlFZOaVLWFuaWKEt4MFxkbSzXKvFRSUzRi506nJlVWUX8KpA+nExaRyKSVXt93cxoSg1m4ER7jh6GFVLbEIISqvViUfhoaG2NnZ6dbLsLCwkOZzUY66VMPF7CKKS8q6WewtTXC2MkRTqkZTeosHi9umKAoFBQVkZGRgZ2d3TyvlajVaUk5cIS4mjbN/XUJbWtbaYmCowrdRWbeKV6gDhjKmR4gaq1YlHwBubm4AVVrgTNQNhSUasvLVaBUwVJUlHvmFhuRf1ndkdYednZ3uPXq3ZaXlExeTSty+NAqy/17fx8nLiuAIdwJbuWJuVTvXeRKirql1yYdKpcLd3R0XF5cbZjWIuqlEo2XpzjN8f/g8ACHuNrzZoyGuNjW/yNX9xNjY+K63eBQXlpLwRzon96aSfjZHt93M0pjA1q4ER7jj7GV9kzMIIWqiWpd8XGdoaFhti6CJmuvC1UJGr/6TP1OuAjD0AT8mdAvGRMZ31FqKVuF8fBYn96Zy5sglNCVlKwOrDFT4hDkSHOGGb7gThvIaC1Fr1drkQ4htcRm89O0RrhaUYG1mxJy+jYkKvTdN/uLey75UQFxMWU2OvKxi3XZ7d0tCItwJbO2Kpa2pHiMUQtwtknyIWqdUo2XullN8vD0RgPB6tnz0VDO8HaVYVG2jLiol8XAGJ/emkpqQrdtuamFEQAtXgtu64+JjLQPLhbjPSPIhapW07CLGfv0nB5KuADAwwofJj4RgaiRdcLWFolW4mHCVuL2pJPx5idLisplJqMA7xIHgtu74NXbCyFheUyHuV5J8iFpj56lLvPTNETLz1ViZGvFen0Y80shd32GJSsrJLCR+X1m3Ss7lIt12WxdzQtq6E9TaDSt7GSQsRF0gyYeo8TRahYW/nWLRtgQUBRq62/BRdDP8nCz1HZq4hRK1hjN/XiIuJpXz8VlwrQCqsZkhAc1dCG7rgVt9G+lWEaKOkeRD1GgZuUW8+PURYs5kAjCglTdv9WyImTTJ11iKopB2Joe4vRc5fSiDkiKNbl+9IHtC2rpTv4kzxqbyGgpRV0nyIWqsvYmXGfv1ES7nFWNhYsi7vcPp1bSevsMS/yEvq5j4/anExaRxNb1At93a0YzgCHeC27hh4yTLIgghJPkQNZBWq/DRtgTm/3YKrQKBrlYsjm5OAxdZo6OmKS3RcDb2MnExqZw7cYXr68oZmRjg38yFkAh3PALsUMkKskKIf5DkQ9QomXnFjPvmCLtOl9VE79vck+mPhWFuIk30NYWiKFxKyeXk3lROH0ynuODvRXPcG9gSHOFOg+YumJjJnxchRMXkr4OoMQ4mXWHM6j9JyynCzNiAGY+F0beFl77DEtcU5KiJ3182W+XKxXzddit7U4LauBEc4Y6di9RaEULcmiQfQu+0WoVPd55hzq/xaLQK/s6WLI5uTpCbrNmhb5pSLclHMzkZk0rysUwUbVm/iqGxAfWbOBMS4U69YHsMpFtFCFEFknwIvcrKV/Pyd7H8Hle2SvFjTTx4t3c4lqbyq6lPl8+XdaucOpBOUd7fCzi6+tkQHOFOQAsXTC2M9RihEKI2k7/wQm8Op2QxetVhLmYXYWJkwNSeoQxo5SU1H/SkME/NqQPpxMWkcvlcnm67hY1JWbdKG3ccPKS2ihDizknyIaqdoih8vvssszbGUapV8HW04KPoZoR62Oo7tDpHq9GScvwKcTGpnP3rMlpNWbeKgaEKv8ZOBEe4493QAQNDWUFWCHH3SPIhqlV2YQkTvo9l8/F0AB4Jd2dWn3CszaQJvzpduZhPXEwq8fvTKMhR67Y7e1sTHOFGYEs3zKzkNRFC3BuSfIhq89f5q4xafZhzVwoxMTTgjR4hPNPGR7pZqklxQQmn/yhbQTYjKUe33czKmKBWbgS3dcfJU2qpCCHuvSolHzNnzmTt2rXExcVhbm5O27Ztee+99wgKCtIdU1RUxMsvv8yaNWsoLi4mKiqKxYsX4+rqeteDF7WDoih8tS+Zt385iVqjxcvBnI+eakYjTzt9h3bf02oVzsddIW5vKmeOXEZTqgVAZaDCJ8yRkLbu+IQ5Ymgk3SpCiOpTpeRjx44djBo1ipYtW1JaWsrkyZN56KGHOHHiBJaWZQPRXnrpJdavX893332Hra0to0eP5vHHH2fPnj335AmImi23qITXfjjK+qOpADzU0JX3+zbG1lya9O+lq+kFum6VvKxi3XYHD0tC2roT2MoNCxsTPUYohKjLVIpyvSBy1V26dAkXFxd27NhBhw4dyM7OxtnZmdWrV/PEE08AEBcXR0hICDExMbRp0+aW58zJycHW1pbs7GxsbGxuNzRRAxy/mM2oVYdJyizAyEDFa92DGfKAn3Sz3CPqolISDmUQtzeV1MRs3XZTCyMCW7oS3NYdZ29ruf9CiHuiKp/fdzTmIzu77A+cg4MDAIcOHaKkpISuXbvqjgkODsbb2/s/k4/i4mKKi//+ZpaTk3PDMaJ2URSFrw+cY+rPx1GXavGwNePD6GY087bXd2j3HUWrcOH0VeL2ppL4Zwal6mvdKirwaljWreLbyBEjWQVYCFGD3HbyodVqGTduHO3atSMsLAyAtLQ0TExMsLOzK3esq6sraWlpFZ5n5syZTJs27XbDEDVMfnEpr/94lHVHLgLQOdiFuX0bY28pTfx3U87lQuJiUonbl0ZuZpFuu52rBSFt3Qlq7YalnakeIxRCiP9228nHqFGjOHbsGLt3776jACZNmsT48eN1P+fk5ODlJet51EbxabmMXHWIxEv5GBqoeDUqiBfa15fS23dJSbGGxD8ziItJ5UL8Vd12EzNDGrR0JSTCHVc/G+lWEULUeLeVfIwePZpffvmFnTt34unpqdvu5uaGWq3m6tWr5Vo/0tPTcXNzq/BcpqammJrKN7Ta7rs/zvHmT8coKtHiamPKh081o6Wvg77DqvUURSE1MZu4mFQSDmVQUqQp26ECzyB7Qtq649fEGWNZ9VcIUYtUKflQFIUxY8bw448/sn37dvz8/Mrtb968OcbGxmzdupU+ffoAEB8fT0pKChEREXcvalFjFKo1vPnTMb4/dB6A9gFOLOjfBEcrSSjvRO6VIt0KstkZhbrtNs7mhES4EdTGHWsHMz1GKIQQt69KyceoUaNYvXo1P/30E9bW1rpxHLa2tpibm2Nra8uQIUMYP348Dg4O2NjYMGbMGCIiIio100XULgkZeYxadZj49FwMVPBS10BGdWog3Sy3qVSt4WzsZU7GpHLu5BW4Ng/NyNSQBs1dCIlww72BnXSrCCFqvSpNtf2vP3rLli1j0KBBwN9Fxr7++utyRcb+q9vl32Sqbe2w7s8LTP7xKAVqDU5WpnwwoAlt/Z30HVatoygKGUm5nIxJ5fTBdNSFpbp9HgF2BEe449/MGRMzKUYshKjZqvL5fUd1Pu4FST5qtqISDdN+PsHXB1IAiKjvyMIBTXCxli6AqsjPLr7WrZJGVmq+bruVgynBbdwJjnDD1tlCjxEKIUTVVFudD1G3JF3OZ+Sqw5xIzUGlgjGdGvBi10AMpZulUjSlWpL+ukxcTCrJx6+gaMvyfkNjA/ybOhPc1h3PQHtUcj+FEPc5ST5Epaz/K5WJP/xFXnEpjpYmzO/fhA6BzvoOq1a4lJJLXEwqpw6kU5RfotvuVt+G4Ah3GrRwxdRc3opCiLpD/uKJmyou1fDu+pOsiEkGoKWvPYsGNMPNVrpZbqYwV82pA+mcjEkl83yebrulrQlB17pV7N0s9RihEELojyQf4j+du1LAqNWH+et8WRn94R39eeWhQIwMZQXUimg0WlKOl60gm3T0MlpNWbeKgZGK+o3LulW8QhxkNpAQos6T5ENU6Nfjabz8XSy5RaXYWRgzr19jOge76jusGikrLZ8Tuy8SfyCdwhy1bruLjzXBEe4EtHTFzFJW8RVCiOsk+RA3WHv4POO/jQWgqbcdHz7VjHp25nqOqubJySzkwM9nid+fpqvJYW5tTFBrN4Ij3HGsZ6XfAIUQooaS5EOUs/PUJSZ8/xcAT7X2ZmrPUEyMpJvlnwpz1RzamMzRnefRlpZlHb7hjjR8wAPvMEcMpVtKCCFuSpIPoXPsQjYjVh6iVKvwaGMP3n4sTMYn/IO6qJTYref4c0uKbo2VekH2RPT2x9VXatIIIURlSfIhAEjJLGDQsgPkqzW09Xfk/b6NJPG4RlOq5fiui/yx4SyFuWVTZZ28rIjo7Y9XiIOUOxdCiCqS5EOQmVfMwGUHuJynJsTdhk+faY6pkaySqmgVTh1M58DPZ8i5XASArbM5rR+rT4NmLlIMTAghbpMkH3VcgbqU51b8wdnL+dSzM2f54JZYm9XtmRmKopBy/Aox6xJ1NTosbExo+YgvIQ94yJgOIYS4Q5J81GGlGi2jV/9J7Lmr2FkYs+K5Vrja1O3iYWlnson5MZGLp68CYGJmSNMoHxp39sLYVFqDhBDibpDko45SFIXXfzzG73EZmBoZ8PnAFjRwqbtTQ6+k5rNvXSJnYy8DYGhkQHhkPZp388XMqm63BAkhxN0myUcdNf+303zzxzkMVLBoQFOa+zjoOyS9yL1SxIFfzhIfk4qigEoFQRHutOrhh7VD3W4FEkKIe0WSjzpo1f5kPth6GoAZvcJ4KNRNzxFVv6K8Eg5tSuLo9gtoSrUA+DV2os1j/jh4yJorQghxL0nyUcdsOZHOm+uOATC2cwOiW/voOaLqVVKsIfb3c/y5ORn1tVodHgF2RPT2x62+rZ6jE0KIukGSjzrkUHIWY74+jFaBfi08eenBQH2HVG00Gi0nd1/k4PokCq6tv+LoaUVEL3+8Q6VWhxBCVCdJPuqIhIw8hqw4SFGJlk5BzrzTO7xOfOAqWoWEwxns/+kM2ZcKAbBxMqNVz/oEtnSVWh1CCKEHknzUARk5RQz84gBXC0po7GXHR9HNML7Pa1UoisK5k1fYt+4Ml1JygbJF31o87Edoew8MZb0aIYTQG0k+7nO5RSUMXHaQC1cL8XW04IuBLbAwub9f9vSkHGJ+TORCfBYAxmaGNH3Qm8ZdvDAxu7+fuxBC1Abyl/g+pi7VMnzlIU6m5uBkZcKXz7XG0cpU32HdM1lp+ez/3xkSD18CwMBIRXgHT5p398Hc2kTP0QkhhLhOko/7lFar8Or3sexJyMTSxJBlg1rh7Wih77DuibysYg6uP8vJvakoWgVUENTajVY9/LBxMtd3eEIIIf5Fko/71KxNcfx05CJGBio+fro54Z733zTSovwSDm9O5q9t59GUlNXq8G3kRJvH6uNYr+5WaxVCiJpOko/70Oe7z/LZzjMAvNenER0CnfUc0d1VotZwdNt5Dm9OprigFAB3f1va9PbHo4GdfoMTQghxS5J83Gd+jr3IjF9OADChWxB9mnvqOaK7R6vRcnJvKgd/OUt+dlmtDgcPSyJ6+eMT7lgnpg4LIcT9QJKP+8jexMu8/G0sAAMjfBjR0V/PEd0diqKQePgS+/93hqvpBQBYO5jR6lE/Alu5YSC1OoQQolaR5OM+cTI1h2FfHkKt0dI9zI0pPUPvi5aA83FXiPkxkYzkslodZlbGtOjuS1iHehgaS60OIYSojST5uA9cuFrIoGUHyC0upZWvA/P7N8GwlrcGXErJJebHBM6dLKvVYWRqSJOuXjTt6o2JufzaCiFEbSZ/xWu5qwVqBn5xgPScYgJdrVjybAvMjA31HdZtu5pRwP7/nSHhjwwADAxVhHaoR4vuvljYSK0OIYS4H0jyUYsVlWgYuuIPEjLycLMxY/ngVthaGOs7rNuSn13MwfVJnNx9Ee21Wh2BLV1p1bM+ts5Sq0MIIe4nknzUUhqtwtiv/+SP5CyszYxY8VwrPOxq34d0cWEpf25OJvb3c5Sqy2p1eIc6EtG7Pk6e1nqOTgghxL0gyUctpCgKU/93nF9PpGNiaMCSZ1sQ5Fa7PqhLSzQc3X6BQ5uSKM4vq9Xh6mdDRG9/6gXa6zk6IYQQ95IkH7XQ4u2JfLUvGZUK5vdvQpv6jvoOqdK0Gi1x+9I4+MtZ8rKKAbB3s6BNL3/8GjvdFzN0hBBC3JwkH7XMd3+c4/3N8QBM6dGQRxq56zmiylEUhbNHLrPvp0Sy0spqdVjZm9Kqpx9Brd0wMJRps0IIUVdI8lGLbIvP4LW1RwEY1rE+g9v56TmiyrlwKouYHxNJP5sDgKmlEc27+RIeWQ+jWjwzRwghxO2R5KOWiD13lVGrDqPRKvRuWo+JUcH6DumWLp/PJebHM6QczwTAyMSAxl28aPqQD6ZSq0MIIeos+QSoBZIu5/Pc8oMUqDW0D3DivT6NanRJ8exLhRz4+QynDqaDAgYGKho+4EGLR3yxtDXVd3hCCCH0TJKPGu5yXjEDlx0gM19NqIcNHz/dHBOjmjk+oiBHzR8bkji+6wJajQJAgxYutH60PnYuFnqOTgghRE0hyUcNll9cynPLD5KcWYCXgznLBrfEyrTmvWTqwlL+3JLCka3nKC3WAODV0IGIXv44e9euKcBCCCHuvZr3SSYAKNFoGbnqMH+dz8bewpgVg1vhYm2m77DK0ZRoObbzAn9sTKIorwQAFx9rInr74xnsoOfohBBC1FSSfNRAiqIwae1Rdpy6hJmxAV8Makl9Zyt9h6Wj1SqcOpDGgf+dJfdKEQB2rha0eaw+9Zs6S60OIYQQNyXJRw0099dTfH/oPIYGKj56qhlNvWtGxU9FUUg6msm+dYlcuZgPgKWtCS17+BHS1l1qdQghhKgUST5qmK/2JfPhtgQA3ukVRpcQVz1HVOZiwlX2/ZhIamI2AKYWRjSL8iG8kyfGJlKrQwghROVJ8lGDbDqWxpSfjgEwrmsAT7by1nNEkHkhj33rEkk6Wlarw9DYgMadPWn6kA9mlrVzBV0hhBD6JclHDfFH0hVeXPMnigIDWnnxYpcAvcaTk1nIgZ/PEr8/DRRQGagIaedOy4f9sLKXWh1CCCFunyQfNcDp9FyGrPiD4lItXUNcmPFYmF4HbcbFpLJ9dTyakrIl7v2bOdP60frYu1nqLSYhhBD3D0k+9Cwtu4iBXxwgu7CEpt52LBrQDCM9DdzUlGrZ/d1pju24AIBHgB1t+zTA1ddGL/EIIYS4P0nyoUc5RSUMWnaAi9lF1Hey5POBLTHX0+DN/KvFbPrsGGlnskEFrXr40aK7L6oaXMZdCCFE7STJh54Ul2p44cs/iEvLxdnalBXPtcLB0kQvsaQmXGXTZ8coyFFjYm7Eg881xDfcSS+xCCGEuP9J8qEHWq3Cy9/Gsu/MFaxMjVg2qCVeDtW/9omiKBzbcYHd355Gq1Vw8LCk+/BwWYdFCCHEPSXJhx68s+Ekv/yVirGhik+ebk5YPdtqj6FUrWHH6nji9qUB0KC5C52eCcbETH4lhBBC3FvySVPNluw8w+e7zwIwp29jHgio/u6NnMxCNn16jEspuahUEPF4A5p09ZKy6EIIIaqFJB/V6KcjF3hnw0kAJj8czGNN6lV7DOdOXuHXpccpyi/BzMqYqKGhsgicEEKIaiXJRzXZk3CZV76LBWBwO1+eb1+/Wq+vKAp//prCvnWJKErZ6rPdhoVj7VCzVsoVQghx/5Pkoxocv5jNsK8OUaJReKSRO28+0rBauzjURaX8/mUciYczAAhu607HAYEYGcuaLEIIIaqfJB/3WFp2EYOWHSSvuJQ29R2Y168xBtVYO+NqegEbPjlKVmo+BoYq2vcPJLS9h4zvEEIIoTeSfNxjM345waXcYoJcrfn0mRaYGlVfa8PZvy7z2xfHURdpsLA1ofuwcNzqV//MGiGEEOKfJPm4h/YmXGb90VQMVDC/fxNszatnFVhFq3Bg/Vn+WJ8EgHsDW6KeD8PSVhaEE0IIoX+SfNwjJRotU38+DsAzbXxo6FE966MUF5Sw5YsTJB/LBCA80pN2TzTA0Eg/68UIIYQQ/ybJxz3yZUwyp9LzcLA0YfyDQdVyzcwLeWz45Cg5lwoxNDYgMjqI4Dbu1XJtIYQQorIk+bgHLuUWs2DLKQAmRAVha3Hvu1tO/5HO71+epFStxdrBjO7Dw3H2tr7n1xVCCCGqSpKPe+C9TXHkFpfSyNOWfi287um1tBotMT8mcuS3cwB4BtsTNTQMM6vqGV8ihBBCVJUkH3fZ4ZQsvj90HoBpj4be02m1hblqNi89zoX4LACaRXnT+jH/ap3KK4QQQlSVJB93kUar8NZPZYNM+zb3pKm3/T27VkZyDhs/OUpeVjFGpoZ0HRiCfzOXe3Y9IYQQ4m6p8hSInTt30rNnTzw8ygpVrVu3rtx+RVGYMmUK7u7umJub07VrV06fPn234q3Rvv3jHEcvZGNtasSEbsH37Don915k7fuHycsqxs7Vgr4TW0jiIYQQotaocvKRn59P48aN+eijjyrcP3v2bD744AM++eQT9u/fj6WlJVFRURQVFd1xsDXZ1QI1szfFATDuwUCcre9+TQ1NqZbtq+P5/cs4NKVafBs58cRrLXDwsLzr1xJCCCHulSp3u3Tv3p3u3btXuE9RFBYsWMAbb7zBY489BsCXX36Jq6sr69at48knn7yzaGuweVtOkVVQQqCrFc9G+Nz18+dfLWbTZ0dJO5MDKmjd04/m3XxRyfgOIYQQtcxdHfNx9uxZ0tLS6Nq1q26bra0trVu3JiYmpsLko7i4mOLiYt3POTk5dzOkanHiYg4r9yUDMPXRUIwN725Br4sJV9n02TEKc9SYWhjRdXBDfMOd7uo1hBBCiOpyV5OPtLQ0AFxdXcttd3V11e37t5kzZzJt2rS7GUa1UhSFqf87jlaBRxq509b/7iUFiqJwdPsF9nx3Gq1WwbGeJd2GhWPnYnHXriGEEEJUN73X3J40aRLZ2dm6f+fOndN3SFXyv9iLHEi6grmxIa8/HHLXzluq1rB1+Ul2fXMKrVYhoIULfSa0kMRDCCFErXdXWz7c3NwASE9Px93977Le6enpNGnSpMLHmJqaYmpaOxc8yysu5d0NJwEY1ckfDzvzu3LenMuFbPz0KJfP5aEyUNH2cX8ad/FCpZLxHUIIIWq/u9ry4efnh5ubG1u3btVty8nJYf/+/URERNzNS9UIi34/TXpOMT6OFgxtX/+unPPciSt8O/Mgl8/lYW5tzKMvNqFJV29JPIQQQtw3qtzykZeXR0JCgu7ns2fPcuTIERwcHPD29mbcuHG8/fbbBAQE4Ofnx5tvvomHhwe9evW6m3HrXeKlPL7YfRaAKT0aYmZseEfnUxSFP39NYd+6RBQFXHys6TYsHGsHs7sRrhBCCFFjVDn5+OOPP+jUqZPu5/HjxwMwcOBAli9fzoQJE8jPz+eFF17g6tWrPPDAA2zatAkzs/vnQ1RRFKb9fIISjULnYBe6hLje+kE3oS4q5fcVJ0n88xIAIe3c6fBkIEZ3mNAIIYQQNZFKURRF30H8U05ODra2tmRnZ2NjY6PvcCr06/E0XvjqECaGBvz6Ugd8nW6/yNfV9AI2fHKUrNR8DAxVdHgykIYPeEg3ixBCiFqlKp/fsrZLFRWVaJix/gQAQ9v73VHicTb2Er8tO4G6SIOlrQndhoXjVt/2boUqhBBC1EiSfFTRpzvOcO5KIe62Zozu3OC2zqFoFQ78cpY/NiQB4N7Alqjnw7C0rZ2zfoQQQoiqkOSjCs5dKWDx9rLBtpMfDsHCpOq3ryi/hN+WnSD5WCYAjTp50vaJBhje5aqoQgghRE0lyUcVvLP+JMWlWtrUd6BHI/dbP+BfMi/kseGTo+RcKsTQ2IBOTwcT1NrtHkQqhBBC1FySfFTSrtOX2HQ8DUMDFVMfDa3ygNDTB9P5/auTlKq1WDua0X1YOM7e1vcoWiGEEKLmkuSjEtSlWqb+7zgAz7TxIdit8rNwtFqFvWsTiP2trGy8V0MHHnouFDMr43sSqxBCCFHTSfJRCd8fOk/ipXwcLU146cHAKj12z3en+WvbeQCadfOh9aP1MTCQabRCCCHqLkk+bkFRFFbsTQJgRKQ/tuaVb7E4tvOCLvHoOrihjO8QQgghqAGr2tZ0B85eIT49F3NjQ/q28Kr0487HXWHnmlMAtH6sviQeQgghxDWSfNzClzHJAPRq6lHpVo+r6QVs+uwYilYhsLUrzbv53MsQhRBCiFpFko+bSM8pYvPxNACeaeNbqccU5Zfwy0exFBeU4lbfhk5PB0updCGEEOIfJPm4idX7UyjVKrT0taehx61nuGg0Wjb/v717j46quvsG/j0zmZncSELIHZJACAS5KgghIMjbpARQvHaVCo9QSrEqWFxYFFBB6AUrvdBFKaWPFvraPqBtRXwp8IpoImKMggQIl0gwgFxCICGZhNzn/J4/JjlmMpMLMJlJcr6ftWbNzN777LPPb53J/uVcZv47F2VFVQgMtWDqk8P543BERETNMPloQZ1NxdbPzwMAHk/p22Z7EcH+t07jwqnrMFmMuO/pEfAPMnfwKImIiLoeJh8t+P/HC1FUXoOwQAumDGn7YtFjGRdw/OOLgAJ8d94QhPUJ9MAoiYiIuh4mHy1ovNB05phYmH1aD9O548X45O3TAIBxDyei3/CwDh8fERFRV8Xkw4VThVZ8XlACo0HBzOTW71QpuXQD7/93LkSAQeOiced32387LhERkR4x+XDhzYajHulDIhEV7Ntiu6qKWvznT0dQW21DdGIwJs1M4p0tREREbWDy0Yy1ug7bD18E0PrttbZ6FXs25cJ6rRpBYb6Y+uQwGNs4PUNERERMPpz8+9AFVNbaMDAyEGMTQl22ERFk/k8eLp0uhdnXfmeLXyDvbCEiImoPJh9NiAje/Mx+yuXxsfEtnkLJ+eAbnPz0MhQFmPzjoQiNCfDkMImIiLo0Jh9NHMgvxtdXbyDQ4oOHR/Zx2ebs0Wv49J18AMD47w1A/NBenhwiERFRl8fko4n/m3UWAPDIyN4ItDj/4O+1CxV4/43jgABDJsRg+HdcJyhERETUMiYfDS6WVuGDk1cA2E+5NFdptd/ZUldjQ++knpjwg4G8s4WIiOgWMPlo8D/Z56AKMK5/LwyI7OFQZ6tTsfvPx1BRUoPgcD9MeWIojEaGjoiI6FZwBgWgqoK3D14AAMxOcT7qcXD3WRR+XQaLvw/uWzAcvgEmTw+RiIio22DyAeD4JSuultcgwGzEdwZFOtSVFlXiy/ftd8D8n/8ahJ5RvLOFiIjodjD5AJD5VREAYHximNPvuBz452mo9YLYwaFIuCvcG8MjIiLqVph8APj4q2sAgIkDHZOLs8eu4eyxYhgMCiZ8fwAvMCUiInID3Scf1uo6HDp/HQBwb5Pko77Ohv0Nv1Q7IjWWp1uIiIjcRPfJx6f512BTBQnhAYgN9dfKcz74BtarVfAPNuPu+/p6b4BERETdjO6Tj8yvrgJwPOpRXlKNQ7vPAgDGPZIIs6/zF44RERHRrdF18iEiyMyzJx9Nr/f49N/5qK9VEZ0YjIFjIltanIiIiG6BrpOPM1crcKmsGmYfA8b2s/9Gy4VTJcg/VARFASbyW0yJiIjcTtfJR0bDUY/kfqHwMxths6n4+C37RaZDJ/ZGWJ8erS1OREREt0DXyUfz6z1yMy7i+uUb8A00YcwDCd4cGhERUbel2+SjqtaG7IISAMCkpHDcKKvB5//vawDA2AcT+BXqREREHUS3yUd2QTFq61XEBPuif3ggPnv3DGqrbYiI74E7xsd4e3hERETdlm6TD+2US1I4bpTWIi/7CgBgwoyBMBh4kSkREVFHYfIxMBynsi5BVEF0YjCiEoK9PDIiIqLuTZfJxzcllfj66g0YDQrGJvTCiU8uAwCGTOjt5ZERERF1f7pMPvaftv+Q3Mi4EJQVlKO8pBoWfx/056/WEhERdThdJh/HLpYBAO7uG4oT+y8BAJKSo+BjNnpzWERERLqgy+Tj5GUrAGBgkD/OHrUfBRl8D+9wISIi8gTdJR82VZBXWA4ACLhUDVUVRCUEo1fvQC+PjIiISB90l3ycLb6BqjobfH0MKDxsP+oxZAKPehAREXmK7pKPxlMuKYEBKC+uhtnPB/1HRXh5VERERPqh2+RjcJV905OSo2DihaZEREQeo8Pkoxz+KuBfVAuAp1yIiIg8TYfJhxWD6oyAAJH9gnihKRERkYfpKvmoqrXhclk1+tbZT7P0v4vXehAREXmarpKPC9crYRAg1mbf7D6Denp5RERERPqjq+Tjm+uViLIZYBYFvgEmhPXhKRciIiJP01Xycb64EvH19k3unRQCxaB4eURERET6o6vk45vrVYivazzlEurl0RAREemTvpKPazcQ3Xi9RxKv9yAiIvIGXSUflcXV8IECg9mA4HA/bw+HiIhIl3SVfOB6HQAgINKP13sQERF5iW6SDxGBpaIeABDWp4eXR0NERKRfukk+qups6FlvP9oRHc/kg4iIyFt8vD0ATymrqkOwak8+wqMDvDwaItIrUQWwqZA6FVIvkHrV4YH6hvI6FWJTGxbSlm72vmnHzZu23bbF/rRicSq72T6ajqX5Ii321Y42cjPb5dSX88JORc0LbmJ9rrfz5sfUvI20a0xttGl4b+hhQvDkvi468AzdJB/Xb9RqyUdQGC82JdKjm5r4W6qrVx3qobVp1l+dCtic+4LN1YxB5Fk+4X5MPjyht58FRtiTj4AQi5dHQ6Q/bU38LU3W2gRfp0Ka1bc68bso73QTvwIoPgYoJgNgtD8rPoq9zMcAGBUoiuK0jP3ZxUXzzYtctHEqaqn/drRRXJS5pb9b3LbmbbTYuRxD+8bksr9bGZPSrEBxbtJam/au09UQXG2bwd/koqHn6Cb5qK2w3+niF2SG0aibS12IANgnfqf/3tsxWTtM/K0dKdCSg6Z9OS7T1SZ+xccAaK8Vra1jeWv1TfoyGaAYDYDJcRkYXCQXRDqgm+TDz3oRYwv/AfWaL4B7vD0c0pEOm/gbjwS0eBrg2+U69cTffAJvPvGbDFCMijaxO03+JgWKkRM/UVfSYcnHhg0bsHbtWhQWFmLEiBFYv349xowZ01Gra5MlpAf8T30KmEwQVYVi4NGPpuyTmA1Sq0JqbfbJTBX7xUlifxZp8l5t9r7hWZrUO7xvqR8X76E2LtdKGxd9i9qOdant6KfZup3aqC6WsUn3nfib1TtN/LdypMDISZ9Izzok+XjrrbewePFi/PnPf0ZycjLWrVuH9PR05OXlISIioiNW2Saf+gtQDIDU1aFm+UD4hhmbnAdTHF8Dzc6RtfSH0tXVye6daOzdGSFihogZqlggYoLArJU5PixQxdyk3uRU31inNqkHvHv+Tz9UKKiDotQBSj0UpQ4KGp4bXn9b3lCm1NsfqAMa36Ox/NvlXdc1WZe2HtX10GwNjxpPxIHJR7t1m1B1mw1p4cKKLqZnX2D2Dq+tXhGne3duX3JyMkaPHo0//vGPAABVVREbG4tnnnkGS5cubXVZq9WK4OBglJWVISgoyG1jqrp2Dv9e/jv4lBRBQT0Mfqr9vy8F0A6CGBQojQmF00VC9jcKDFAU+wMwaO/trxUARihQ7G2gQIERUAwwKD4NDzMMigkGNLyGDxTFBINigrHhWdHqG9578OtYBAKROqioh4it4Va7xhvu1IZbvRwf9j1ItLb216r9iEDjbXH2Qwb2Z2na1l7btEzsh020JZv2rS0nTcbUdDzSbLxO62syJhGn5e3t4dhn49il6baI1jcgEEWFKvUQ1GuxU8X+GlIPVWz212hh4idqUSc7ctagG0y/uubvZ8YDf/jArX3ezPzt9iMftbW1OHToEJYtW6aVGQwGpKWlISsry6l9TU0Namq+/VfLarW6e0gAgJzcPOTH9ARiOsMPynn0X0wd46k1IiJXjNVVeMCL63d78nHt2jXYbDZERkY6lEdGRuLUqVNO7desWYNVq1a5exhOFNUMfzGjBvW32dPN/hcirp5c9OPqi2HEZUsiIqLb4WO73bnwNtfv1bUDWLZsGRYvXqy9t1qtiI2Ndft6xn5nEsZ+Z5Lb+yUiIqKb4/bkIywsDEajEVeuXHEov3LlCqKiopzaWywWWCz80i8iIiK9cPtJcbPZjFGjRmHfvn1amaqq2LdvH1JSUty9OiIiIupiOuS0y+LFizFnzhzcfffdGDNmDNatW4cbN25g7ty5HbE6IiIi6kI6JPmYMWMGrl69ihUrVqCwsBB33nkn9uzZ43QRKhEREelPh3zPx+3oqO/5ICIioo5zM/M3vwiBiIiIPIrJBxEREXkUkw8iIiLyKCYfRERE5FFMPoiIiMijmHwQERGRRzH5ICIiIo9i8kFEREQexeSDiIiIPKpDvl79djR+4arVavXySIiIiKi9Guft9nxxeqdLPsrLywEAsbGxXh4JERER3azy8nIEBwe32qbT/baLqqq4dOkSevToAUVR3Nq31WpFbGwsvvnmG/5uTBsYq/ZjrNqPsWo/xurmMF7t11GxEhGUl5cjJiYGBkPrV3V0uiMfBoMBffr06dB1BAUFcedsJ8aq/Rir9mOs2o+xujmMV/t1RKzaOuLRiBecEhERkUcx+SAiIiKP0lXyYbFYsHLlSlgsFm8PpdNjrNqPsWo/xqr9GKubw3i1X2eIVae74JSIiIi6N10d+SAiIiLvY/JBREREHsXkg4iIiDyKyQcRERF5lG6Sjw0bNqBv377w9fVFcnIyPv/8c28PyeNeeeUVKIri8Bg0aJBWX11djQULFqBXr14IDAzEo48+iitXrjj0cf78edx3333w9/dHREQElixZgvr6ek9vitt9/PHHmD59OmJiYqAoCt59912HehHBihUrEB0dDT8/P6SlpeH06dMObUpKSjBr1iwEBQUhJCQE8+bNQ0VFhUObo0ePYsKECfD19UVsbCxee+21jt40t2srVj/84Q+d9rMpU6Y4tNFLrNasWYPRo0ejR48eiIiIwEMPPYS8vDyHNu763GVkZGDkyJGwWCxITEzEli1bOnrz3Ko9sZo0aZLTvvXkk086tNFDrDZu3Ijhw4drXxKWkpKC3bt3a/VdYp8SHdi2bZuYzWb561//KsePH5f58+dLSEiIXLlyxdtD86iVK1fKkCFD5PLly9rj6tWrWv2TTz4psbGxsm/fPjl48KCMHTtWxo0bp9XX19fL0KFDJS0tTQ4fPiy7du2SsLAwWbZsmTc2x6127dolL774orzzzjsCQLZv3+5Q/+qrr0pwcLC8++67cuTIEXnggQekX79+UlVVpbWZMmWKjBgxQj777DPZv3+/JCYmymOPPabVl5WVSWRkpMyaNUtyc3Nl69at4ufnJ5s2bfLUZrpFW7GaM2eOTJkyxWE/KykpcWijl1ilp6fL5s2bJTc3V3JycmTatGkSFxcnFRUVWht3fO6+/vpr8ff3l8WLF8uJEydk/fr1YjQaZc+ePR7d3tvRnljde++9Mn/+fId9q6ysTKvXS6zee+89+c9//iNfffWV5OXlyfLly8VkMklubq6IdI19ShfJx5gxY2TBggXae5vNJjExMbJmzRovjsrzVq5cKSNGjHBZV1paKiaTSf75z39qZSdPnhQAkpWVJSL2ScdgMEhhYaHWZuPGjRIUFCQ1NTUdOnZPaj6hqqoqUVFRsnbtWq2stLRULBaLbN26VURETpw4IQDkiy++0Nrs3r1bFEWRixcviojIn/70J+nZs6dDrF544QVJSkrq4C3qOC0lHw8++GCLy+g1ViIiRUVFAkAyMzNFxH2fu+eff16GDBnisK4ZM2ZIenp6R29Sh2keKxF78rFo0aIWl9FrrEREevbsKa+//nqX2ae6/WmX2tpaHDp0CGlpaVqZwWBAWloasrKyvDgy7zh9+jRiYmKQkJCAWbNm4fz58wCAQ4cOoa6uziFOgwYNQlxcnBanrKwsDBs2DJGRkVqb9PR0WK1WHD9+3LMb4kEFBQUoLCx0iE1wcDCSk5MdYhMSEoK7775ba5OWlgaDwYDs7GytzcSJE2E2m7U26enpyMvLw/Xr1z20NZ6RkZGBiIgIJCUl4amnnkJxcbFWp+dYlZWVAQBCQ0MBuO9zl5WV5dBHY5uu/Deueawa/eMf/0BYWBiGDh2KZcuWobKyUqvTY6xsNhu2bduGGzduICUlpcvsU53uh+Xc7dq1a7DZbA5BBoDIyEicOnXKS6PyjuTkZGzZsgVJSUm4fPkyVq1ahQkTJiA3NxeFhYUwm80ICQlxWCYyMhKFhYUAgMLCQpdxbKzrrhq3zdW2N41NRESEQ72Pjw9CQ0Md2vTr18+pj8a6nj17dsj4PW3KlCl45JFH0K9fP5w5cwbLly/H1KlTkZWVBaPRqNtYqaqKZ599FuPHj8fQoUMBwG2fu5baWK1WVFVVwc/PryM2qcO4ihUAzJw5E/Hx8YiJicHRo0fxwgsvIC8vD++88w4AfcXq2LFjSElJQXV1NQIDA7F9+3YMHjwYOTk5XWKf6vbJB31r6tSp2uvhw4cjOTkZ8fHxePvtt7vMB446vx/84Afa62HDhmH48OHo378/MjIykJqa6sWRedeCBQuQm5uLTz75xNtD6fRaitUTTzyhvR42bBiio6ORmpqKM2fOoH///p4eplclJSUhJycHZWVl+Ne//oU5c+YgMzPT28Nqt25/2iUsLAxGo9HpSt8rV64gKirKS6PqHEJCQjBw4EDk5+cjKioKtbW1KC0tdWjTNE5RUVEu49hY1101bltr+1BUVBSKiooc6uvr61FSUqL7+CUkJCAsLAz5+fkA9BmrhQsXYufOnfjoo4/Qp08frdxdn7uW2gQFBXW5fyxaipUrycnJAOCwb+klVmazGYmJiRg1ahTWrFmDESNG4A9/+EOX2ae6ffJhNpsxatQo7Nu3TytTVRX79u1DSkqKF0fmfRUVFThz5gyio6MxatQomEwmhzjl5eXh/PnzWpxSUlJw7Ngxh4lj7969CAoKwuDBgz0+fk/p168foqKiHGJjtVqRnZ3tEJvS0lIcOnRIa/Phhx9CVVXtD2RKSgo+/vhj1NXVaW327t2LpKSkLnkaob0uXLiA4uJiREdHA9BXrEQECxcuxPbt2/Hhhx86nUpy1+cuJSXFoY/GNl3pb1xbsXIlJycHABz2LT3EyhVVVVFTU9N19im3XLbayW3btk0sFots2bJFTpw4IU888YSEhIQ4XOmrB88995xkZGRIQUGBHDhwQNLS0iQsLEyKiopExH57VlxcnHz44Ydy8OBBSUlJkZSUFG35xtuzJk+eLDk5ObJnzx4JDw/vFrfalpeXy+HDh+Xw4cMCQH73u9/J4cOH5dy5cyJiv9U2JCREduzYIUePHpUHH3zQ5a22d911l2RnZ8snn3wiAwYMcLh9tLS0VCIjI+Xxxx+X3Nxc2bZtm/j7+3e520dbi1V5ebn87Gc/k6ysLCkoKJAPPvhARo4cKQMGDJDq6mqtD73E6qmnnpLg4GDJyMhwuD20srJSa+OOz13jbZFLliyRkydPyoYNG7rc7aNtxSo/P19Wr14tBw8elIKCAtmxY4ckJCTIxIkTtT70EqulS5dKZmamFBQUyNGjR2Xp0qWiKIq8//77ItI19ildJB8iIuvXr5e4uDgxm80yZswY+eyzz7w9JI+bMWOGREdHi9lslt69e8uMGTMkPz9fq6+qqpKnn35aevbsKf7+/vLwww/L5cuXHfo4e/asTJ06Vfz8/CQsLEyee+45qaur8/SmuN1HH30kAJwec+bMERH77bYvv/yyREZGisVikdTUVMnLy3Poo7i4WB577DEJDAyUoKAgmTt3rpSXlzu0OXLkiNxzzz1isVikd+/e8uqrr3pqE92mtVhVVlbK5MmTJTw8XEwmk8THx8v8+fOdEn29xMpVnADI5s2btTbu+tx99NFHcuedd4rZbJaEhASHdXQFbcXq/PnzMnHiRAkNDRWLxSKJiYmyZMkSh+/5ENFHrH70ox9JfHy8mM1mCQ8Pl9TUVC3xEOka+5QiIuKeYyhEREREbev213wQERFR58Lkg4iIiDyKyQcRERF5FJMPIiIi8igmH0RERORRTD6IiIjIo5h8EBERkUcx+SAiIiKPYvJBpGOTJk3Cs88+CwDo27cv1q1b59XxtOXs2bNQFEX7TQ8i6pp8vD0AIuocvvjiCwQEBHh7GK2KjY3F5cuXERYW5u2hENFtYPJBRACA8PBwbw+hTUajUfvJbyLqunjahUgnbty4gdmzZyMwMBDR0dH47W9/61Df/LSLoijYtGkT7r//fvj7++OOO+5AVlYW8vPzMWnSJAQEBGDcuHE4c+aMQz87duzAyJEj4evri4SEBKxatQr19fUO/b7++ut4+OGH4e/vjwEDBuC9997T6q9fv45Zs2YhPDwcfn5+GDBgADZv3gzA9WmXzMxMjBkzBhaLBdHR0Vi6dKnD+iZNmoSf/vSneP755xEaGoqoqCi88sorbogoEd0qJh9EOrFkyRJkZmZix44deP/995GRkYEvv/yy1WV+/vOfY/bs2cjJycGgQYMwc+ZM/OQnP8GyZctw8OBBiAgWLlyotd+/fz9mz56NRYsW4cSJE9i0aRO2bNmCX/7ylw79rlq1Ct///vdx9OhRTJs2DbNmzUJJSQkA4OWXX8aJEyewe/dunDx5Ehs3bmzxNMvFixcxbdo0jB49GkeOHMHGjRvxxhtv4Be/+IVDu7/97W8ICAhAdnY2XnvtNaxevRp79+69lTASkTu47fdxiajTKi8vF7PZLG+//bZWVlxcLH5+frJo0SIREYmPj5ff//73Wj0Aeemll7T3WVlZAkDeeOMNrWzr1q3i6+urvU9NTZVf/epXDut+8803JTo6usV+KyoqBIDs3r1bRESmT58uc+fOdbkdBQUFAkAOHz4sIiLLly+XpKQkUVVVa7NhwwYJDAwUm80mIiL33nuv3HPPPQ79jB49Wl544QWX6yCijsdrPoh04MyZM6itrUVycrJWFhoaiqSkpFaXGz58uPY6MjISADBs2DCHsurqalitVgQFBeHIkSM4cOCAw5EOm82G6upqVFZWwt/f36nfgIAABAUFoaioCADw1FNP4dFHH8WXX36JyZMn46GHHsK4ceNcju/kyZNISUmBoiha2fjx41FRUYELFy4gLi7OaX0AEB0dra2PiDyPyQcRtchkMmmvGyd4V2WqqgIAKioqsGrVKjzyyCNOffn6+rrst7Gfxj6mTp2Kc+fOYdeuXdi7dy9SU1OxYMEC/OY3v3HLdjRfHxF5Hq/5INKB/v37w2QyITs7Wyu7fv06vvrqK7euZ+TIkcjLy0NiYqLTw2Bo/5+b8PBwzJkzB3//+9+xbt06/OUvf3HZrvEiWBHRyg4cOIAePXqgT58+t709RNQxeOSDSAcCAwMxb948LFmyBL169UJERARefPHFm0oI2mPFihW4//77ERcXh+9973swGAw4cuQIcnNznS4Cba2PUaNGYciQIaipqcHOnTtxxx13uGz79NNPY926dXjmmWewcOFC5OXlYeXKlVi8eLHbt42I3IfJB5FOrF27FhUVFZg+fTp69OiB5557DmVlZW5dR3p6Onbu3InVq1fj17/+NUwmEwYNGoQf//jH7e7DbDZj2bJlOHv2LPz8/DBhwgRs27bNZdvevXtj165dWLJkCUaMGIHQ0FDMmzcPL730krs2iYg6gCJNj1cSERERdTAelyQiIiKPYvJBREREHsXkg4iIiDyKyQcRERF5FJMPIiIi8igmH0RERORRTD6IiIjIo5h8EBERkUcx+SAiIiKPYvJBREREHsXkg4iIiDzqfwFhUDV/eC2krAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x='dimension')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class EmbeddingKNN:\n",
    "    def __init__(self, words, embeddings, *, n_neighbors=10, metric='cosine'):\n",
    "        \"\"\"\n",
    "        Initialize with:\n",
    "          - words: list of w words\n",
    "          - embeddings: np.array of shape (w, n), each row is an embedding.\n",
    "        \"\"\"\n",
    "        self.words = words\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "        # Fit Nearest Neighbors with up to 10 neighbors using cosine distance\n",
    "        self.neigh = NearestNeighbors(n_neighbors=n_neighbors, metric=metric)\n",
    "        self.neigh.fit(self.embeddings)\n",
    "\n",
    "    def translation_neighbors(self, trans_vect, base_vecs=None, *, min_dist=None):\n",
    "        \"\"\"\n",
    "        For each vector in base_vecs (defaulting to self.embeddings), add trans_vect\n",
    "        to the vector, then find the closest embedding in self.embeddings.\n",
    "\n",
    "        :param trans_vect: A translation vector of shape (n,).\n",
    "        :param base_vecs: A matrix of shape (m, n). If None, uses self.embeddings.\n",
    "        :return: A list of (closest_word, cosine_distance) for each row of base_vecs.\n",
    "        \"\"\"\n",
    "        if base_vecs is None:\n",
    "            base_vecs = self.embeddings\n",
    "\n",
    "        # Add trans_vect to each row of base_vecs\n",
    "        translated_vecs = base_vecs + trans_vect\n",
    "\n",
    "        # Query the nearest neighbor (n_neighbors=1) for each translated vector\n",
    "        distances, indices = self.neigh.kneighbors(translated_vecs, n_neighbors=1)\n",
    "        words = self.words[indices]\n",
    "\n",
    "        if min_dist is not None:\n",
    "            mask = distances < min_dist\n",
    "            distances = distances[mask]\n",
    "            words = words[mask]\n",
    "        \n",
    "        return words\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words.shape=(52078, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "src = '/Users/thorwhalen/Dropbox/_odata/figiri/wordnet_words/words_embeddings.parquet'\n",
    "\n",
    "words = pd.read_parquet(src)\n",
    "print(f\"{words.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52078, 1536)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec = words.embedding.loc\n",
    "\n",
    "all_words_vecs = np.vstack(words.embedding.values)\n",
    "all_words_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacc = EmbeddingKNN(words.index.values, np.vstack(words.embedding.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'aaa', 'aachen', 'aah', 'aalborg', 'aalst'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.words[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=100)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_neighbors = 100  # Number of nearest neighbors to find\n",
    "\n",
    "# Step 1: Train a NearestNeighbors model\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "knn.fit(all_words_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    ['man', 'woman'],\n",
    "    # ['boy', 'girl'],\n",
    "    # ['king', 'queen'],\n",
    "    # ['father', 'mother'],\n",
    "    # ['son', 'daughter'],\n",
    "    # ['brother', 'sister'],\n",
    "    # ['uncle', 'aunt'],\n",
    "    # ['nephew', 'niece'],\n",
    "    # ['husband', 'wife'],\n",
    "    # ['grandfather', 'grandmother'],\n",
    "    # ['grandson', 'granddaughter'],\n",
    "    # ['he', 'she'],\n",
    "    # ['his', 'her'],\n",
    "    # ['him', 'her'],\n",
    "]\n",
    "\n",
    "trans_vecs = {(pair[0], pair[1]): word_vec[pair[1]] - word_vec[pair[0]] for pair in pairs}\n",
    "vecs = np.array(list(trans_vecs.values()))\n",
    "mean_vec = vecs.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52078, 1536)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'aaa', 'aachen', 'aah', 'aalborg', 'aalst', 'aalto',\n",
       "       'aar', 'aardvark'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dacc.translation_neighbors(mean_vec, all_words_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>womanhood</th>\n",
       "      <td>womanhood</td>\n",
       "      <td>0.087021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>englishwoman</th>\n",
       "      <td>englishwoman</td>\n",
       "      <td>0.087088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>0.089477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>womanly</th>\n",
       "      <td>womanly</td>\n",
       "      <td>0.091009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewoman</th>\n",
       "      <td>gentlewoman</td>\n",
       "      <td>0.091991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boss</th>\n",
       "      <td>boss</td>\n",
       "      <td>0.159679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strongman</th>\n",
       "      <td>strongman</td>\n",
       "      <td>0.159842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>godfather</th>\n",
       "      <td>godfather</td>\n",
       "      <td>0.160356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headman</th>\n",
       "      <td>headman</td>\n",
       "      <td>0.167203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>king</td>\n",
       "      <td>0.167990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52078 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target  distance\n",
       "source                              \n",
       "womanhood        womanhood  0.087021\n",
       "englishwoman  englishwoman  0.087088\n",
       "queen                queen  0.089477\n",
       "womanly            womanly  0.091009\n",
       "gentlewoman    gentlewoman  0.091991\n",
       "...                    ...       ...\n",
       "boss                  boss  0.159679\n",
       "strongman        strongman  0.159842\n",
       "godfather        godfather  0.160356\n",
       "headman            headman  0.167203\n",
       "king                  king  0.167990\n",
       "\n",
       "[52078 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a pandas pandas dataframe with a word column and a distance column from this t\n",
    "\n",
    "tt = pd.DataFrame(t, columns=['target', 'distance'])\n",
    "tt['source'] = dacc.words\n",
    "tt = tt[['source', 'target', 'distance']]\n",
    "tt.sort_values('distance', ascending=True, inplace=True)\n",
    "tt = tt.set_index('source')\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target      grandson\n",
       "distance    0.148719\n",
       "Name: grandson, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.loc['grandson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target          lord\n",
       "distance    0.151395\n",
       "Name: lord, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.loc['lord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target             a\n",
       "distance    0.144619\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(source_not_target)=18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spokesman</th>\n",
       "      <td>spokeswoman</td>\n",
       "      <td>0.102214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grandfather</th>\n",
       "      <td>grandmother</td>\n",
       "      <td>0.108817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sculptor</th>\n",
       "      <td>sculptress</td>\n",
       "      <td>0.110693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congressman</th>\n",
       "      <td>congresswoman</td>\n",
       "      <td>0.115322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father</th>\n",
       "      <td>mother</td>\n",
       "      <td>0.119465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grandpa</th>\n",
       "      <td>grandma</td>\n",
       "      <td>0.122415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spokesperson</th>\n",
       "      <td>spokeswoman</td>\n",
       "      <td>0.125043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horseman</th>\n",
       "      <td>horsewoman</td>\n",
       "      <td>0.128347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assemblyman</th>\n",
       "      <td>assemblywoman</td>\n",
       "      <td>0.129331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.131448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masseur</th>\n",
       "      <td>masseuse</td>\n",
       "      <td>0.132221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobleman</th>\n",
       "      <td>noblewoman</td>\n",
       "      <td>0.133292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>villain</th>\n",
       "      <td>villainess</td>\n",
       "      <td>0.133443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confidant</th>\n",
       "      <td>confidante</td>\n",
       "      <td>0.136283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frenchman</th>\n",
       "      <td>frenchwoman</td>\n",
       "      <td>0.136729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>councilman</th>\n",
       "      <td>councilwoman</td>\n",
       "      <td>0.138699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shepherd</th>\n",
       "      <td>shepherdess</td>\n",
       "      <td>0.141557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>girl</td>\n",
       "      <td>0.145842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     target  distance\n",
       "source                               \n",
       "spokesman       spokeswoman  0.102214\n",
       "grandfather     grandmother  0.108817\n",
       "sculptor         sculptress  0.110693\n",
       "congressman   congresswoman  0.115322\n",
       "father               mother  0.119465\n",
       "grandpa             grandma  0.122415\n",
       "spokesperson    spokeswoman  0.125043\n",
       "horseman         horsewoman  0.128347\n",
       "assemblyman   assemblywoman  0.129331\n",
       "man                   woman  0.131448\n",
       "masseur            masseuse  0.132221\n",
       "nobleman         noblewoman  0.133292\n",
       "villain          villainess  0.133443\n",
       "confidant        confidante  0.136283\n",
       "frenchman       frenchwoman  0.136729\n",
       "councilman     councilwoman  0.138699\n",
       "shepherd        shepherdess  0.141557\n",
       "boy                    girl  0.145842"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_not_target = tt[tt.index != tt.target]\n",
    "print(f\"{len(source_not_target)=}\")\n",
    "source_not_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnet_features.shape=(123587, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word                                                          a\n",
       "frequency                                              0.015441\n",
       "definition    a metric unit of length equal to one ten billi...\n",
       "lexname                                           noun.quantity\n",
       "name                                              angstrom.n.01\n",
       "pos                                                        noun\n",
       "umap_x                                                 3.027916\n",
       "umap_y                                                 3.760965\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "wordnet_features = pd.read_parquet('/Users/thorwhalen/Dropbox/_odata/figiri/wordnet_words/wordnet_feature_meta.parquet')\n",
    "print(f\"{wordnet_features.shape=}\")\n",
    "wordnet_features.iloc[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnet_metadata.shape=(123587, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word                                                                  a\n",
       "synset                                                    angstrom.n.01\n",
       "example                                                                \n",
       "definition            a metric unit of length equal to one ten billi...\n",
       "lexname                                                   noun.quantity\n",
       "name                                                      angstrom.n.01\n",
       "pos                                                                noun\n",
       "attributes                                                           []\n",
       "causes                                                               []\n",
       "entailments                                                          []\n",
       "hypernyms                                     [metric_linear_unit.n.01]\n",
       "hyponyms                                                             []\n",
       "in_region_domains                                                    []\n",
       "in_topic_domains                                                     []\n",
       "in_usage_domains                                                     []\n",
       "instance_hypernyms                                                   []\n",
       "instance_hyponyms                                                    []\n",
       "member_holonyms                                                      []\n",
       "member_meronyms                                                      []\n",
       "part_holonyms                                          [nanometer.n.01]\n",
       "part_meronyms                                          [picometer.n.01]\n",
       "region_domains                                                       []\n",
       "root_hypernyms                                            [entity.n.01]\n",
       "similar_tos                                                          []\n",
       "substance_holonyms                                                   []\n",
       "substance_meronyms                                                   []\n",
       "topic_domains                                                        []\n",
       "usage_domains                                                        []\n",
       "verb_groups                                                          []\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wordnet_metadata = pd.read_parquet('/Users/thorwhalen/Dropbox/_odata/figiri/wordnet_words/wordnet_metadata.parquet')\n",
    "print(f\"{wordnet_metadata.shape=}\")\n",
    "wordnet_metadata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>synset</th>\n",
       "      <th>example</th>\n",
       "      <th>definition</th>\n",
       "      <th>lexname</th>\n",
       "      <th>name</th>\n",
       "      <th>pos</th>\n",
       "      <th>attributes</th>\n",
       "      <th>causes</th>\n",
       "      <th>entailments</th>\n",
       "      <th>hypernyms</th>\n",
       "      <th>hyponyms</th>\n",
       "      <th>in_region_domains</th>\n",
       "      <th>in_topic_domains</th>\n",
       "      <th>in_usage_domains</th>\n",
       "      <th>instance_hypernyms</th>\n",
       "      <th>instance_hyponyms</th>\n",
       "      <th>member_holonyms</th>\n",
       "      <th>member_meronyms</th>\n",
       "      <th>part_holonyms</th>\n",
       "      <th>part_meronyms</th>\n",
       "      <th>region_domains</th>\n",
       "      <th>root_hypernyms</th>\n",
       "      <th>similar_tos</th>\n",
       "      <th>substance_holonyms</th>\n",
       "      <th>substance_meronyms</th>\n",
       "      <th>topic_domains</th>\n",
       "      <th>usage_domains</th>\n",
       "      <th>verb_groups</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>queen.n.01.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.n.01</td>\n",
       "      <td></td>\n",
       "      <td>the only fertile female in a colony of social ...</td>\n",
       "      <td>noun.animal</td>\n",
       "      <td>queen.n.01</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[insect.n.01]</td>\n",
       "      <td>[queen_bee.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen.n.02.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.n.02</td>\n",
       "      <td></td>\n",
       "      <td>a female sovereign ruler</td>\n",
       "      <td>noun.person</td>\n",
       "      <td>queen.n.02</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[female_aristocrat.n.01]</td>\n",
       "      <td>[queen_of_england.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mary_queen_of_scots.n.01, liliuokalani.n.01, ...</td>\n",
       "      <td>[royalty.n.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen.n.03.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.n.03</td>\n",
       "      <td></td>\n",
       "      <td>the wife or widow of a king</td>\n",
       "      <td>noun.person</td>\n",
       "      <td>queen.n.03</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[female_aristocrat.n.01]</td>\n",
       "      <td>[queen_regent.n.01, queen_consort.n.01, queen_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[marie_antoinette.n.01, howard.n.02, nefertiti...</td>\n",
       "      <td>[royalty.n.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen.n.04.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.n.04</td>\n",
       "      <td>Paris is the queen of cities</td>\n",
       "      <td>something personified as a woman who is consid...</td>\n",
       "      <td>noun.person</td>\n",
       "      <td>queen.n.04</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[personification.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king.n.02.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>king.n.02</td>\n",
       "      <td></td>\n",
       "      <td>a competitor who holds a preeminent position</td>\n",
       "      <td>noun.person</td>\n",
       "      <td>king.n.02</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[rival.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fagot.n.01.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>fagot.n.01</td>\n",
       "      <td></td>\n",
       "      <td>offensive term for an openly homosexual man</td>\n",
       "      <td>noun.person</td>\n",
       "      <td>fagot.n.01</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[gay_man.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[disparagement.n.01]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen.n.07.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.n.07</td>\n",
       "      <td></td>\n",
       "      <td>one of four face cards in a deck bearing a pic...</td>\n",
       "      <td>noun.artifact</td>\n",
       "      <td>queen.n.07</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[face_card.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pack_of_cards.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen.n.08.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.n.08</td>\n",
       "      <td></td>\n",
       "      <td>(chess) the most powerful piece</td>\n",
       "      <td>noun.artifact</td>\n",
       "      <td>queen.n.08</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chessman.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chess.n.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen.n.09.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.n.09</td>\n",
       "      <td></td>\n",
       "      <td>an especially large mole rat and the only memb...</td>\n",
       "      <td>noun.animal</td>\n",
       "      <td>queen.n.09</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[naked_mole_rat.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabby.n.02.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>tabby.n.02</td>\n",
       "      <td></td>\n",
       "      <td>female cat</td>\n",
       "      <td>noun.animal</td>\n",
       "      <td>tabby.n.02</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[domestic_cat.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[entity.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen.v.01.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.v.01</td>\n",
       "      <td></td>\n",
       "      <td>promote to a queen, as of a pawn in chess</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>queen.v.01</td>\n",
       "      <td>verb</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[promote.v.05]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[use.v.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen.v.02.queen</th>\n",
       "      <td>queen</td>\n",
       "      <td>queen.v.02</td>\n",
       "      <td>her pawn queened</td>\n",
       "      <td>become a queen</td>\n",
       "      <td>verb.motion</td>\n",
       "      <td>queen.v.02</td>\n",
       "      <td>verb</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[promote.v.04]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[change.v.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chess.n.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word      synset  ...         usage_domains verb_groups\n",
       "lemma                                ...                                  \n",
       "queen.n.01.queen  queen  queen.n.01  ...                    []          []\n",
       "queen.n.02.queen  queen  queen.n.02  ...                    []          []\n",
       "queen.n.03.queen  queen  queen.n.03  ...                    []          []\n",
       "queen.n.04.queen  queen  queen.n.04  ...                    []          []\n",
       "king.n.02.queen   queen   king.n.02  ...                    []          []\n",
       "fagot.n.01.queen  queen  fagot.n.01  ...  [disparagement.n.01]          []\n",
       "queen.n.07.queen  queen  queen.n.07  ...                    []          []\n",
       "queen.n.08.queen  queen  queen.n.08  ...                    []          []\n",
       "queen.n.09.queen  queen  queen.n.09  ...                    []          []\n",
       "tabby.n.02.queen  queen  tabby.n.02  ...                    []          []\n",
       "queen.v.01.queen  queen  queen.v.01  ...                    []          []\n",
       "queen.v.02.queen  queen  queen.v.02  ...                    []          []\n",
       "\n",
       "[12 rows x 29 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metadata_for_word(word):\n",
    "    return wordnet_metadata.loc[wordnet_metadata.word == word]\n",
    "\n",
    "metadata_for_word('queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 29)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_for_word('queen').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15375</th>\n",
       "      <td>englishwoman</td>\n",
       "      <td>0.059379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19042</th>\n",
       "      <td>gentlewoman</td>\n",
       "      <td>0.059601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>actress</td>\n",
       "      <td>0.060443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25768</th>\n",
       "      <td>landlady</td>\n",
       "      <td>0.060760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25658</th>\n",
       "      <td>lady</td>\n",
       "      <td>0.061288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20576</th>\n",
       "      <td>handsome</td>\n",
       "      <td>0.100385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>businessman</td>\n",
       "      <td>0.100488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27797</th>\n",
       "      <td>man</td>\n",
       "      <td>0.100852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44356</th>\n",
       "      <td>strongman</td>\n",
       "      <td>0.101159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20884</th>\n",
       "      <td>headman</td>\n",
       "      <td>0.102410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52078 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  distance\n",
       "15375  englishwoman  0.059379\n",
       "19042   gentlewoman  0.059601\n",
       "488         actress  0.060443\n",
       "25768      landlady  0.060760\n",
       "25658          lady  0.061288\n",
       "...             ...       ...\n",
       "20576      handsome  0.100385\n",
       "6479    businessman  0.100488\n",
       "27797           man  0.100852\n",
       "44356     strongman  0.101159\n",
       "20884       headman  0.102410\n",
       "\n",
       "[52078 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a pandas pandas dataframe with a word column and a distance column from this t\n",
    "\n",
    "tt = pd.DataFrame(t, columns=['word', 'distance'])\n",
    "tt.sort_values('distance', ascending=True, inplace=True)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embedding    [0.03497309610247612, 0.003794316668063402, -0...\n",
       "Name: englishwoman, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.iloc[15375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbors = find_nearest_neighbors(mean_vec, words.index.values, knn, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('englishwoman', 0.6488416364242586),\n",
       " ('gentlewoman', 0.6514492275017839),\n",
       " ('actress', 0.661357856802595),\n",
       " ('landlady', 0.6651019032417215),\n",
       " ('lady', 0.671341027828316),\n",
       " ('schoolgirl', 0.6742232729238721),\n",
       " ('goddaughter', 0.6776582926827888),\n",
       " ('womanhood', 0.681937009735876),\n",
       " ('girlhood', 0.6843100376626591),\n",
       " ('kinswoman', 0.6864297869414873)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emilia', 0.1856053348206207),\n",
       " ('amelia', 0.46806522773982784),\n",
       " ('melia', 0.49728034334623095),\n",
       " ('elisa', 0.5167585876760002),\n",
       " ('silvia', 0.5349300795158866),\n",
       " ('molise', 0.5359479139491025),\n",
       " ('selma', 0.5632534638477151),\n",
       " ('ma', 0.5637456101948137),\n",
       " ('camelia', 0.5658067890279446),\n",
       " ('emile', 0.5695956263111385),\n",
       " ('ela', 0.5700265779662446),\n",
       " ('milord', 0.5701551230167076),\n",
       " ('arminius', 0.5704029512850921),\n",
       " ('parmelia', 0.5727260735708704),\n",
       " ('abelia', 0.5812744010549296),\n",
       " ('minerva', 0.5818079692613954),\n",
       " ('maia', 0.5836960554181392),\n",
       " ('carmine', 0.5897216682569613),\n",
       " ('romulus', 0.5902641981276877),\n",
       " ('male', 0.5916144864350306),\n",
       " ('lena', 0.5979485698736845),\n",
       " ('anna', 0.5981072501945826),\n",
       " ('mare', 0.5991993418873663),\n",
       " ('noemi', 0.6018002615988873),\n",
       " ('pomelo', 0.6031528296288499),\n",
       " ('malvasia', 0.6052748010527991),\n",
       " ('murillo', 0.605366251841285),\n",
       " ('attilio', 0.6054655484089878),\n",
       " ('elm', 0.6068193034487999),\n",
       " ('ermine', 0.6071094397610399),\n",
       " ('emu', 0.6071992568378295),\n",
       " ('proserpina', 0.6074394992100911),\n",
       " ('salerno', 0.607870483172039),\n",
       " ('apulia', 0.6085565481391807),\n",
       " ('milvus', 0.6093400454754743),\n",
       " ('susanna', 0.6099898668638382),\n",
       " ('sicily', 0.6107384780853063),\n",
       " ('umbria', 0.6107786482423723),\n",
       " ('remus', 0.6114762556466518),\n",
       " ('isabella', 0.6121759592911782),\n",
       " ('tilia', 0.6131919290352419),\n",
       " ('melena', 0.6132150987994526),\n",
       " ('milo', 0.6135363510656481),\n",
       " ('messily', 0.613592617886886),\n",
       " ('simeon', 0.6161008417950715),\n",
       " ('lydia', 0.6163942689729716),\n",
       " ('manda', 0.6166227301977781),\n",
       " ('mil', 0.6168500311977161),\n",
       " ('malachi', 0.6177681450836885),\n",
       " ('jerome', 0.6181713658064419),\n",
       " ('lysimachia', 0.6184703231730524),\n",
       " ('commelina', 0.6190969431331762),\n",
       " ('maria', 0.6194397165948221),\n",
       " ('aurelius', 0.61983242718997),\n",
       " ('benedick', 0.6198677516178139),\n",
       " ('mattole', 0.620089729823945),\n",
       " ('annona', 0.620323115755862),\n",
       " ('amenia', 0.6206088741041699),\n",
       " ('semolina', 0.6207866327255513),\n",
       " ('anselm', 0.6212450580711719),\n",
       " ('mari', 0.6217145842676157),\n",
       " ('melchior', 0.6220387248893477),\n",
       " ('aleppo', 0.6223260714629778),\n",
       " ('carolus', 0.6225365672907202),\n",
       " ('mary', 0.6227552378574446),\n",
       " ('maiolica', 0.6231333649637043),\n",
       " ('erato', 0.6242932105968075),\n",
       " ('mann', 0.6245044047972291),\n",
       " ('mauldin', 0.6256365739650628),\n",
       " ('iago', 0.6270265681959428),\n",
       " ('merciless', 0.6275263415289469),\n",
       " ('iliamna', 0.627532213132883),\n",
       " ('amon', 0.6277661954129099),\n",
       " ('felicia', 0.6309059831744622),\n",
       " ('etruria', 0.6309814644377459),\n",
       " ('mina', 0.6311794952162055),\n",
       " ('roma', 0.6319360007591196),\n",
       " ('bruno', 0.6320869683767187),\n",
       " ('beatrice', 0.6324902698142716),\n",
       " ('meles', 0.6327258875210018),\n",
       " ('sylvanus', 0.6328719110507329),\n",
       " ('damon', 0.63312926819845),\n",
       " ('pimento', 0.6331911846143484),\n",
       " ('merl', 0.633434829766749),\n",
       " ('amia', 0.6334577765795473),\n",
       " ('melpomene', 0.6334836214487318),\n",
       " ('calluna', 0.6335948804107613),\n",
       " ('romeo', 0.63401143564329),\n",
       " ('melissa', 0.634722201358296),\n",
       " ('mem', 0.6351069020954393),\n",
       " ('marshal', 0.6353546178752638),\n",
       " ('mantua', 0.6358407280797215),\n",
       " ('alfred', 0.6361459093938874),\n",
       " ('sylva', 0.6364120808051602),\n",
       " ('mamma', 0.6367383659681383),\n",
       " ('animus', 0.6367719183618668),\n",
       " ('silvanus', 0.6369563476914188),\n",
       " ('edward', 0.6369850967566788),\n",
       " ('liguria', 0.6371657007882378),\n",
       " ('morello', 0.6372160020741473)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = word_vec['emilia'] - word_vec['female'] + word_vec['male']\n",
    "find_nearest_neighbors(v, knn, words.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6086880638995171"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average cosine similarity between mean_vec and the vecs\n",
    "from imbed import cosine_similarity\n",
    "\n",
    "mean_similarity_of_targets = np.mean([cosine_similarity(mean_vec, vec) for vec in vecs])\n",
    "mean_similarity_of_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52078,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Compute cosine distances\n",
    "cosine_distances = cdist(all_words_vecs, mean_vec.reshape(1, -1), metric='cosine').flatten()\n",
    "\n",
    "cosine_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6685385560757456"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed import cosine_similarity\n",
    "\n",
    "cosine_similarity(word_vec['emilia'], word_vec['amelia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average cosine similarity between mean_vec and the vecs\n",
    "from imbed import cosine_similarity\n",
    "\n",
    "mean_similarity_of_targets = np.mean([cosine_similarity(mean_vec, vec) for vec in vecs])\n",
    "mean_similarity_of_other_words = np.mean([cosine_similarity(mean_vec, vec) for vec in vecs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395650570848009"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = all_words_vecs[0]\n",
    "all_words_vecs[:10]\n",
    "cosine_similarity(t, all_words_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## musings on knn (or just heapq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'apple', 'value': 3}, {'name': 'cherry', 'value': 2}]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "data = [{'name': 'apple', 'value': 3}, {'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]\n",
    "\n",
    "# Find 2 items with smallest 'value'\n",
    "smallest_by_value = heapq.nlargest(2, data, key=lambda x: x['value'])\n",
    "print(smallest_by_value)  # Output: [{'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "data = [{'name': 'apple', 'value': 3}, {'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]\n",
    "\n",
    "# Find 2 items with smallest 'value'\n",
    "k = 10\n",
    "smallest_by_value = heapq.nlargest(k, data, key=lambda x: cosine_similarity()\n",
    "print(smallest_by_value)  # Output: [{'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "def find_nearest_neighbors(target_vec, word_list, knn_model=None):\n",
    "    \"\"\"\n",
    "    Finds the nearest neighbors of a given vector using the trained KNN model.\n",
    "\n",
    "    Args:\n",
    "        target_vec (np.ndarray): The target vector (n-dimensional).\n",
    "        knn_model (NearestNeighbors): Trained sklearn KNN model.\n",
    "        word_list (list): List of words corresponding to rows in the embedding matrix.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples (word, distance) for the nearest neighbors.\n",
    "    \"\"\"\n",
    "    if knn_model is None:\n",
    "        raise ValueError(\"knn_model must be provided.\")\n",
    "    else:\n",
    "        distances, indices = knn_model.kneighbors(target_vec.reshape(1, -1))\n",
    "        neighbors = [(word_list[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The k-d to 2-d problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After embedding your objects of interest into k-dimensional vectors, you might further embed them into two or three dimensions for visualization. This process inevitably loses some information and introduces distortions, but it's still valuable. The initial conversion of texts or images into numerical vectors also involved information loss, yet it was useful for your specific goals.\n",
    "\n",
    "Dimensionality reduction typically results in losing some details. The key is to preserve the essential information (the \"signal\") and minimize the loss of less important details (the \"noise\"). Done well, this can be beneficial, especially if it enhances the signal-to-noise ratio.\n",
    "\n",
    "This principle also applies to compressing vectors for visualization. The aim is to present complex data usefully and intuitively, enabling analysts to spot patterns and gain insights. It's a balance between maintaining utility and practical implementation when transforming k-dimensional data into two-dimensional forms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"504pt\" height=\"764pt\"\n",
       " viewBox=\"0.00 0.00 504.44 764.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 760)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-760 500.44,-760 500.44,4 -4,4\"/>\n",
       "<!-- src_folder -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>src_folder</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.92\" cy=\"-738\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.92\" y=\"-732.95\" font-family=\"Times,serif\" font-size=\"14.00\">src_folder</text>\n",
       "</g>\n",
       "<!-- pjoin -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>pjoin</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.92\" cy=\"-666\" rx=\"29.86\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.92\" y=\"-660.95\" font-family=\"Times,serif\" font-size=\"14.00\">pjoin</text>\n",
       "</g>\n",
       "<!-- src_folder&#45;&gt;pjoin -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>src_folder&#45;&gt;pjoin</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.92,-719.7C280.92,-712.41 280.92,-703.73 280.92,-695.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.42,-695.62 280.92,-685.62 277.42,-695.62 284.42,-695.62\"/>\n",
       "</g>\n",
       "<!-- embeddings_filepath -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>embeddings_filepath</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"93.92\" cy=\"-594\" rx=\"88.71\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.92\" y=\"-588.95\" font-family=\"Times,serif\" font-size=\"14.00\">embeddings_filepath</text>\n",
       "</g>\n",
       "<!-- pjoin&#45;&gt;embeddings_filepath -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>pjoin&#45;&gt;embeddings_filepath</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.09,-655.7C227.97,-645.18 181.38,-627.74 145.33,-614.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"147,-611.13 136.41,-610.9 144.55,-617.69 147,-611.13\"/>\n",
       "</g>\n",
       "<!-- citations_hcp3_src -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>citations_hcp3_src</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.92\" cy=\"-594\" rx=\"80.01\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.92\" y=\"-588.95\" font-family=\"Times,serif\" font-size=\"14.00\">citations_hcp3_src</text>\n",
       "</g>\n",
       "<!-- pjoin&#45;&gt;citations_hcp3_src -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>pjoin&#45;&gt;citations_hcp3_src</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.92,-647.7C280.92,-640.41 280.92,-631.73 280.92,-623.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.42,-623.62 280.92,-613.62 277.42,-623.62 284.42,-623.62\"/>\n",
       "</g>\n",
       "<!-- info_filepath -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>info_filepath</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"437.92\" cy=\"-594\" rx=\"58.52\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.92\" y=\"-588.95\" font-family=\"Times,serif\" font-size=\"14.00\">info_filepath</text>\n",
       "</g>\n",
       "<!-- pjoin&#45;&gt;info_filepath -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>pjoin&#45;&gt;info_filepath</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M304.43,-654.52C328.35,-643.85 365.97,-627.08 395.18,-614.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"396.43,-617.33 404.14,-610.06 393.58,-610.94 396.43,-617.33\"/>\n",
       "</g>\n",
       "<!-- embeddings_hcp2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>embeddings_hcp2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"93.92\" cy=\"-522\" rx=\"78.48\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.92\" y=\"-516.95\" font-family=\"Times,serif\" font-size=\"14.00\">embeddings_hcp2</text>\n",
       "</g>\n",
       "<!-- embeddings_filepath&#45;&gt;embeddings_hcp2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>embeddings_filepath&#45;&gt;embeddings_hcp2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.92,-575.7C93.92,-568.41 93.92,-559.73 93.92,-551.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"97.42,-551.62 93.92,-541.62 90.42,-551.62 97.42,-551.62\"/>\n",
       "</g>\n",
       "<!-- _citations_hcp3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>_citations_hcp3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.92\" cy=\"-522\" rx=\"69.26\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.92\" y=\"-516.95\" font-family=\"Times,serif\" font-size=\"14.00\">_citations_hcp3</text>\n",
       "</g>\n",
       "<!-- citations_hcp3_src&#45;&gt;_citations_hcp3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>citations_hcp3_src&#45;&gt;_citations_hcp3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.92,-575.7C280.92,-568.41 280.92,-559.73 280.92,-551.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.42,-551.62 280.92,-541.62 277.42,-551.62 284.42,-551.62\"/>\n",
       "</g>\n",
       "<!-- info_hcp2 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>info_hcp2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"437.92\" cy=\"-378\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.92\" y=\"-372.95\" font-family=\"Times,serif\" font-size=\"14.00\">info_hcp2</text>\n",
       "</g>\n",
       "<!-- info_filepath&#45;&gt;info_hcp2 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>info_filepath&#45;&gt;info_hcp2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437.92,-575.85C437.92,-539.14 437.92,-452.66 437.92,-407.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"441.42,-407.75 437.92,-397.75 434.42,-407.75 441.42,-407.75\"/>\n",
       "</g>\n",
       "<!-- embeddings_ids -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>embeddings_ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"100.92\" cy=\"-450\" rx=\"71.31\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.92\" y=\"-444.95\" font-family=\"Times,serif\" font-size=\"14.00\">embeddings_ids</text>\n",
       "</g>\n",
       "<!-- embeddings_hcp2&#45;&gt;embeddings_ids -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>embeddings_hcp2&#45;&gt;embeddings_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M95.65,-503.7C96.38,-496.41 97.25,-487.73 98.07,-479.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.55,-479.91 99.06,-469.61 94.58,-479.21 101.55,-479.91\"/>\n",
       "</g>\n",
       "<!-- mean_aggregates -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>mean_aggregates</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"170.92\" cy=\"-162\" rx=\"75.41\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.92\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">mean_aggregates</text>\n",
       "</g>\n",
       "<!-- embeddings_hcp2&#45;&gt;mean_aggregates -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>embeddings_hcp2&#45;&gt;mean_aggregates</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.31,-505.13C47.57,-496.18 31.08,-483.62 20.92,-468 -1.13,-434.09 1.92,-419.45 1.92,-379 1.92,-379 1.92,-379 1.92,-305 1.92,-264.55 -5.77,-246.39 20.92,-216 39.75,-194.57 67.79,-181.81 94.56,-174.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"95.26,-177.63 104.06,-171.73 93.5,-170.86 95.26,-177.63\"/>\n",
       "</g>\n",
       "<!-- _citations_ids -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>_citations_ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"251.92\" cy=\"-450\" rx=\"62.1\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.92\" y=\"-444.95\" font-family=\"Times,serif\" font-size=\"14.00\">_citations_ids</text>\n",
       "</g>\n",
       "<!-- _citations_hcp3&#45;&gt;_citations_ids -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>_citations_hcp3&#45;&gt;_citations_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M273.75,-503.7C270.63,-496.15 266.89,-487.12 263.39,-478.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"266.65,-477.4 259.59,-469.5 260.18,-480.08 266.65,-477.4\"/>\n",
       "</g>\n",
       "<!-- citations_hcp3 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>citations_hcp3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"296.92\" cy=\"-306\" rx=\"64.66\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"296.92\" y=\"-300.95\" font-family=\"Times,serif\" font-size=\"14.00\">citations_hcp3</text>\n",
       "</g>\n",
       "<!-- _citations_hcp3&#45;&gt;citations_hcp3 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>_citations_hcp3&#45;&gt;citations_hcp3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.09,-504.22C308.13,-494.61 318.14,-481.75 322.92,-468 338.66,-422.79 322.27,-367.08 309.33,-334.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"312.6,-333.21 305.53,-325.32 306.14,-335.9 312.6,-333.21\"/>\n",
       "</g>\n",
       "<!-- missing_ids -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>missing_ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"251.92\" cy=\"-378\" rx=\"55.45\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.92\" y=\"-372.95\" font-family=\"Times,serif\" font-size=\"14.00\">missing_ids</text>\n",
       "</g>\n",
       "<!-- _citations_ids&#45;&gt;missing_ids -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>_citations_ids&#45;&gt;missing_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.92,-431.7C251.92,-424.41 251.92,-415.73 251.92,-407.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"255.42,-407.62 251.92,-397.62 248.42,-407.62 255.42,-407.62\"/>\n",
       "</g>\n",
       "<!-- embeddings_ids&#45;&gt;missing_ids -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>embeddings_ids&#45;&gt;missing_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.06,-433.64C156.6,-423.19 186.58,-409.29 210.66,-398.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.95,-401.39 219.55,-394.01 209.01,-395.04 211.95,-401.39\"/>\n",
       "</g>\n",
       "<!-- missing_ids&#45;&gt;citations_hcp3 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>missing_ids&#45;&gt;citations_hcp3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M262.82,-360.05C267.96,-352.06 274.21,-342.33 279.95,-333.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.85,-335.37 285.31,-325.06 276.96,-331.58 282.85,-335.37\"/>\n",
       "</g>\n",
       "<!-- cited_by -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>cited_by</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"240.92\" cy=\"-234\" rx=\"42.65\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.92\" y=\"-228.95\" font-family=\"Times,serif\" font-size=\"14.00\">cited_by</text>\n",
       "</g>\n",
       "<!-- citations_hcp3&#45;&gt;cited_by -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>citations_hcp3&#45;&gt;cited_by</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M283.37,-288.05C276.67,-279.68 268.45,-269.4 261.03,-260.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.89,-258.11 254.91,-252.49 258.43,-262.48 263.89,-258.11\"/>\n",
       "</g>\n",
       "<!-- citations_of -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>citations_of</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"355.92\" cy=\"-234\" rx=\"54.42\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"355.92\" y=\"-228.95\" font-family=\"Times,serif\" font-size=\"14.00\">citations_of</text>\n",
       "</g>\n",
       "<!-- citations_hcp3&#45;&gt;citations_of -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>citations_hcp3&#45;&gt;citations_of</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M311.21,-288.05C318.16,-279.8 326.67,-269.7 334.4,-260.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"337.03,-262.85 340.8,-252.95 331.68,-258.34 337.03,-262.85\"/>\n",
       "</g>\n",
       "<!-- ids -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"355.92\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"355.92\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">ids</text>\n",
       "</g>\n",
       "<!-- citations_of&#45;&gt;ids -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>citations_of&#45;&gt;ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M355.92,-215.7C355.92,-208.41 355.92,-199.73 355.92,-191.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"359.42,-191.62 355.92,-181.62 352.42,-191.62 359.42,-191.62\"/>\n",
       "</g>\n",
       "<!-- citations_of&#45;&gt;mean_aggregates -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>citations_of&#45;&gt;mean_aggregates</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M321.13,-219.83C292.73,-209.09 252.25,-193.77 220.46,-181.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.05,-178.6 211.46,-178.34 219.58,-185.15 222.05,-178.6\"/>\n",
       "</g>\n",
       "<!-- planar_mean_embeddings -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>planar_mean_embeddings</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"268.92\" cy=\"-90\" rx=\"108.67\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"268.92\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">planar_mean_embeddings</text>\n",
       "</g>\n",
       "<!-- mean_aggregates&#45;&gt;planar_mean_embeddings -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>mean_aggregates&#45;&gt;planar_mean_embeddings</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.15,-144.41C206.66,-135.48 222.3,-124.3 236.04,-114.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"237.85,-117.5 243.95,-108.84 233.78,-111.8 237.85,-117.5\"/>\n",
       "</g>\n",
       "<!-- mean_aggregator -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>mean_aggregator</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.92\" cy=\"-234\" rx=\"75.41\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.92\" y=\"-228.95\" font-family=\"Times,serif\" font-size=\"14.00\">mean_aggregator</text>\n",
       "</g>\n",
       "<!-- mean_aggregator&#45;&gt;mean_aggregates -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>mean_aggregator&#45;&gt;mean_aggregates</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M120.9,-216.05C128.84,-207.63 138.6,-197.28 147.38,-187.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"149.74,-190.57 154.06,-180.89 144.65,-185.77 149.74,-190.57\"/>\n",
       "</g>\n",
       "<!-- planar_mean_embeddings_with_ids -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>planar_mean_embeddings_with_ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"336.92\" cy=\"-18\" rx=\"145.01\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"336.92\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">planar_mean_embeddings_with_ids</text>\n",
       "</g>\n",
       "<!-- planar_mean_embeddings&#45;&gt;planar_mean_embeddings_with_ids -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>planar_mean_embeddings&#45;&gt;planar_mean_embeddings_with_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M285.38,-72.05C293.45,-63.75 303.33,-53.58 312.27,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.63,-46.97 319.09,-37.36 309.61,-42.09 314.63,-46.97\"/>\n",
       "</g>\n",
       "<!-- info_hcp2&#45;&gt;planar_mean_embeddings_with_ids -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>info_hcp2&#45;&gt;planar_mean_embeddings_with_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437.92,-359.51C437.92,-332.71 437.92,-279.87 437.92,-235 437.92,-235 437.92,-235 437.92,-161 437.92,-112.61 398.49,-69.25 368.91,-43.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"371.16,-40.86 361.25,-37.1 366.66,-46.21 371.16,-40.86\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2bf00f280>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from i2.footprints import attribute_dependencies, init_argument_names\n",
    "from imbed.mdat.hcp import Hcp3Dacc\n",
    "from meshed.itools import graphviz_digraph\n",
    "\n",
    "deps = dict(attribute_dependencies(Hcp3Dacc))\n",
    "\n",
    "graphviz_digraph(deps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/thorwhalen/Dropbox/_odata/figiri/hcp'\n",
    "dacc = Hcp3Dacc(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dacc.info_hcp2)=354165, 308135, dacc.citations_and_titles.shape=(308135, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cited_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2138790588, 2013150886]</td>\n",
       "      <td>245658</td>\n",
       "      <td>Standardized low-resolution brain electromagne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1994893189, 2158553737, 1604916109, 202841896...</td>\n",
       "      <td>718838</td>\n",
       "      <td>Pathophysiology of obsessivecompulsive diso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2114205159, 2161774890, 1965693998, 211020414...</td>\n",
       "      <td>831416</td>\n",
       "      <td>Remote Ischemic Preconditioning Provides Early...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2025976960, 2172013173]</td>\n",
       "      <td>898828</td>\n",
       "      <td>The Unknown Mechanism of the Overtraining Synd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2138019504, 2127271355, 2103972604]</td>\n",
       "      <td>905619</td>\n",
       "      <td>Revisiting Frank-Wolfe: Projection-Free Sparse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cited_ids      id  \\\n",
       "0                           [2138790588, 2013150886]  245658   \n",
       "2  [1994893189, 2158553737, 1604916109, 202841896...  718838   \n",
       "4  [2114205159, 2161774890, 1965693998, 211020414...  831416   \n",
       "5                           [2025976960, 2172013173]  898828   \n",
       "6               [2138019504, 2127271355, 2103972604]  905619   \n",
       "\n",
       "                                               title  \n",
       "0  Standardized low-resolution brain electromagne...  \n",
       "2  Pathophysiology of obsessivecompulsive diso...  \n",
       "4  Remote Ischemic Preconditioning Provides Early...  \n",
       "5  The Unknown Mechanism of the Overtraining Synd...  \n",
       "6  Revisiting Frank-Wolfe: Projection-Free Sparse...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dacc.citations_and_titles\n",
    "print(f\"{len(dacc.info_hcp2)=}, {len(dacc.citations_of)}, {dacc.citations_and_titles.shape=}\")\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Speed comparison between numpy and scipy cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9746318461970762\n",
      "[0.97341717 0.99716412]\n",
      "[[0.97341717 0.96761727]\n",
      " [0.99868766 0.99716412]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(u, v, *, cartesian_product=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors.\n",
    "\n",
    "    If both inputs are 1D vectors, returns a float.\n",
    "    If one or both inputs are 2D arrays, returns either a 1D array (row-wise)\n",
    "    or a 2D array (cartesian product of rows) depending on the cartesian_product flag.\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k x n),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k x n).\n",
    "        cartesian_product (bool, optional):\n",
    "            - If False (default), the function compares rows in a one-to-one fashion.\n",
    "              Expects the same number of rows in u and v.\n",
    "            - If True, computes the similarity for every combination of rows\n",
    "              (results in a 2D array).\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D numpy array if either u or v is a 2D array and cartesian_product=False.\n",
    "            - A 2D numpy array if cartesian_product=True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the number of columns in u and v do not match,\n",
    "                    or if (cartesian_product=False) but u and v have different row counts.\n",
    "    \"\"\"\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Case 1: Both are single 1D vectors\n",
    "    # -----------------------------\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        if u.shape[0] != v.shape[0]:\n",
    "            raise ValueError(\"Vectors u and v must have the same dimension.\")\n",
    "        dot_uv = np.dot(u, v)\n",
    "        norm_u = np.linalg.norm(u)\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Case 2: At least one is 2D\n",
    "    # Ensure both are 2D\n",
    "    # -----------------------------\n",
    "    if u.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        u = u[np.newaxis, :]\n",
    "    if v.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        v = v[np.newaxis, :]\n",
    "\n",
    "    # Now u.shape = (k1, n1), v.shape = (k2, n2)\n",
    "    k1, n1 = u.shape\n",
    "    k2, n2 = v.shape\n",
    "\n",
    "    # Validate the number of columns (dimensions)\n",
    "    if n1 != n2:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent dimensions: u has {n1} columns, v has {n2} columns.\"\n",
    "        )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Non-cartesian (row-wise) vs cartesian product\n",
    "    # -----------------------------\n",
    "    if not cartesian_product:\n",
    "        # Requires the same number of rows in u and v\n",
    "        if k1 != k2:\n",
    "            raise ValueError(\n",
    "                f\"For row-wise comparison, u and v must have the same number of rows. \"\n",
    "                f\"(u has {k1}, v has {k2})\"\n",
    "            )\n",
    "\n",
    "        # Row-wise dot products\n",
    "        dot_uv = np.sum(u * v, axis=1)   # shape (k1,)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k1,)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "    else:\n",
    "        # Cartesian product: compute similarity for all row combinations\n",
    "        # dot_uv will have shape (k1, k2)\n",
    "        dot_uv = u @ v.T\n",
    "        # Norms for each row in u (shape (k1,)) and v (shape (k2,))\n",
    "        norm_u = np.linalg.norm(u, axis=1)\n",
    "        norm_v = np.linalg.norm(v, axis=1)\n",
    "        # Outer product of norms to match (k1, k2)\n",
    "        denom = np.outer(norm_u, norm_v)\n",
    "        return dot_uv / denom\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Single 1D vectors\n",
    "u_1d = [1, 2, 3]\n",
    "v_1d = [4, 5, 6]\n",
    "print(cosine_similarity(u_1d, v_1d))  # ~0.9746\n",
    "\n",
    "# Row-wise 2D\n",
    "u_2d = np.array([[1, 2], [3, 4]])\n",
    "v_2d = np.array([[5, 6], [7, 8]])\n",
    "print(cosine_similarity(u_2d, v_2d, cartesian_product=False))\n",
    "# array of length 2 (row-wise comparisons)\n",
    "\n",
    "# Cartesian product\n",
    "print(cosine_similarity(u_2d, v_2d, cartesian_product=True))\n",
    "# 2D array (2x2), each element is similarity of row i from u_2d with row j from v_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Performance Comparison: NumPy vs. SciPy ===\n",
      "\n",
      "Scenario: single_1d\n",
      "  NumPy time: 0.00001 seconds/run (best of 5)\n",
      "  SciPy time: 0.00001 seconds/run (best of 5)\n",
      "\n",
      "Scenario: one_row_vs_multi\n",
      "  NumPy time: 0.00094 seconds/run (best of 5)\n",
      "  SciPy time: 0.00115 seconds/run (best of 5)\n",
      "\n",
      "Scenario: row_wise_equal_rows\n",
      "  NumPy time: 0.00155 seconds/run (best of 5)\n",
      "  SciPy time: 0.91469 seconds/run (best of 5)\n",
      "\n",
      "Scenario: cartesian_product\n",
      "  NumPy time: 0.00603 seconds/run (best of 5)\n",
      "  SciPy time: 0.14682 seconds/run (best of 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'single_1d': {'numpy_time': 1.2133398558944464e-05,\n",
       "  'scipy_time': 1.3966800179332494e-05},\n",
       " 'one_row_vs_multi': {'numpy_time': 0.0009408915997482836,\n",
       "  'scipy_time': 0.0011457418091595172},\n",
       " 'row_wise_equal_rows': {'numpy_time': 0.0015512250014580787,\n",
       "  'scipy_time': 0.9146882999921218},\n",
       " 'cartesian_product': {'numpy_time': 0.006034700002055615,\n",
       "  'scipy_time': 0.1468225166085176}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(u, v, *, cartesian_product=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors.\n",
    "\n",
    "    If both inputs are 1D vectors, returns a float.\n",
    "    If one or both inputs are 2D arrays, returns either a 1D array (row-wise)\n",
    "    or a 2D array (cartesian product of rows) depending on the cartesian_product flag.\n",
    "\n",
    "    Behavior for row-wise (cartesian_product=False):\n",
    "      - If both arrays have the same number of rows, compares row i of u to row i of v.\n",
    "      - If one array has only 1 row, it is broadcast against each row of the other array.\n",
    "        (Returns a 1D array of length k, where k is the number of rows in the multi-row array.)\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k1 x n),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k2 x n).\n",
    "        cartesian_product (bool, optional):\n",
    "            - If False (default), the function compares rows in a one-to-one fashion (u[i] vs. v[i]),\n",
    "              **except** if one array has exactly 1 row and the other has multiple rows, in which case\n",
    "              that single row is broadcast to all rows of the other array.\n",
    "            - If True, computes the similarity for every combination of rows\n",
    "              (results in a 2D array of shape (k1, k2)).\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D numpy array if either u or v is 2D and cartesian_product=False.\n",
    "            - A 2D numpy array if cartesian_product=True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            - If the number of columns in u and v do not match.\n",
    "            - If cartesian_product=False, both arrays have multiple rows but differ in row count.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    # --- Case 1: Both are single 1D vectors\n",
    "    >>> u1d = [2, 0]\n",
    "    >>> v1d = [2, 0]\n",
    "    >>> cosine_similarity(u1d, v1d)\n",
    "    1.0\n",
    "\n",
    "    # --- Case 2: Single 1D vector vs. a 2D array (row-wise broadcast)\n",
    "    >>> import numpy as np\n",
    "    >>> M1 = np.array([\n",
    "    ...     [2, 0],\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res2 = cosine_similarity(u1d, M1)\n",
    "    >>> res2  # doctest: +ELLIPSIS\n",
    "    array([1.        , 0.        , 0.70710678...])\n",
    "\n",
    "    # --- Case 3: Two 2D arrays of different row lengths, cartesian_product=False (raises ValueError)\n",
    "    >>> M2_different = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> # Expect a ValueError because M1 has 3 rows and M2_different has 2 rows\n",
    "    >>> cosine_similarity(M1, M2_different, cartesian_product=False)  # doctest: +IGNORE_EXCEPTION_DETAIL\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: For row-wise comparison, u and v must have the same number of rows...\n",
    "\n",
    "    # --- Case 4: Two 2D arrays of the same number of rows, cartesian_product=False\n",
    "    >>> M2 = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 0],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res4 = cosine_similarity(M1, M2, cartesian_product=False)\n",
    "    >>> res4\n",
    "    array([0., 0., 1.])\n",
    "\n",
    "    # --- Case 5: Two 2D arrays of the same size, cartesian_product=True\n",
    "    # (computes every combination of rows => 3 x 3)\n",
    "    >>> res5 = cosine_similarity(M1, M2, cartesian_product=True)\n",
    "    >>> np.round(res5, 3)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    array([[0.   , 1.   , 0.707],\n",
    "           [1.   , 0.   , 0.707],\n",
    "           [0.707, 0.707, 1.   ]])\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # --------------- CASE 1: Both are single 1D vectors ---------------\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        if u.shape[0] != v.shape[0]:\n",
    "            raise ValueError(\"Vectors u and v must have the same dimension.\")\n",
    "        dot_uv = np.dot(u, v)\n",
    "        norm_u = np.linalg.norm(u)\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # --------------- CASE 2: At least one is 2D; ensure both are 2D ---------------\n",
    "    if u.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        u = u[np.newaxis, :]\n",
    "    if v.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        v = v[np.newaxis, :]\n",
    "\n",
    "    k1, n1 = u.shape\n",
    "    k2, n2 = v.shape\n",
    "\n",
    "    # Check that columns (vector dimension) match\n",
    "    if n1 != n2:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent dimensions: u has {n1} columns, v has {n2} columns.\"\n",
    "        )\n",
    "\n",
    "    # --------------- CARTESIAN PRODUCT ---------------\n",
    "    if cartesian_product:\n",
    "        # (k1 x k2) dot products\n",
    "        dot_uv = u @ v.T  # shape (k1, k2)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k2,)\n",
    "        # Outer product of norms => shape (k1, k2)\n",
    "        denom = np.outer(norm_u, norm_v)\n",
    "        return dot_uv / denom\n",
    "\n",
    "    # --------------- ROW-WISE (NOT CARTESIAN) ---------------\n",
    "    # 1) If one array has a single row (k=1), broadcast it against each row of the other\n",
    "    if k1 == 1 and k2 > 1:\n",
    "        # Broadcast u's single row against each row in v\n",
    "        dot_uv = np.sum(u[0] * v, axis=1)  # shape (k2,)\n",
    "        norm_u = np.linalg.norm(u[0])  # scalar\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k2,)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    if k2 == 1 and k1 > 1:\n",
    "        # Broadcast v's single row against each row in u\n",
    "        dot_uv = np.sum(u * v[0], axis=1)  # shape (k1,)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v[0])  # scalar\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # 2) Otherwise, require the same number of rows\n",
    "    if k1 != k2:\n",
    "        raise ValueError(\n",
    "            f\"For row-wise comparison, u and v must have the same number of rows. \"\n",
    "            f\"(u has {k1}, v has {k2})\"\n",
    "        )\n",
    "    dot_uv = np.sum(u * v, axis=1)  # shape (k1,)\n",
    "    norm_u = np.linalg.norm(u, axis=1)\n",
    "    norm_v = np.linalg.norm(v, axis=1)\n",
    "    return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine, cdist\n",
    "\n",
    "\n",
    "def cosine_similarity_scipy(u, v, *, cartesian_product=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors,\n",
    "    using SciPy's distance functions under the hood.\n",
    "\n",
    "    - If both inputs are 1D vectors, returns a float.\n",
    "    - If one or both inputs are 2D arrays, returns either a 1D array (row-wise)\n",
    "      or a 2D array (cartesian product of rows) depending on the\n",
    "      `cartesian_product` flag.\n",
    "\n",
    "    Behavior for row-wise (cartesian_product=False):\n",
    "      - If both arrays have the same number of rows (k), compares row i of u\n",
    "        with row i of v, resulting in a 1D array of length k.\n",
    "      - If one array has shape (1, d) and the other has shape (k, d), the single\n",
    "        row is broadcast to all k rows of the other array, returning a 1D array\n",
    "        of length k.\n",
    "      - Otherwise, raises a ValueError if row counts are incompatible.\n",
    "\n",
    "    Behavior for cartesian_product=True:\n",
    "      - Computes the similarity for every combination of rows in u and v,\n",
    "        returning a 2D array of shape (k1, k2).\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k1 x d),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k2 x d).\n",
    "        cartesian_product (bool, optional):\n",
    "            If True, computes a 2D matrix of size (k1, k2) for all pairs of rows.\n",
    "            If False, performs row-wise comparisons or broadcasting\n",
    "            as described above.\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D NumPy array if either u or v is 2D and cartesian_product=False.\n",
    "            - A 2D NumPy array if cartesian_product=True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            - If the number of columns (dimensions) in u and v do not match.\n",
    "            - If cartesian_product=False and row counts are incompatible.\n",
    "\n",
    "    Notes:\n",
    "        Internally, uses:\n",
    "         - `scipy.spatial.distance.cosine(u, v)` for single 1D vectors.\n",
    "         - `scipy.spatial.distance.cdist(u, v, metric=\"cosine\")` for multi-row data,\n",
    "           then converts distances to similarity via `1 - distance`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Single 1D vectors\n",
    "    >>> u1d = [2, 0]\n",
    "    >>> v1d = [2, 0]\n",
    "    >>> cosine_similarity_scipy(u1d, v1d)\n",
    "    1.0\n",
    "\n",
    "    >>> # Single 1D vector vs. 2D array (row-wise broadcast)\n",
    "    >>> import numpy as np\n",
    "    >>> M1 = np.array([\n",
    "    ...     [2, 0],\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res2 = cosine_similarity_scipy(u1d, M1)\n",
    "    >>> np.round(res2, 3)\n",
    "    array([1.   , 0.   , 0.707])\n",
    "\n",
    "    >>> # Two 2D arrays of different row lengths, cartesian_product=False\n",
    "    >>> M2_different = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> # Expect a ValueError if we try row-wise with mismatched rows\n",
    "    >>> cosine_similarity_scipy(M1, M2_different, cartesian_product=False)  # doctest: +IGNORE_EXCEPTION_DETAIL\n",
    "    Traceback (most recent call last):\n",
    "      ...\n",
    "    ValueError: ...\n",
    "\n",
    "    >>> # Two 2D arrays of the same row length (row-wise)\n",
    "    >>> M2 = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 0],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res4 = cosine_similarity_scipy(M1, M2, cartesian_product=False)\n",
    "    >>> res4\n",
    "    array([0., 0., 1.])\n",
    "\n",
    "    >>> # Cartesian product of all row pairs => (3 x 3) matrix\n",
    "    >>> res5 = cosine_similarity_scipy(M1, M2, cartesian_product=True)\n",
    "    >>> np.round(res5, 3)\n",
    "    array([[0.   , 1.   , 0.707],\n",
    "           [1.   , 0.   , 0.707],\n",
    "           [0.707, 0.707, 1.   ]])\n",
    "    \"\"\"\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # ----- CASE 1: Both are single 1D vectors -----\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        if u.shape[0] != v.shape[0]:\n",
    "            raise ValueError(\"Vectors u and v must have the same dimension.\")\n",
    "        # Cosine distance => 1 - similarity\n",
    "        dist = cosine(u, v)\n",
    "        return 1.0 - dist\n",
    "\n",
    "    # ----- CASE 2: At least one is 2D; ensure both are 2D -----\n",
    "    if u.ndim == 1:\n",
    "        u = u[np.newaxis, :]  # (1, d)\n",
    "    if v.ndim == 1:\n",
    "        v = v[np.newaxis, :]  # (1, d)\n",
    "\n",
    "    k1, d1 = u.shape\n",
    "    k2, d2 = v.shape\n",
    "\n",
    "    if d1 != d2:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent dimensions: u has {d1} columns, v has {d2} columns.\"\n",
    "        )\n",
    "\n",
    "    # ----- CARTESIAN PRODUCT -----\n",
    "    if cartesian_product:\n",
    "        # cdist => shape (k1, k2)\n",
    "        dist_matrix = cdist(u, v, metric=\"cosine\")\n",
    "        return 1.0 - dist_matrix\n",
    "\n",
    "    # ----- ROW-WISE (NOT CARTESIAN) -----\n",
    "    # If either array has 1 row, broadcast it against the rows of the other\n",
    "    if k1 == 1 and k2 > 1:\n",
    "        # => shape (1, k2)\n",
    "        dist_matrix = cdist(u, v, metric=\"cosine\")\n",
    "        # flatten => shape (k2,)\n",
    "        return 1.0 - dist_matrix.ravel()\n",
    "\n",
    "    if k2 == 1 and k1 > 1:\n",
    "        # => shape (k1, 1)\n",
    "        dist_matrix = cdist(u, v, metric=\"cosine\")\n",
    "        # flatten => shape (k1,)\n",
    "        return 1.0 - dist_matrix.ravel()\n",
    "\n",
    "    # Otherwise, require that k1 == k2\n",
    "    if k1 != k2:\n",
    "        raise ValueError(\n",
    "            f\"For row-wise comparison, u and v must have the same number of rows. \"\n",
    "            f\"(u has {k1}, v has {k2})\"\n",
    "        )\n",
    "\n",
    "    # cdist => shape (k1, k1)\n",
    "    dist_matrix = cdist(u, v, metric=\"cosine\")\n",
    "    # Row-wise => take diagonal => shape (k1,)\n",
    "    diag_distances = np.diag(dist_matrix)\n",
    "    return 1.0 - diag_distances\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "\n",
    "def test_cosine_similarity_performance(\n",
    "    *,\n",
    "    numpy_func=cosine_similarity,\n",
    "    scipy_func=cosine_similarity_scipy,\n",
    "    repeats=5,\n",
    "    number=5,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compares the performance of two cosine similarity functions (NumPy and SciPy)\n",
    "    under various scenarios.\n",
    "\n",
    "    Args:\n",
    "        numpy_func (callable): The NumPy-based cosine similarity function.\n",
    "        scipy_func (callable): The SciPy-based cosine similarity function.\n",
    "        repeats (int): How many times to repeat each timing scenario (timeit 'repeat').\n",
    "        number (int): How many times to run the timed operation per repeat (timeit 'number').\n",
    "        verbose (bool): Whether to print a summary of the results.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary containing timing results for each test scenario.\n",
    "              Example structure:\n",
    "              {\n",
    "                  \"single_1d\": {\"numpy_time\": ..., \"scipy_time\": ...},\n",
    "                  \"one_row_vs_multi\": {...},\n",
    "                  \"row_wise_equal_rows\": {...},\n",
    "                  \"cartesian_product\": {...}\n",
    "              }\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Test Data\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    # 1) Single 1D vectors (dimension = 512)\n",
    "    u_1d = np.random.rand(512)\n",
    "    v_1d = np.random.rand(512)\n",
    "\n",
    "    # 2) One-row vs. multi-row (for row-wise broadcast)\n",
    "    #    e.g. shape (1, 512) vs. shape (1000, 512)\n",
    "    u_one_row = np.random.rand(1, 512)\n",
    "    v_multi = np.random.rand(1000, 512)\n",
    "\n",
    "    # 3) Row-wise with equal rows\n",
    "    #    e.g. shape (2000, 256) each\n",
    "    u_equal = np.random.rand(2000, 256)\n",
    "    v_equal = np.random.rand(2000, 256)\n",
    "\n",
    "    # 4) Cartesian product with moderately sized arrays\n",
    "    #    shape (800, 256) each => result is (800 x 800) distance matrix\n",
    "    u_cart = np.random.rand(800, 256)\n",
    "    v_cart = np.random.rand(800, 256)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Helper function to measure a scenario\n",
    "    # ------------------------------------------------\n",
    "    def measure_time(stmt, globals_dict):\n",
    "        \"\"\"\n",
    "        Measures execution time of `stmt` using the timeit.repeat function,\n",
    "        returns the best timing out of 'repeats' repeats, each doing 'number' runs.\n",
    "        \"\"\"\n",
    "        times = timeit.repeat(stmt, repeat=repeats, number=number, globals=globals_dict)\n",
    "        best_time = min(times) / number  # average time per run\n",
    "        return best_time\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Single 1D vectors\n",
    "    # ------------------------------------------------\n",
    "    globals_single_1d = {\n",
    "        \"u\": u_1d,\n",
    "        \"v\": v_1d,\n",
    "        \"numpy_func\": numpy_func,\n",
    "        \"scipy_func\": scipy_func,\n",
    "    }\n",
    "    numpy_time = measure_time(\"numpy_func(u, v)\", globals_single_1d)\n",
    "    scipy_time = measure_time(\"scipy_func(u, v)\", globals_single_1d)\n",
    "    results[\"single_1d\"] = {\n",
    "        \"numpy_time\": numpy_time,\n",
    "        \"scipy_time\": scipy_time,\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # One-row vs. multi-row\n",
    "    # ------------------------------------------------\n",
    "    globals_one_vs_multi = {\n",
    "        \"u\": u_one_row,\n",
    "        \"v\": v_multi,\n",
    "        \"numpy_func\": numpy_func,\n",
    "        \"scipy_func\": scipy_func,\n",
    "    }\n",
    "    numpy_time = measure_time(\n",
    "        \"numpy_func(u, v, cartesian_product=False)\", globals_one_vs_multi\n",
    "    )\n",
    "    scipy_time = measure_time(\n",
    "        \"scipy_func(u, v, cartesian_product=False)\", globals_one_vs_multi\n",
    "    )\n",
    "    results[\"one_row_vs_multi\"] = {\n",
    "        \"numpy_time\": numpy_time,\n",
    "        \"scipy_time\": scipy_time,\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Row-wise with equal rows\n",
    "    # ------------------------------------------------\n",
    "    globals_equal_rows = {\n",
    "        \"u\": u_equal,\n",
    "        \"v\": v_equal,\n",
    "        \"numpy_func\": numpy_func,\n",
    "        \"scipy_func\": scipy_func,\n",
    "    }\n",
    "    numpy_time = measure_time(\n",
    "        \"numpy_func(u, v, cartesian_product=False)\", globals_equal_rows\n",
    "    )\n",
    "    scipy_time = measure_time(\n",
    "        \"scipy_func(u, v, cartesian_product=False)\", globals_equal_rows\n",
    "    )\n",
    "    results[\"row_wise_equal_rows\"] = {\n",
    "        \"numpy_time\": numpy_time,\n",
    "        \"scipy_time\": scipy_time,\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Cartesian product\n",
    "    # ------------------------------------------------\n",
    "    globals_cart = {\n",
    "        \"u\": u_cart,\n",
    "        \"v\": v_cart,\n",
    "        \"numpy_func\": numpy_func,\n",
    "        \"scipy_func\": scipy_func,\n",
    "    }\n",
    "    numpy_time = measure_time(\"numpy_func(u, v, cartesian_product=True)\", globals_cart)\n",
    "    scipy_time = measure_time(\"scipy_func(u, v, cartesian_product=True)\", globals_cart)\n",
    "    results[\"cartesian_product\"] = {\n",
    "        \"numpy_time\": numpy_time,\n",
    "        \"scipy_time\": scipy_time,\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Performance Comparison: NumPy vs. SciPy ===\")\n",
    "        for scenario, times in results.items():\n",
    "            print(f\"\\nScenario: {scenario}\")\n",
    "            print(\n",
    "                f\"  NumPy time: {times['numpy_time']:.5f} seconds/run (best of {repeats})\"\n",
    "            )\n",
    "            print(\n",
    "                f\"  SciPy time: {times['scipy_time']:.5f} seconds/run (best of {repeats})\"\n",
    "            )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "test_cosine_similarity_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_similarity(u, v, *, cartesian_product=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors.\n",
    "\n",
    "    If both inputs are 1D vectors, returns a float.\n",
    "    If one or both inputs are 2D arrays, returns either a 1D array (row-wise)\n",
    "    or a 2D array (cartesian product of rows) depending on the cartesian_product flag.\n",
    "\n",
    "    Behavior for row-wise (cartesian_product=False):\n",
    "      - If both arrays have the same number of rows, compares row i of u to row i of v.\n",
    "      - If one array has only 1 row, it is broadcast against each row of the other array.\n",
    "        (Returns a 1D array of length k, where k is the number of rows in the multi-row array.)\n",
    "\n",
    "    Note: This function only uses numpy.\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k1 x n),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k2 x n).\n",
    "        cartesian_product (bool, optional):\n",
    "            - If False (default), the function compares rows in a one-to-one fashion (u[i] vs. v[i]),\n",
    "              **except** if one array has exactly 1 row and the other has multiple rows, in which case\n",
    "              that single row is broadcast to all rows of the other array.\n",
    "            - If True, computes the similarity for every combination of rows\n",
    "              (results in a 2D array of shape (k1, k2)).\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D numpy array if either u or v is 2D and cartesian_product=False.\n",
    "            - A 2D numpy array if cartesian_product=True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            - If the number of columns in u and v do not match.\n",
    "            - If cartesian_product=False, both arrays have multiple rows but differ in row count.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    # --- Case 1: Both are single 1D vectors\n",
    "    >>> u1d = [2, 0]\n",
    "    >>> v1d = [2, 0]\n",
    "    >>> float(cosine_similarity(u1d, v1d))\n",
    "    1.0\n",
    "\n",
    "    # --- Case 2: Single 1D vector vs. a 2D array (row-wise broadcast)\n",
    "    >>> import numpy as np\n",
    "    >>> M1 = np.array([\n",
    "    ...     [2, 0],\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res2 = cosine_similarity(u1d, M1)\n",
    "    >>> res2  # doctest: +ELLIPSIS\n",
    "    array([1.        , 0.        , 0.70710678...])\n",
    "\n",
    "    # --- Case 3: Two 2D arrays of different row lengths, cartesian_product=False (raises ValueError)\n",
    "    >>> M2_different = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> # Expect a ValueError because M1 has 3 rows and M2_different has 2 rows\n",
    "    >>> cosine_similarity(M1, M2_different, cartesian_product=False)  # doctest: +IGNORE_EXCEPTION_DETAIL\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: For row-wise comparison, u and v must have the same number of rows...\n",
    "\n",
    "    # --- Case 4: Two 2D arrays of the same number of rows, cartesian_product=False\n",
    "    >>> M2 = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 0],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res4 = cosine_similarity(M1, M2, cartesian_product=False)\n",
    "    >>> res4\n",
    "    array([0., 0., 1.])\n",
    "\n",
    "    # --- Case 5: Two 2D arrays of the same size, cartesian_product=True\n",
    "    # (computes every combination of rows => 3 x 3)\n",
    "    >>> res5 = cosine_similarity(M1, M2, cartesian_product=True)\n",
    "    >>> np.round(res5, 3)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    array([[0.   , 1.   , 0.707],\n",
    "           [1.   , 0.   , 0.707],\n",
    "           [0.707, 0.707, 1.   ]])\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # --------------- CASE 1: Both are single 1D vectors ---------------\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        if u.shape[0] != v.shape[0]:\n",
    "            raise ValueError(\"Vectors u and v must have the same dimension.\")\n",
    "        dot_uv = np.dot(u, v)\n",
    "        norm_u = np.linalg.norm(u)\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # --------------- CASE 2: At least one is 2D; ensure both are 2D ---------------\n",
    "    if u.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        u = u[np.newaxis, :]\n",
    "    if v.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        v = v[np.newaxis, :]\n",
    "\n",
    "    k1, n1 = u.shape\n",
    "    k2, n2 = v.shape\n",
    "\n",
    "    # Check that columns (vector dimension) match\n",
    "    if n1 != n2:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent dimensions: u has {n1} columns, v has {n2} columns.\"\n",
    "        )\n",
    "\n",
    "    # --------------- CARTESIAN PRODUCT ---------------\n",
    "    if cartesian_product:\n",
    "        # (k1 x k2) dot products\n",
    "        dot_uv = u @ v.T  # shape (k1, k2)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k2,)\n",
    "        # Outer product of norms => shape (k1, k2)\n",
    "        denom = np.outer(norm_u, norm_v)\n",
    "        return dot_uv / denom\n",
    "\n",
    "    # --------------- ROW-WISE (NOT CARTESIAN) ---------------\n",
    "    # 1) If one array has a single row (k=1), broadcast it against each row of the other\n",
    "    if k1 == 1 and k2 > 1:\n",
    "        # Broadcast u's single row against each row in v\n",
    "        dot_uv = np.sum(u[0] * v, axis=1)  # shape (k2,)\n",
    "        norm_u = np.linalg.norm(u[0])  # scalar\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k2,)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    if k2 == 1 and k1 > 1:\n",
    "        # Broadcast v's single row against each row in u\n",
    "        dot_uv = np.sum(u * v[0], axis=1)  # shape (k1,)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v[0])  # scalar\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # 2) Otherwise, require the same number of rows\n",
    "    if k1 != k2:\n",
    "        raise ValueError(\n",
    "            f\"For row-wise comparison, u and v must have the same number of rows. \"\n",
    "            f\"(u has {k1}, v has {k2})\"\n",
    "        )\n",
    "    dot_uv = np.sum(u * v, axis=1)  # shape (k1,)\n",
    "    norm_u = np.linalg.norm(u, axis=1)\n",
    "    norm_v = np.linalg.norm(v, axis=1)\n",
    "    return dot_uv / (norm_u * norm_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_vector:\n",
      "  NumPy: 0.0001 seconds (10 runs)\n",
      "  SciPy: 0.0001 seconds (10 runs)\n",
      "matrix_100:\n",
      "  NumPy: 0.0003 seconds (10 runs)\n",
      "  SciPy: 0.0112 seconds (10 runs)\n",
      "matrix_1000:\n",
      "  NumPy: 0.0021 seconds (10 runs)\n",
      "  SciPy: 1.0576 seconds (10 runs)\n",
      "matrix_10000:\n",
      "  NumPy: 0.0230 seconds (10 runs)\n",
      "  SciPy: 102.5846 seconds (10 runs)\n"
     ]
    }
   ],
   "source": [
    "from imbed.util import cosine_similarity, cosine_similarity_scipy\n",
    "import timeit \n",
    "\n",
    "# Function to benchmark performance\n",
    "def benchmark_cosine_similarity():\n",
    "    # Test cases\n",
    "    test_cases = {\n",
    "        \"single_vector\": (np.random.rand(128), np.random.rand(128)),\n",
    "        \"matrix_100\": (np.random.rand(100, 128), np.random.rand(100, 128)),\n",
    "        \"matrix_1000\": (np.random.rand(1000, 128), np.random.rand(1000, 128)),\n",
    "        \"matrix_10000\": (np.random.rand(10000, 128), np.random.rand(10000, 128)),\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for test_name, (u, v) in test_cases.items():\n",
    "        # Measure time for NumPy-based implementation\n",
    "        time_numpy = timeit.timeit(\n",
    "            lambda: cosine_similarity(u, v), number=10\n",
    "        )\n",
    "        # Measure time for SciPy-based implementation\n",
    "        time_scipy = timeit.timeit(\n",
    "            lambda: cosine_similarity_scipy(u, v), number=10\n",
    "        )\n",
    "        results[test_name] = {\n",
    "            \"time_numpy\": time_numpy,\n",
    "            \"time_scipy\": time_scipy,\n",
    "        }\n",
    "\n",
    "    # Print results\n",
    "    for test_name, times in results.items():\n",
    "        print(\n",
    "            f\"{test_name}:\\n\"\n",
    "            f\"  NumPy: {times['time_numpy']:.4f} seconds (10 runs)\\n\"\n",
    "            f\"  SciPy: {times['time_scipy']:.4f} seconds (10 runs)\"\n",
    "        )\n",
    "\n",
    "\n",
    "benchmark_cosine_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
