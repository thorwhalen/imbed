{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the work-in-progress (WIP) scrap for the `imbed` project.\n",
    "\n",
    "It is not meant to be run by all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Note: This cosine similarity function only uses numpy arrays, so is dependency-light-weight.\n",
    "#     Note tested for speed or memory though.\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors.\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k x n),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k x n).\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D numpy array if either u or v is a 2D array.\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # Case 1: Both are single vectors\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        dot_uv = np.dot(u, v)\n",
    "        norm_u = np.linalg.norm(u)\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # Case 2: One is a single vector, the other is a 2D matrix\n",
    "    if u.ndim == 1:\n",
    "        # Turn u into shape (1, n)\n",
    "        u = u[np.newaxis, :]\n",
    "    if v.ndim == 1:\n",
    "        # Turn v into shape (1, n)\n",
    "        v = v[np.newaxis, :]\n",
    "\n",
    "    # Now both u and v are 2D arrays. We want to compute row-wise similarities.\n",
    "    # If one array has k rows and the other has m rows, row-wise dot products\n",
    "    # across all pairs would yield a (k, m) matrix. But if typically you want\n",
    "    # them to have the same number of rows or one has just 1 row, you can adjust\n",
    "    # the code or usage. For now, let's assume each row in u is compared to the\n",
    "    # corresponding row in v, which requires they have the same number of rows.\n",
    "\n",
    "    # If you want each row in u to compare to the single row in v (i.e. v has shape (1, n)),\n",
    "    # that will broadcast properly, giving a (k, n) array for u * v, summed along axis=1.\n",
    "\n",
    "    # Dot products (row-wise)\n",
    "    dot_uv = np.sum(u * v, axis=1)\n",
    "\n",
    "    # Norms (row-wise)\n",
    "    norm_u = np.linalg.norm(u, axis=1)\n",
    "    norm_v = np.linalg.norm(v, axis=1)\n",
    "\n",
    "    # Cosine similarity per row\n",
    "    return dot_uv / (norm_u * norm_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9746318461970762\n"
     ]
    }
   ],
   "source": [
    "u = [1, 2, 3]\n",
    "v = [4, 5, 6]\n",
    "print(cosine_similarity(u, v))  # Output: 0.9746318461970762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26726124 0.45584231 0.50257071]\n"
     ]
    }
   ],
   "source": [
    "u = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "v = [1, 0, 0]\n",
    "print(cosine_similarity(u, v))  \n",
    "# Output: [0.26726124 0.45584231 0.50257071]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746318461970762"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed import cosine_similarity\n",
    "\n",
    "cosine_similarity(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class EmbeddingKNN:\n",
    "    def __init__(self, words, embeddings):\n",
    "        \"\"\"\n",
    "        Initialize with:\n",
    "          - words: list of w words\n",
    "          - embeddings: np.array of shape (w, n), each row is an embedding.\n",
    "        \"\"\"\n",
    "        self.words = words\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "        # Fit Nearest Neighbors with up to 10 neighbors using cosine distance\n",
    "        self.neigh = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "        self.neigh.fit(self.embeddings)\n",
    "\n",
    "    def translation_neighbors(self, trans_vect, base_vecs=None):\n",
    "        \"\"\"\n",
    "        For each vector in base_vecs (defaulting to self.embeddings), add trans_vect\n",
    "        to the vector, then find the closest embedding in self.embeddings.\n",
    "\n",
    "        :param trans_vect: A translation vector of shape (n,).\n",
    "        :param base_vecs: A matrix of shape (m, n). If None, uses self.embeddings.\n",
    "        :return: A list of (closest_word, cosine_distance) for each row of base_vecs.\n",
    "        \"\"\"\n",
    "        if base_vecs is None:\n",
    "            base_vecs = self.embeddings\n",
    "\n",
    "        # Add trans_vect to each row of base_vecs\n",
    "        translated_vecs = base_vecs + trans_vect\n",
    "\n",
    "        # Query the nearest neighbor (n_neighbors=1) for each translated vector\n",
    "        distances, indices = self.neigh.kneighbors(translated_vecs, n_neighbors=1)\n",
    "\n",
    "        # Build the result (closest_word, distance)\n",
    "        closest_word_list = []\n",
    "        for i in range(len(translated_vecs)):\n",
    "            idx = indices[i][0]       # The nearest neighbor index\n",
    "            dist = distances[i][0]    # The cosine distance\n",
    "            closest_word_list.append((self.words[idx], dist))\n",
    "\n",
    "        return closest_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words.shape=(52078, 1)\n"
     ]
    }
   ],
   "source": [
    "src = '/Users/thorwhalen/Dropbox/_odata/figiri/wordnet_words/words_embeddings.parquet'\n",
    "\n",
    "words = pd.read_parquet(src)\n",
    "print(f\"{words.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'aaa', 'aachen', 'aah', 'aalborg', 'aalst', 'aalto',\n",
       "       'aar', 'aardvark'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.index.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52078, 1536)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec = words.embedding.loc\n",
    "\n",
    "all_words_vecs = np.vstack(words.embedding.values)\n",
    "all_words_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacc = EmbeddingKNN(words.index.values, np.vstack(words.embedding.values))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "data = [{'name': 'apple', 'value': 3}, {'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]\n",
    "\n",
    "# Find 2 items with smallest 'value'\n",
    "smallest_by_value = heapq.nlargest(2, data, key=lambda x: x['value'])\n",
    "print(smallest_by_value)  # Output: [{'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "data = [{'name': 'apple', 'value': 3}, {'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]\n",
    "\n",
    "# Find 2 items with smallest 'value'\n",
    "k = 10\n",
    "smallest_by_value = heapq.nlargest(k, data, key=lambda x: cosine_similarity()\n",
    "print(smallest_by_value)  # Output: [{'name': 'banana', 'value': 1}, {'name': 'cherry', 'value': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "def find_nearest_neighbors(target_vec, word_list, knn_model=None):\n",
    "    \"\"\"\n",
    "    Finds the nearest neighbors of a given vector using the trained KNN model.\n",
    "\n",
    "    Args:\n",
    "        target_vec (np.ndarray): The target vector (n-dimensional).\n",
    "        knn_model (NearestNeighbors): Trained sklearn KNN model.\n",
    "        word_list (list): List of words corresponding to rows in the embedding matrix.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples (word, distance) for the nearest neighbors.\n",
    "    \"\"\"\n",
    "    if knn_model is None:\n",
    "        raise ValueError(\"knn_model must be provided.\")\n",
    "    else:\n",
    "        distances, indices = knn_model.kneighbors(target_vec.reshape(1, -1))\n",
    "        neighbors = [(word_list[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_neighbors = 100  # Number of nearest neighbors to find\n",
    "\n",
    "# Step 1: Train a NearestNeighbors model\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "knn.fit(all_words_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    ['man', 'woman'],\n",
    "    ['boy', 'girl'],\n",
    "    ['king', 'queen'],\n",
    "    ['father', 'mother'],\n",
    "    ['son', 'daughter'],\n",
    "    ['brother', 'sister'],\n",
    "    ['uncle', 'aunt'],\n",
    "    ['nephew', 'niece'],\n",
    "    ['husband', 'wife'],\n",
    "    ['grandfather', 'grandmother'],\n",
    "    ['grandson', 'granddaughter'],\n",
    "    # ['he', 'she'],\n",
    "    # ['his', 'her'],\n",
    "    # ['him', 'her'],\n",
    "]\n",
    "\n",
    "trans_vecs = {(pair[0], pair[1]): word_vec[pair[1]] - word_vec[pair[0]] for pair in pairs}\n",
    "vecs = np.array(list(trans_vecs.values()))\n",
    "mean_vec = vecs.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dacc.translation_neighbors(mean_vec, all_words_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15375</th>\n",
       "      <td>englishwoman</td>\n",
       "      <td>0.059379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19042</th>\n",
       "      <td>gentlewoman</td>\n",
       "      <td>0.059601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>actress</td>\n",
       "      <td>0.060443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25768</th>\n",
       "      <td>landlady</td>\n",
       "      <td>0.060760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25658</th>\n",
       "      <td>lady</td>\n",
       "      <td>0.061288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20576</th>\n",
       "      <td>handsome</td>\n",
       "      <td>0.100385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>businessman</td>\n",
       "      <td>0.100488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27797</th>\n",
       "      <td>man</td>\n",
       "      <td>0.100852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44356</th>\n",
       "      <td>strongman</td>\n",
       "      <td>0.101159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20884</th>\n",
       "      <td>headman</td>\n",
       "      <td>0.102410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52078 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  distance\n",
       "15375  englishwoman  0.059379\n",
       "19042   gentlewoman  0.059601\n",
       "488         actress  0.060443\n",
       "25768      landlady  0.060760\n",
       "25658          lady  0.061288\n",
       "...             ...       ...\n",
       "20576      handsome  0.100385\n",
       "6479    businessman  0.100488\n",
       "27797           man  0.100852\n",
       "44356     strongman  0.101159\n",
       "20884       headman  0.102410\n",
       "\n",
       "[52078 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a pandas pandas dataframe with a word column and a distance column from this t\n",
    "\n",
    "tt = pd.DataFrame(t, columns=['word', 'distance'])\n",
    "tt.sort_values('distance', ascending=True, inplace=True)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embedding    [0.03497309610247612, 0.003794316668063402, -0...\n",
       "Name: englishwoman, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.iloc[15375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbors = find_nearest_neighbors(mean_vec, words.index.values, knn, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('englishwoman', 0.6488416364242586),\n",
       " ('gentlewoman', 0.6514492275017839),\n",
       " ('actress', 0.661357856802595),\n",
       " ('landlady', 0.6651019032417215),\n",
       " ('lady', 0.671341027828316),\n",
       " ('schoolgirl', 0.6742232729238721),\n",
       " ('goddaughter', 0.6776582926827888),\n",
       " ('womanhood', 0.681937009735876),\n",
       " ('girlhood', 0.6843100376626591),\n",
       " ('kinswoman', 0.6864297869414873)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emilia', 0.1856053348206207),\n",
       " ('amelia', 0.46806522773982784),\n",
       " ('melia', 0.49728034334623095),\n",
       " ('elisa', 0.5167585876760002),\n",
       " ('silvia', 0.5349300795158866),\n",
       " ('molise', 0.5359479139491025),\n",
       " ('selma', 0.5632534638477151),\n",
       " ('ma', 0.5637456101948137),\n",
       " ('camelia', 0.5658067890279446),\n",
       " ('emile', 0.5695956263111385),\n",
       " ('ela', 0.5700265779662446),\n",
       " ('milord', 0.5701551230167076),\n",
       " ('arminius', 0.5704029512850921),\n",
       " ('parmelia', 0.5727260735708704),\n",
       " ('abelia', 0.5812744010549296),\n",
       " ('minerva', 0.5818079692613954),\n",
       " ('maia', 0.5836960554181392),\n",
       " ('carmine', 0.5897216682569613),\n",
       " ('romulus', 0.5902641981276877),\n",
       " ('male', 0.5916144864350306),\n",
       " ('lena', 0.5979485698736845),\n",
       " ('anna', 0.5981072501945826),\n",
       " ('mare', 0.5991993418873663),\n",
       " ('noemi', 0.6018002615988873),\n",
       " ('pomelo', 0.6031528296288499),\n",
       " ('malvasia', 0.6052748010527991),\n",
       " ('murillo', 0.605366251841285),\n",
       " ('attilio', 0.6054655484089878),\n",
       " ('elm', 0.6068193034487999),\n",
       " ('ermine', 0.6071094397610399),\n",
       " ('emu', 0.6071992568378295),\n",
       " ('proserpina', 0.6074394992100911),\n",
       " ('salerno', 0.607870483172039),\n",
       " ('apulia', 0.6085565481391807),\n",
       " ('milvus', 0.6093400454754743),\n",
       " ('susanna', 0.6099898668638382),\n",
       " ('sicily', 0.6107384780853063),\n",
       " ('umbria', 0.6107786482423723),\n",
       " ('remus', 0.6114762556466518),\n",
       " ('isabella', 0.6121759592911782),\n",
       " ('tilia', 0.6131919290352419),\n",
       " ('melena', 0.6132150987994526),\n",
       " ('milo', 0.6135363510656481),\n",
       " ('messily', 0.613592617886886),\n",
       " ('simeon', 0.6161008417950715),\n",
       " ('lydia', 0.6163942689729716),\n",
       " ('manda', 0.6166227301977781),\n",
       " ('mil', 0.6168500311977161),\n",
       " ('malachi', 0.6177681450836885),\n",
       " ('jerome', 0.6181713658064419),\n",
       " ('lysimachia', 0.6184703231730524),\n",
       " ('commelina', 0.6190969431331762),\n",
       " ('maria', 0.6194397165948221),\n",
       " ('aurelius', 0.61983242718997),\n",
       " ('benedick', 0.6198677516178139),\n",
       " ('mattole', 0.620089729823945),\n",
       " ('annona', 0.620323115755862),\n",
       " ('amenia', 0.6206088741041699),\n",
       " ('semolina', 0.6207866327255513),\n",
       " ('anselm', 0.6212450580711719),\n",
       " ('mari', 0.6217145842676157),\n",
       " ('melchior', 0.6220387248893477),\n",
       " ('aleppo', 0.6223260714629778),\n",
       " ('carolus', 0.6225365672907202),\n",
       " ('mary', 0.6227552378574446),\n",
       " ('maiolica', 0.6231333649637043),\n",
       " ('erato', 0.6242932105968075),\n",
       " ('mann', 0.6245044047972291),\n",
       " ('mauldin', 0.6256365739650628),\n",
       " ('iago', 0.6270265681959428),\n",
       " ('merciless', 0.6275263415289469),\n",
       " ('iliamna', 0.627532213132883),\n",
       " ('amon', 0.6277661954129099),\n",
       " ('felicia', 0.6309059831744622),\n",
       " ('etruria', 0.6309814644377459),\n",
       " ('mina', 0.6311794952162055),\n",
       " ('roma', 0.6319360007591196),\n",
       " ('bruno', 0.6320869683767187),\n",
       " ('beatrice', 0.6324902698142716),\n",
       " ('meles', 0.6327258875210018),\n",
       " ('sylvanus', 0.6328719110507329),\n",
       " ('damon', 0.63312926819845),\n",
       " ('pimento', 0.6331911846143484),\n",
       " ('merl', 0.633434829766749),\n",
       " ('amia', 0.6334577765795473),\n",
       " ('melpomene', 0.6334836214487318),\n",
       " ('calluna', 0.6335948804107613),\n",
       " ('romeo', 0.63401143564329),\n",
       " ('melissa', 0.634722201358296),\n",
       " ('mem', 0.6351069020954393),\n",
       " ('marshal', 0.6353546178752638),\n",
       " ('mantua', 0.6358407280797215),\n",
       " ('alfred', 0.6361459093938874),\n",
       " ('sylva', 0.6364120808051602),\n",
       " ('mamma', 0.6367383659681383),\n",
       " ('animus', 0.6367719183618668),\n",
       " ('silvanus', 0.6369563476914188),\n",
       " ('edward', 0.6369850967566788),\n",
       " ('liguria', 0.6371657007882378),\n",
       " ('morello', 0.6372160020741473)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = word_vec['emilia'] - word_vec['female'] + word_vec['male']\n",
    "find_nearest_neighbors(v, knn, words.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6086880638995171"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average cosine similarity between mean_vec and the vecs\n",
    "from imbed import cosine_similarity\n",
    "\n",
    "mean_similarity_of_targets = np.mean([cosine_similarity(mean_vec, vec) for vec in vecs])\n",
    "mean_similarity_of_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52078,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Compute cosine distances\n",
    "cosine_distances = cdist(all_words_vecs, mean_vec.reshape(1, -1), metric='cosine').flatten()\n",
    "\n",
    "cosine_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6685385560757456"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed import cosine_similarity\n",
    "\n",
    "cosine_similarity(word_vec['emilia'], word_vec['amelia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average cosine similarity between mean_vec and the vecs\n",
    "from imbed import cosine_similarity\n",
    "\n",
    "mean_similarity_of_targets = np.mean([cosine_similarity(mean_vec, vec) for vec in vecs])\n",
    "mean_similarity_of_other_words = np.mean([cosine_similarity(mean_vec, vec) for vec in vecs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395650570848009"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = all_words_vecs[0]\n",
    "all_words_vecs[:10]\n",
    "cosine_similarity(t, all_words_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The k-d to 2-d problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After embedding your objects of interest into k-dimensional vectors, you might further embed them into two or three dimensions for visualization. This process inevitably loses some information and introduces distortions, but it's still valuable. The initial conversion of texts or images into numerical vectors also involved information loss, yet it was useful for your specific goals.\n",
    "\n",
    "Dimensionality reduction typically results in losing some details. The key is to preserve the essential information (the \"signal\") and minimize the loss of less important details (the \"noise\"). Done well, this can be beneficial, especially if it enhances the signal-to-noise ratio.\n",
    "\n",
    "This principle also applies to compressing vectors for visualization. The aim is to present complex data usefully and intuitively, enabling analysts to spot patterns and gain insights. It's a balance between maintaining utility and practical implementation when transforming k-dimensional data into two-dimensional forms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"504pt\" height=\"764pt\"\n",
       " viewBox=\"0.00 0.00 504.44 764.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 760)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-760 500.44,-760 500.44,4 -4,4\"/>\n",
       "<!-- src_folder -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>src_folder</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.92\" cy=\"-738\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.92\" y=\"-732.95\" font-family=\"Times,serif\" font-size=\"14.00\">src_folder</text>\n",
       "</g>\n",
       "<!-- pjoin -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>pjoin</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.92\" cy=\"-666\" rx=\"29.86\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.92\" y=\"-660.95\" font-family=\"Times,serif\" font-size=\"14.00\">pjoin</text>\n",
       "</g>\n",
       "<!-- src_folder&#45;&gt;pjoin -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>src_folder&#45;&gt;pjoin</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.92,-719.7C280.92,-712.41 280.92,-703.73 280.92,-695.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.42,-695.62 280.92,-685.62 277.42,-695.62 284.42,-695.62\"/>\n",
       "</g>\n",
       "<!-- embeddings_filepath -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>embeddings_filepath</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"93.92\" cy=\"-594\" rx=\"88.71\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.92\" y=\"-588.95\" font-family=\"Times,serif\" font-size=\"14.00\">embeddings_filepath</text>\n",
       "</g>\n",
       "<!-- pjoin&#45;&gt;embeddings_filepath -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>pjoin&#45;&gt;embeddings_filepath</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.09,-655.7C227.97,-645.18 181.38,-627.74 145.33,-614.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"147,-611.13 136.41,-610.9 144.55,-617.69 147,-611.13\"/>\n",
       "</g>\n",
       "<!-- citations_hcp3_src -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>citations_hcp3_src</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.92\" cy=\"-594\" rx=\"80.01\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.92\" y=\"-588.95\" font-family=\"Times,serif\" font-size=\"14.00\">citations_hcp3_src</text>\n",
       "</g>\n",
       "<!-- pjoin&#45;&gt;citations_hcp3_src -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>pjoin&#45;&gt;citations_hcp3_src</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.92,-647.7C280.92,-640.41 280.92,-631.73 280.92,-623.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.42,-623.62 280.92,-613.62 277.42,-623.62 284.42,-623.62\"/>\n",
       "</g>\n",
       "<!-- info_filepath -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>info_filepath</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"437.92\" cy=\"-594\" rx=\"58.52\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.92\" y=\"-588.95\" font-family=\"Times,serif\" font-size=\"14.00\">info_filepath</text>\n",
       "</g>\n",
       "<!-- pjoin&#45;&gt;info_filepath -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>pjoin&#45;&gt;info_filepath</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M304.43,-654.52C328.35,-643.85 365.97,-627.08 395.18,-614.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"396.43,-617.33 404.14,-610.06 393.58,-610.94 396.43,-617.33\"/>\n",
       "</g>\n",
       "<!-- embeddings_hcp2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>embeddings_hcp2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"93.92\" cy=\"-522\" rx=\"78.48\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.92\" y=\"-516.95\" font-family=\"Times,serif\" font-size=\"14.00\">embeddings_hcp2</text>\n",
       "</g>\n",
       "<!-- embeddings_filepath&#45;&gt;embeddings_hcp2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>embeddings_filepath&#45;&gt;embeddings_hcp2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.92,-575.7C93.92,-568.41 93.92,-559.73 93.92,-551.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"97.42,-551.62 93.92,-541.62 90.42,-551.62 97.42,-551.62\"/>\n",
       "</g>\n",
       "<!-- _citations_hcp3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>_citations_hcp3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.92\" cy=\"-522\" rx=\"69.26\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.92\" y=\"-516.95\" font-family=\"Times,serif\" font-size=\"14.00\">_citations_hcp3</text>\n",
       "</g>\n",
       "<!-- citations_hcp3_src&#45;&gt;_citations_hcp3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>citations_hcp3_src&#45;&gt;_citations_hcp3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.92,-575.7C280.92,-568.41 280.92,-559.73 280.92,-551.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.42,-551.62 280.92,-541.62 277.42,-551.62 284.42,-551.62\"/>\n",
       "</g>\n",
       "<!-- info_hcp2 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>info_hcp2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"437.92\" cy=\"-378\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.92\" y=\"-372.95\" font-family=\"Times,serif\" font-size=\"14.00\">info_hcp2</text>\n",
       "</g>\n",
       "<!-- info_filepath&#45;&gt;info_hcp2 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>info_filepath&#45;&gt;info_hcp2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437.92,-575.85C437.92,-539.14 437.92,-452.66 437.92,-407.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"441.42,-407.75 437.92,-397.75 434.42,-407.75 441.42,-407.75\"/>\n",
       "</g>\n",
       "<!-- embeddings_ids -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>embeddings_ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"100.92\" cy=\"-450\" rx=\"71.31\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.92\" y=\"-444.95\" font-family=\"Times,serif\" font-size=\"14.00\">embeddings_ids</text>\n",
       "</g>\n",
       "<!-- embeddings_hcp2&#45;&gt;embeddings_ids -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>embeddings_hcp2&#45;&gt;embeddings_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M95.65,-503.7C96.38,-496.41 97.25,-487.73 98.07,-479.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.55,-479.91 99.06,-469.61 94.58,-479.21 101.55,-479.91\"/>\n",
       "</g>\n",
       "<!-- mean_aggregates -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>mean_aggregates</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"170.92\" cy=\"-162\" rx=\"75.41\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.92\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">mean_aggregates</text>\n",
       "</g>\n",
       "<!-- embeddings_hcp2&#45;&gt;mean_aggregates -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>embeddings_hcp2&#45;&gt;mean_aggregates</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.31,-505.13C47.57,-496.18 31.08,-483.62 20.92,-468 -1.13,-434.09 1.92,-419.45 1.92,-379 1.92,-379 1.92,-379 1.92,-305 1.92,-264.55 -5.77,-246.39 20.92,-216 39.75,-194.57 67.79,-181.81 94.56,-174.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"95.26,-177.63 104.06,-171.73 93.5,-170.86 95.26,-177.63\"/>\n",
       "</g>\n",
       "<!-- _citations_ids -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>_citations_ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"251.92\" cy=\"-450\" rx=\"62.1\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.92\" y=\"-444.95\" font-family=\"Times,serif\" font-size=\"14.00\">_citations_ids</text>\n",
       "</g>\n",
       "<!-- _citations_hcp3&#45;&gt;_citations_ids -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>_citations_hcp3&#45;&gt;_citations_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M273.75,-503.7C270.63,-496.15 266.89,-487.12 263.39,-478.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"266.65,-477.4 259.59,-469.5 260.18,-480.08 266.65,-477.4\"/>\n",
       "</g>\n",
       "<!-- citations_hcp3 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>citations_hcp3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"296.92\" cy=\"-306\" rx=\"64.66\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"296.92\" y=\"-300.95\" font-family=\"Times,serif\" font-size=\"14.00\">citations_hcp3</text>\n",
       "</g>\n",
       "<!-- _citations_hcp3&#45;&gt;citations_hcp3 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>_citations_hcp3&#45;&gt;citations_hcp3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.09,-504.22C308.13,-494.61 318.14,-481.75 322.92,-468 338.66,-422.79 322.27,-367.08 309.33,-334.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"312.6,-333.21 305.53,-325.32 306.14,-335.9 312.6,-333.21\"/>\n",
       "</g>\n",
       "<!-- missing_ids -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>missing_ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"251.92\" cy=\"-378\" rx=\"55.45\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.92\" y=\"-372.95\" font-family=\"Times,serif\" font-size=\"14.00\">missing_ids</text>\n",
       "</g>\n",
       "<!-- _citations_ids&#45;&gt;missing_ids -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>_citations_ids&#45;&gt;missing_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.92,-431.7C251.92,-424.41 251.92,-415.73 251.92,-407.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"255.42,-407.62 251.92,-397.62 248.42,-407.62 255.42,-407.62\"/>\n",
       "</g>\n",
       "<!-- embeddings_ids&#45;&gt;missing_ids -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>embeddings_ids&#45;&gt;missing_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.06,-433.64C156.6,-423.19 186.58,-409.29 210.66,-398.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.95,-401.39 219.55,-394.01 209.01,-395.04 211.95,-401.39\"/>\n",
       "</g>\n",
       "<!-- missing_ids&#45;&gt;citations_hcp3 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>missing_ids&#45;&gt;citations_hcp3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M262.82,-360.05C267.96,-352.06 274.21,-342.33 279.95,-333.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.85,-335.37 285.31,-325.06 276.96,-331.58 282.85,-335.37\"/>\n",
       "</g>\n",
       "<!-- cited_by -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>cited_by</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"240.92\" cy=\"-234\" rx=\"42.65\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.92\" y=\"-228.95\" font-family=\"Times,serif\" font-size=\"14.00\">cited_by</text>\n",
       "</g>\n",
       "<!-- citations_hcp3&#45;&gt;cited_by -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>citations_hcp3&#45;&gt;cited_by</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M283.37,-288.05C276.67,-279.68 268.45,-269.4 261.03,-260.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.89,-258.11 254.91,-252.49 258.43,-262.48 263.89,-258.11\"/>\n",
       "</g>\n",
       "<!-- citations_of -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>citations_of</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"355.92\" cy=\"-234\" rx=\"54.42\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"355.92\" y=\"-228.95\" font-family=\"Times,serif\" font-size=\"14.00\">citations_of</text>\n",
       "</g>\n",
       "<!-- citations_hcp3&#45;&gt;citations_of -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>citations_hcp3&#45;&gt;citations_of</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M311.21,-288.05C318.16,-279.8 326.67,-269.7 334.4,-260.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"337.03,-262.85 340.8,-252.95 331.68,-258.34 337.03,-262.85\"/>\n",
       "</g>\n",
       "<!-- ids -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"355.92\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"355.92\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">ids</text>\n",
       "</g>\n",
       "<!-- citations_of&#45;&gt;ids -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>citations_of&#45;&gt;ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M355.92,-215.7C355.92,-208.41 355.92,-199.73 355.92,-191.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"359.42,-191.62 355.92,-181.62 352.42,-191.62 359.42,-191.62\"/>\n",
       "</g>\n",
       "<!-- citations_of&#45;&gt;mean_aggregates -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>citations_of&#45;&gt;mean_aggregates</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M321.13,-219.83C292.73,-209.09 252.25,-193.77 220.46,-181.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.05,-178.6 211.46,-178.34 219.58,-185.15 222.05,-178.6\"/>\n",
       "</g>\n",
       "<!-- planar_mean_embeddings -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>planar_mean_embeddings</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"268.92\" cy=\"-90\" rx=\"108.67\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"268.92\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">planar_mean_embeddings</text>\n",
       "</g>\n",
       "<!-- mean_aggregates&#45;&gt;planar_mean_embeddings -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>mean_aggregates&#45;&gt;planar_mean_embeddings</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.15,-144.41C206.66,-135.48 222.3,-124.3 236.04,-114.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"237.85,-117.5 243.95,-108.84 233.78,-111.8 237.85,-117.5\"/>\n",
       "</g>\n",
       "<!-- mean_aggregator -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>mean_aggregator</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.92\" cy=\"-234\" rx=\"75.41\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.92\" y=\"-228.95\" font-family=\"Times,serif\" font-size=\"14.00\">mean_aggregator</text>\n",
       "</g>\n",
       "<!-- mean_aggregator&#45;&gt;mean_aggregates -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>mean_aggregator&#45;&gt;mean_aggregates</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M120.9,-216.05C128.84,-207.63 138.6,-197.28 147.38,-187.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"149.74,-190.57 154.06,-180.89 144.65,-185.77 149.74,-190.57\"/>\n",
       "</g>\n",
       "<!-- planar_mean_embeddings_with_ids -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>planar_mean_embeddings_with_ids</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"336.92\" cy=\"-18\" rx=\"145.01\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"336.92\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">planar_mean_embeddings_with_ids</text>\n",
       "</g>\n",
       "<!-- planar_mean_embeddings&#45;&gt;planar_mean_embeddings_with_ids -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>planar_mean_embeddings&#45;&gt;planar_mean_embeddings_with_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M285.38,-72.05C293.45,-63.75 303.33,-53.58 312.27,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.63,-46.97 319.09,-37.36 309.61,-42.09 314.63,-46.97\"/>\n",
       "</g>\n",
       "<!-- info_hcp2&#45;&gt;planar_mean_embeddings_with_ids -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>info_hcp2&#45;&gt;planar_mean_embeddings_with_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437.92,-359.51C437.92,-332.71 437.92,-279.87 437.92,-235 437.92,-235 437.92,-235 437.92,-161 437.92,-112.61 398.49,-69.25 368.91,-43.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"371.16,-40.86 361.25,-37.1 366.66,-46.21 371.16,-40.86\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2bf00f280>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from i2.footprints import attribute_dependencies, init_argument_names\n",
    "from imbed.mdat.hcp import Hcp3Dacc\n",
    "from meshed.itools import graphviz_digraph\n",
    "\n",
    "deps = dict(attribute_dependencies(Hcp3Dacc))\n",
    "\n",
    "graphviz_digraph(deps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/thorwhalen/Dropbox/_odata/figiri/hcp'\n",
    "dacc = Hcp3Dacc(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dacc.info_hcp2)=354165, 308135, dacc.citations_and_titles.shape=(308135, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cited_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2138790588, 2013150886]</td>\n",
       "      <td>245658</td>\n",
       "      <td>Standardized low-resolution brain electromagne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1994893189, 2158553737, 1604916109, 202841896...</td>\n",
       "      <td>718838</td>\n",
       "      <td>Pathophysiology of obsessiveâcompulsive diso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2114205159, 2161774890, 1965693998, 211020414...</td>\n",
       "      <td>831416</td>\n",
       "      <td>Remote Ischemic Preconditioning Provides Early...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2025976960, 2172013173]</td>\n",
       "      <td>898828</td>\n",
       "      <td>The Unknown Mechanism of the Overtraining Synd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2138019504, 2127271355, 2103972604]</td>\n",
       "      <td>905619</td>\n",
       "      <td>Revisiting Frank-Wolfe: Projection-Free Sparse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cited_ids      id  \\\n",
       "0                           [2138790588, 2013150886]  245658   \n",
       "2  [1994893189, 2158553737, 1604916109, 202841896...  718838   \n",
       "4  [2114205159, 2161774890, 1965693998, 211020414...  831416   \n",
       "5                           [2025976960, 2172013173]  898828   \n",
       "6               [2138019504, 2127271355, 2103972604]  905619   \n",
       "\n",
       "                                               title  \n",
       "0  Standardized low-resolution brain electromagne...  \n",
       "2  Pathophysiology of obsessiveâcompulsive diso...  \n",
       "4  Remote Ischemic Preconditioning Provides Early...  \n",
       "5  The Unknown Mechanism of the Overtraining Synd...  \n",
       "6  Revisiting Frank-Wolfe: Projection-Free Sparse...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dacc.citations_and_titles\n",
    "print(f\"{len(dacc.info_hcp2)=}, {len(dacc.citations_of)}, {dacc.citations_and_titles.shape=}\")\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Speed comparison between numpy and scipy cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9746318461970762\n",
      "[0.97341717 0.99716412]\n",
      "[[0.97341717 0.96761727]\n",
      " [0.99868766 0.99716412]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(u, v, *, cartesian_product=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors.\n",
    "\n",
    "    If both inputs are 1D vectors, returns a float.\n",
    "    If one or both inputs are 2D arrays, returns either a 1D array (row-wise)\n",
    "    or a 2D array (cartesian product of rows) depending on the cartesian_product flag.\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k x n),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k x n).\n",
    "        cartesian_product (bool, optional):\n",
    "            - If False (default), the function compares rows in a one-to-one fashion.\n",
    "              Expects the same number of rows in u and v.\n",
    "            - If True, computes the similarity for every combination of rows\n",
    "              (results in a 2D array).\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D numpy array if either u or v is a 2D array and cartesian_product=False.\n",
    "            - A 2D numpy array if cartesian_product=True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the number of columns in u and v do not match,\n",
    "                    or if (cartesian_product=False) but u and v have different row counts.\n",
    "    \"\"\"\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Case 1: Both are single 1D vectors\n",
    "    # -----------------------------\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        if u.shape[0] != v.shape[0]:\n",
    "            raise ValueError(\"Vectors u and v must have the same dimension.\")\n",
    "        dot_uv = np.dot(u, v)\n",
    "        norm_u = np.linalg.norm(u)\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Case 2: At least one is 2D\n",
    "    # Ensure both are 2D\n",
    "    # -----------------------------\n",
    "    if u.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        u = u[np.newaxis, :]\n",
    "    if v.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        v = v[np.newaxis, :]\n",
    "\n",
    "    # Now u.shape = (k1, n1), v.shape = (k2, n2)\n",
    "    k1, n1 = u.shape\n",
    "    k2, n2 = v.shape\n",
    "\n",
    "    # Validate the number of columns (dimensions)\n",
    "    if n1 != n2:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent dimensions: u has {n1} columns, v has {n2} columns.\"\n",
    "        )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Non-cartesian (row-wise) vs cartesian product\n",
    "    # -----------------------------\n",
    "    if not cartesian_product:\n",
    "        # Requires the same number of rows in u and v\n",
    "        if k1 != k2:\n",
    "            raise ValueError(\n",
    "                f\"For row-wise comparison, u and v must have the same number of rows. \"\n",
    "                f\"(u has {k1}, v has {k2})\"\n",
    "            )\n",
    "\n",
    "        # Row-wise dot products\n",
    "        dot_uv = np.sum(u * v, axis=1)   # shape (k1,)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k1,)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "    else:\n",
    "        # Cartesian product: compute similarity for all row combinations\n",
    "        # dot_uv will have shape (k1, k2)\n",
    "        dot_uv = u @ v.T\n",
    "        # Norms for each row in u (shape (k1,)) and v (shape (k2,))\n",
    "        norm_u = np.linalg.norm(u, axis=1)\n",
    "        norm_v = np.linalg.norm(v, axis=1)\n",
    "        # Outer product of norms to match (k1, k2)\n",
    "        denom = np.outer(norm_u, norm_v)\n",
    "        return dot_uv / denom\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Single 1D vectors\n",
    "u_1d = [1, 2, 3]\n",
    "v_1d = [4, 5, 6]\n",
    "print(cosine_similarity(u_1d, v_1d))  # ~0.9746\n",
    "\n",
    "# Row-wise 2D\n",
    "u_2d = np.array([[1, 2], [3, 4]])\n",
    "v_2d = np.array([[5, 6], [7, 8]])\n",
    "print(cosine_similarity(u_2d, v_2d, cartesian_product=False))\n",
    "# array of length 2 (row-wise comparisons)\n",
    "\n",
    "# Cartesian product\n",
    "print(cosine_similarity(u_2d, v_2d, cartesian_product=True))\n",
    "# 2D array (2x2), each element is similarity of row i from u_2d with row j from v_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Performance Comparison: NumPy vs. SciPy ===\n",
      "\n",
      "Scenario: single_1d\n",
      "  NumPy time: 0.00001 seconds/run (best of 5)\n",
      "  SciPy time: 0.00001 seconds/run (best of 5)\n",
      "\n",
      "Scenario: one_row_vs_multi\n",
      "  NumPy time: 0.00094 seconds/run (best of 5)\n",
      "  SciPy time: 0.00115 seconds/run (best of 5)\n",
      "\n",
      "Scenario: row_wise_equal_rows\n",
      "  NumPy time: 0.00155 seconds/run (best of 5)\n",
      "  SciPy time: 0.91469 seconds/run (best of 5)\n",
      "\n",
      "Scenario: cartesian_product\n",
      "  NumPy time: 0.00603 seconds/run (best of 5)\n",
      "  SciPy time: 0.14682 seconds/run (best of 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'single_1d': {'numpy_time': 1.2133398558944464e-05,\n",
       "  'scipy_time': 1.3966800179332494e-05},\n",
       " 'one_row_vs_multi': {'numpy_time': 0.0009408915997482836,\n",
       "  'scipy_time': 0.0011457418091595172},\n",
       " 'row_wise_equal_rows': {'numpy_time': 0.0015512250014580787,\n",
       "  'scipy_time': 0.9146882999921218},\n",
       " 'cartesian_product': {'numpy_time': 0.006034700002055615,\n",
       "  'scipy_time': 0.1468225166085176}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(u, v, *, cartesian_product=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors.\n",
    "\n",
    "    If both inputs are 1D vectors, returns a float.\n",
    "    If one or both inputs are 2D arrays, returns either a 1D array (row-wise)\n",
    "    or a 2D array (cartesian product of rows) depending on the cartesian_product flag.\n",
    "\n",
    "    Behavior for row-wise (cartesian_product=False):\n",
    "      - If both arrays have the same number of rows, compares row i of u to row i of v.\n",
    "      - If one array has only 1 row, it is broadcast against each row of the other array.\n",
    "        (Returns a 1D array of length k, where k is the number of rows in the multi-row array.)\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k1 x n),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k2 x n).\n",
    "        cartesian_product (bool, optional):\n",
    "            - If False (default), the function compares rows in a one-to-one fashion (u[i] vs. v[i]),\n",
    "              **except** if one array has exactly 1 row and the other has multiple rows, in which case\n",
    "              that single row is broadcast to all rows of the other array.\n",
    "            - If True, computes the similarity for every combination of rows\n",
    "              (results in a 2D array of shape (k1, k2)).\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D numpy array if either u or v is 2D and cartesian_product=False.\n",
    "            - A 2D numpy array if cartesian_product=True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            - If the number of columns in u and v do not match.\n",
    "            - If cartesian_product=False, both arrays have multiple rows but differ in row count.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    # --- Case 1: Both are single 1D vectors\n",
    "    >>> u1d = [2, 0]\n",
    "    >>> v1d = [2, 0]\n",
    "    >>> cosine_similarity(u1d, v1d)\n",
    "    1.0\n",
    "\n",
    "    # --- Case 2: Single 1D vector vs. a 2D array (row-wise broadcast)\n",
    "    >>> import numpy as np\n",
    "    >>> M1 = np.array([\n",
    "    ...     [2, 0],\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res2 = cosine_similarity(u1d, M1)\n",
    "    >>> res2  # doctest: +ELLIPSIS\n",
    "    array([1.        , 0.        , 0.70710678...])\n",
    "\n",
    "    # --- Case 3: Two 2D arrays of different row lengths, cartesian_product=False (raises ValueError)\n",
    "    >>> M2_different = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> # Expect a ValueError because M1 has 3 rows and M2_different has 2 rows\n",
    "    >>> cosine_similarity(M1, M2_different, cartesian_product=False)  # doctest: +IGNORE_EXCEPTION_DETAIL\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: For row-wise comparison, u and v must have the same number of rows...\n",
    "\n",
    "    # --- Case 4: Two 2D arrays of the same number of rows, cartesian_product=False\n",
    "    >>> M2 = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 0],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res4 = cosine_similarity(M1, M2, cartesian_product=False)\n",
    "    >>> res4\n",
    "    array([0., 0., 1.])\n",
    "\n",
    "    # --- Case 5: Two 2D arrays of the same size, cartesian_product=True\n",
    "    # (computes every combination of rows => 3 x 3)\n",
    "    >>> res5 = cosine_similarity(M1, M2, cartesian_product=True)\n",
    "    >>> np.round(res5, 3)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    array([[0.   , 1.   , 0.707],\n",
    "           [1.   , 0.   , 0.707],\n",
    "           [0.707, 0.707, 1.   ]])\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # --------------- CASE 1: Both are single 1D vectors ---------------\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        if u.shape[0] != v.shape[0]:\n",
    "            raise ValueError(\"Vectors u and v must have the same dimension.\")\n",
    "        dot_uv = np.dot(u, v)\n",
    "        norm_u = np.linalg.norm(u)\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # --------------- CASE 2: At least one is 2D; ensure both are 2D ---------------\n",
    "    if u.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        u = u[np.newaxis, :]\n",
    "    if v.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        v = v[np.newaxis, :]\n",
    "\n",
    "    k1, n1 = u.shape\n",
    "    k2, n2 = v.shape\n",
    "\n",
    "    # Check that columns (vector dimension) match\n",
    "    if n1 != n2:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent dimensions: u has {n1} columns, v has {n2} columns.\"\n",
    "        )\n",
    "\n",
    "    # --------------- CARTESIAN PRODUCT ---------------\n",
    "    if cartesian_product:\n",
    "        # (k1 x k2) dot products\n",
    "        dot_uv = u @ v.T  # shape (k1, k2)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k2,)\n",
    "        # Outer product of norms => shape (k1, k2)\n",
    "        denom = np.outer(norm_u, norm_v)\n",
    "        return dot_uv / denom\n",
    "\n",
    "    # --------------- ROW-WISE (NOT CARTESIAN) ---------------\n",
    "    # 1) If one array has a single row (k=1), broadcast it against each row of the other\n",
    "    if k1 == 1 and k2 > 1:\n",
    "        # Broadcast u's single row against each row in v\n",
    "        dot_uv = np.sum(u[0] * v, axis=1)  # shape (k2,)\n",
    "        norm_u = np.linalg.norm(u[0])  # scalar\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k2,)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    if k2 == 1 and k1 > 1:\n",
    "        # Broadcast v's single row against each row in u\n",
    "        dot_uv = np.sum(u * v[0], axis=1)  # shape (k1,)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v[0])  # scalar\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # 2) Otherwise, require the same number of rows\n",
    "    if k1 != k2:\n",
    "        raise ValueError(\n",
    "            f\"For row-wise comparison, u and v must have the same number of rows. \"\n",
    "            f\"(u has {k1}, v has {k2})\"\n",
    "        )\n",
    "    dot_uv = np.sum(u * v, axis=1)  # shape (k1,)\n",
    "    norm_u = np.linalg.norm(u, axis=1)\n",
    "    norm_v = np.linalg.norm(v, axis=1)\n",
    "    return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine, cdist\n",
    "\n",
    "\n",
    "def cosine_similarity_scipy(u, v, *, cartesian_product=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors,\n",
    "    using SciPy's distance functions under the hood.\n",
    "\n",
    "    - If both inputs are 1D vectors, returns a float.\n",
    "    - If one or both inputs are 2D arrays, returns either a 1D array (row-wise)\n",
    "      or a 2D array (cartesian product of rows) depending on the\n",
    "      `cartesian_product` flag.\n",
    "\n",
    "    Behavior for row-wise (cartesian_product=False):\n",
    "      - If both arrays have the same number of rows (k), compares row i of u\n",
    "        with row i of v, resulting in a 1D array of length k.\n",
    "      - If one array has shape (1, d) and the other has shape (k, d), the single\n",
    "        row is broadcast to all k rows of the other array, returning a 1D array\n",
    "        of length k.\n",
    "      - Otherwise, raises a ValueError if row counts are incompatible.\n",
    "\n",
    "    Behavior for cartesian_product=True:\n",
    "      - Computes the similarity for every combination of rows in u and v,\n",
    "        returning a 2D array of shape (k1, k2).\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k1 x d),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k2 x d).\n",
    "        cartesian_product (bool, optional):\n",
    "            If True, computes a 2D matrix of size (k1, k2) for all pairs of rows.\n",
    "            If False, performs row-wise comparisons or broadcasting\n",
    "            as described above.\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D NumPy array if either u or v is 2D and cartesian_product=False.\n",
    "            - A 2D NumPy array if cartesian_product=True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            - If the number of columns (dimensions) in u and v do not match.\n",
    "            - If cartesian_product=False and row counts are incompatible.\n",
    "\n",
    "    Notes:\n",
    "        Internally, uses:\n",
    "         - `scipy.spatial.distance.cosine(u, v)` for single 1D vectors.\n",
    "         - `scipy.spatial.distance.cdist(u, v, metric=\"cosine\")` for multi-row data,\n",
    "           then converts distances to similarity via `1 - distance`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Single 1D vectors\n",
    "    >>> u1d = [2, 0]\n",
    "    >>> v1d = [2, 0]\n",
    "    >>> cosine_similarity_scipy(u1d, v1d)\n",
    "    1.0\n",
    "\n",
    "    >>> # Single 1D vector vs. 2D array (row-wise broadcast)\n",
    "    >>> import numpy as np\n",
    "    >>> M1 = np.array([\n",
    "    ...     [2, 0],\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res2 = cosine_similarity_scipy(u1d, M1)\n",
    "    >>> np.round(res2, 3)\n",
    "    array([1.   , 0.   , 0.707])\n",
    "\n",
    "    >>> # Two 2D arrays of different row lengths, cartesian_product=False\n",
    "    >>> M2_different = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> # Expect a ValueError if we try row-wise with mismatched rows\n",
    "    >>> cosine_similarity_scipy(M1, M2_different, cartesian_product=False)  # doctest: +IGNORE_EXCEPTION_DETAIL\n",
    "    Traceback (most recent call last):\n",
    "      ...\n",
    "    ValueError: ...\n",
    "\n",
    "    >>> # Two 2D arrays of the same row length (row-wise)\n",
    "    >>> M2 = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 0],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res4 = cosine_similarity_scipy(M1, M2, cartesian_product=False)\n",
    "    >>> res4\n",
    "    array([0., 0., 1.])\n",
    "\n",
    "    >>> # Cartesian product of all row pairs => (3 x 3) matrix\n",
    "    >>> res5 = cosine_similarity_scipy(M1, M2, cartesian_product=True)\n",
    "    >>> np.round(res5, 3)\n",
    "    array([[0.   , 1.   , 0.707],\n",
    "           [1.   , 0.   , 0.707],\n",
    "           [0.707, 0.707, 1.   ]])\n",
    "    \"\"\"\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # ----- CASE 1: Both are single 1D vectors -----\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        if u.shape[0] != v.shape[0]:\n",
    "            raise ValueError(\"Vectors u and v must have the same dimension.\")\n",
    "        # Cosine distance => 1 - similarity\n",
    "        dist = cosine(u, v)\n",
    "        return 1.0 - dist\n",
    "\n",
    "    # ----- CASE 2: At least one is 2D; ensure both are 2D -----\n",
    "    if u.ndim == 1:\n",
    "        u = u[np.newaxis, :]  # (1, d)\n",
    "    if v.ndim == 1:\n",
    "        v = v[np.newaxis, :]  # (1, d)\n",
    "\n",
    "    k1, d1 = u.shape\n",
    "    k2, d2 = v.shape\n",
    "\n",
    "    if d1 != d2:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent dimensions: u has {d1} columns, v has {d2} columns.\"\n",
    "        )\n",
    "\n",
    "    # ----- CARTESIAN PRODUCT -----\n",
    "    if cartesian_product:\n",
    "        # cdist => shape (k1, k2)\n",
    "        dist_matrix = cdist(u, v, metric=\"cosine\")\n",
    "        return 1.0 - dist_matrix\n",
    "\n",
    "    # ----- ROW-WISE (NOT CARTESIAN) -----\n",
    "    # If either array has 1 row, broadcast it against the rows of the other\n",
    "    if k1 == 1 and k2 > 1:\n",
    "        # => shape (1, k2)\n",
    "        dist_matrix = cdist(u, v, metric=\"cosine\")\n",
    "        # flatten => shape (k2,)\n",
    "        return 1.0 - dist_matrix.ravel()\n",
    "\n",
    "    if k2 == 1 and k1 > 1:\n",
    "        # => shape (k1, 1)\n",
    "        dist_matrix = cdist(u, v, metric=\"cosine\")\n",
    "        # flatten => shape (k1,)\n",
    "        return 1.0 - dist_matrix.ravel()\n",
    "\n",
    "    # Otherwise, require that k1 == k2\n",
    "    if k1 != k2:\n",
    "        raise ValueError(\n",
    "            f\"For row-wise comparison, u and v must have the same number of rows. \"\n",
    "            f\"(u has {k1}, v has {k2})\"\n",
    "        )\n",
    "\n",
    "    # cdist => shape (k1, k1)\n",
    "    dist_matrix = cdist(u, v, metric=\"cosine\")\n",
    "    # Row-wise => take diagonal => shape (k1,)\n",
    "    diag_distances = np.diag(dist_matrix)\n",
    "    return 1.0 - diag_distances\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "\n",
    "def test_cosine_similarity_performance(\n",
    "    *,\n",
    "    numpy_func=cosine_similarity,\n",
    "    scipy_func=cosine_similarity_scipy,\n",
    "    repeats=5,\n",
    "    number=5,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compares the performance of two cosine similarity functions (NumPy and SciPy)\n",
    "    under various scenarios.\n",
    "\n",
    "    Args:\n",
    "        numpy_func (callable): The NumPy-based cosine similarity function.\n",
    "        scipy_func (callable): The SciPy-based cosine similarity function.\n",
    "        repeats (int): How many times to repeat each timing scenario (timeit 'repeat').\n",
    "        number (int): How many times to run the timed operation per repeat (timeit 'number').\n",
    "        verbose (bool): Whether to print a summary of the results.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary containing timing results for each test scenario.\n",
    "              Example structure:\n",
    "              {\n",
    "                  \"single_1d\": {\"numpy_time\": ..., \"scipy_time\": ...},\n",
    "                  \"one_row_vs_multi\": {...},\n",
    "                  \"row_wise_equal_rows\": {...},\n",
    "                  \"cartesian_product\": {...}\n",
    "              }\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Test Data\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    # 1) Single 1D vectors (dimension = 512)\n",
    "    u_1d = np.random.rand(512)\n",
    "    v_1d = np.random.rand(512)\n",
    "\n",
    "    # 2) One-row vs. multi-row (for row-wise broadcast)\n",
    "    #    e.g. shape (1, 512) vs. shape (1000, 512)\n",
    "    u_one_row = np.random.rand(1, 512)\n",
    "    v_multi = np.random.rand(1000, 512)\n",
    "\n",
    "    # 3) Row-wise with equal rows\n",
    "    #    e.g. shape (2000, 256) each\n",
    "    u_equal = np.random.rand(2000, 256)\n",
    "    v_equal = np.random.rand(2000, 256)\n",
    "\n",
    "    # 4) Cartesian product with moderately sized arrays\n",
    "    #    shape (800, 256) each => result is (800 x 800) distance matrix\n",
    "    u_cart = np.random.rand(800, 256)\n",
    "    v_cart = np.random.rand(800, 256)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Helper function to measure a scenario\n",
    "    # ------------------------------------------------\n",
    "    def measure_time(stmt, globals_dict):\n",
    "        \"\"\"\n",
    "        Measures execution time of `stmt` using the timeit.repeat function,\n",
    "        returns the best timing out of 'repeats' repeats, each doing 'number' runs.\n",
    "        \"\"\"\n",
    "        times = timeit.repeat(stmt, repeat=repeats, number=number, globals=globals_dict)\n",
    "        best_time = min(times) / number  # average time per run\n",
    "        return best_time\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Single 1D vectors\n",
    "    # ------------------------------------------------\n",
    "    globals_single_1d = {\n",
    "        \"u\": u_1d,\n",
    "        \"v\": v_1d,\n",
    "        \"numpy_func\": numpy_func,\n",
    "        \"scipy_func\": scipy_func,\n",
    "    }\n",
    "    numpy_time = measure_time(\"numpy_func(u, v)\", globals_single_1d)\n",
    "    scipy_time = measure_time(\"scipy_func(u, v)\", globals_single_1d)\n",
    "    results[\"single_1d\"] = {\n",
    "        \"numpy_time\": numpy_time,\n",
    "        \"scipy_time\": scipy_time,\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # One-row vs. multi-row\n",
    "    # ------------------------------------------------\n",
    "    globals_one_vs_multi = {\n",
    "        \"u\": u_one_row,\n",
    "        \"v\": v_multi,\n",
    "        \"numpy_func\": numpy_func,\n",
    "        \"scipy_func\": scipy_func,\n",
    "    }\n",
    "    numpy_time = measure_time(\n",
    "        \"numpy_func(u, v, cartesian_product=False)\", globals_one_vs_multi\n",
    "    )\n",
    "    scipy_time = measure_time(\n",
    "        \"scipy_func(u, v, cartesian_product=False)\", globals_one_vs_multi\n",
    "    )\n",
    "    results[\"one_row_vs_multi\"] = {\n",
    "        \"numpy_time\": numpy_time,\n",
    "        \"scipy_time\": scipy_time,\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Row-wise with equal rows\n",
    "    # ------------------------------------------------\n",
    "    globals_equal_rows = {\n",
    "        \"u\": u_equal,\n",
    "        \"v\": v_equal,\n",
    "        \"numpy_func\": numpy_func,\n",
    "        \"scipy_func\": scipy_func,\n",
    "    }\n",
    "    numpy_time = measure_time(\n",
    "        \"numpy_func(u, v, cartesian_product=False)\", globals_equal_rows\n",
    "    )\n",
    "    scipy_time = measure_time(\n",
    "        \"scipy_func(u, v, cartesian_product=False)\", globals_equal_rows\n",
    "    )\n",
    "    results[\"row_wise_equal_rows\"] = {\n",
    "        \"numpy_time\": numpy_time,\n",
    "        \"scipy_time\": scipy_time,\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Cartesian product\n",
    "    # ------------------------------------------------\n",
    "    globals_cart = {\n",
    "        \"u\": u_cart,\n",
    "        \"v\": v_cart,\n",
    "        \"numpy_func\": numpy_func,\n",
    "        \"scipy_func\": scipy_func,\n",
    "    }\n",
    "    numpy_time = measure_time(\"numpy_func(u, v, cartesian_product=True)\", globals_cart)\n",
    "    scipy_time = measure_time(\"scipy_func(u, v, cartesian_product=True)\", globals_cart)\n",
    "    results[\"cartesian_product\"] = {\n",
    "        \"numpy_time\": numpy_time,\n",
    "        \"scipy_time\": scipy_time,\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Performance Comparison: NumPy vs. SciPy ===\")\n",
    "        for scenario, times in results.items():\n",
    "            print(f\"\\nScenario: {scenario}\")\n",
    "            print(\n",
    "                f\"  NumPy time: {times['numpy_time']:.5f} seconds/run (best of {repeats})\"\n",
    "            )\n",
    "            print(\n",
    "                f\"  SciPy time: {times['scipy_time']:.5f} seconds/run (best of {repeats})\"\n",
    "            )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "test_cosine_similarity_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_similarity(u, v, *, cartesian_product=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors or arrays of vectors.\n",
    "\n",
    "    If both inputs are 1D vectors, returns a float.\n",
    "    If one or both inputs are 2D arrays, returns either a 1D array (row-wise)\n",
    "    or a 2D array (cartesian product of rows) depending on the cartesian_product flag.\n",
    "\n",
    "    Behavior for row-wise (cartesian_product=False):\n",
    "      - If both arrays have the same number of rows, compares row i of u to row i of v.\n",
    "      - If one array has only 1 row, it is broadcast against each row of the other array.\n",
    "        (Returns a 1D array of length k, where k is the number of rows in the multi-row array.)\n",
    "\n",
    "    Note: This function only uses numpy.\n",
    "\n",
    "    Args:\n",
    "        u (array-like): A single vector (1D) or a 2D array (k1 x n),\n",
    "                        where each row is a separate vector.\n",
    "        v (array-like): A single vector (1D) or a 2D array (k2 x n).\n",
    "        cartesian_product (bool, optional):\n",
    "            - If False (default), the function compares rows in a one-to-one fashion (u[i] vs. v[i]),\n",
    "              **except** if one array has exactly 1 row and the other has multiple rows, in which case\n",
    "              that single row is broadcast to all rows of the other array.\n",
    "            - If True, computes the similarity for every combination of rows\n",
    "              (results in a 2D array of shape (k1, k2)).\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray:\n",
    "            - A float if both u and v are 1D vectors.\n",
    "            - A 1D numpy array if either u or v is 2D and cartesian_product=False.\n",
    "            - A 2D numpy array if cartesian_product=True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            - If the number of columns in u and v do not match.\n",
    "            - If cartesian_product=False, both arrays have multiple rows but differ in row count.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    # --- Case 1: Both are single 1D vectors\n",
    "    >>> u1d = [2, 0]\n",
    "    >>> v1d = [2, 0]\n",
    "    >>> cosine_similarity(u1d, v1d)\n",
    "    1.0\n",
    "\n",
    "    # --- Case 2: Single 1D vector vs. a 2D array (row-wise broadcast)\n",
    "    >>> import numpy as np\n",
    "    >>> M1 = np.array([\n",
    "    ...     [2, 0],\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res2 = cosine_similarity(u1d, M1)\n",
    "    >>> res2  # doctest: +ELLIPSIS\n",
    "    array([1.        , 0.        , 0.70710678...])\n",
    "\n",
    "    # --- Case 3: Two 2D arrays of different row lengths, cartesian_product=False (raises ValueError)\n",
    "    >>> M2_different = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> # Expect a ValueError because M1 has 3 rows and M2_different has 2 rows\n",
    "    >>> cosine_similarity(M1, M2_different, cartesian_product=False)  # doctest: +IGNORE_EXCEPTION_DETAIL\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: For row-wise comparison, u and v must have the same number of rows...\n",
    "\n",
    "    # --- Case 4: Two 2D arrays of the same number of rows, cartesian_product=False\n",
    "    >>> M2 = np.array([\n",
    "    ...     [0, 2],\n",
    "    ...     [2, 0],\n",
    "    ...     [2, 2]\n",
    "    ... ])\n",
    "    >>> res4 = cosine_similarity(M1, M2, cartesian_product=False)\n",
    "    >>> res4\n",
    "    array([0., 0., 1.])\n",
    "\n",
    "    # --- Case 5: Two 2D arrays of the same size, cartesian_product=True\n",
    "    # (computes every combination of rows => 3 x 3)\n",
    "    >>> res5 = cosine_similarity(M1, M2, cartesian_product=True)\n",
    "    >>> np.round(res5, 3)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    array([[0.   , 1.   , 0.707],\n",
    "           [1.   , 0.   , 0.707],\n",
    "           [0.707, 0.707, 1.   ]])\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    # --------------- CASE 1: Both are single 1D vectors ---------------\n",
    "    if u.ndim == 1 and v.ndim == 1:\n",
    "        if u.shape[0] != v.shape[0]:\n",
    "            raise ValueError(\"Vectors u and v must have the same dimension.\")\n",
    "        dot_uv = np.dot(u, v)\n",
    "        norm_u = np.linalg.norm(u)\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # --------------- CASE 2: At least one is 2D; ensure both are 2D ---------------\n",
    "    if u.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        u = u[np.newaxis, :]\n",
    "    if v.ndim == 1:  # shape (n,) -> (1, n)\n",
    "        v = v[np.newaxis, :]\n",
    "\n",
    "    k1, n1 = u.shape\n",
    "    k2, n2 = v.shape\n",
    "\n",
    "    # Check that columns (vector dimension) match\n",
    "    if n1 != n2:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent dimensions: u has {n1} columns, v has {n2} columns.\"\n",
    "        )\n",
    "\n",
    "    # --------------- CARTESIAN PRODUCT ---------------\n",
    "    if cartesian_product:\n",
    "        # (k1 x k2) dot products\n",
    "        dot_uv = u @ v.T  # shape (k1, k2)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k2,)\n",
    "        # Outer product of norms => shape (k1, k2)\n",
    "        denom = np.outer(norm_u, norm_v)\n",
    "        return dot_uv / denom\n",
    "\n",
    "    # --------------- ROW-WISE (NOT CARTESIAN) ---------------\n",
    "    # 1) If one array has a single row (k=1), broadcast it against each row of the other\n",
    "    if k1 == 1 and k2 > 1:\n",
    "        # Broadcast u's single row against each row in v\n",
    "        dot_uv = np.sum(u[0] * v, axis=1)  # shape (k2,)\n",
    "        norm_u = np.linalg.norm(u[0])  # scalar\n",
    "        norm_v = np.linalg.norm(v, axis=1)  # shape (k2,)\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    if k2 == 1 and k1 > 1:\n",
    "        # Broadcast v's single row against each row in u\n",
    "        dot_uv = np.sum(u * v[0], axis=1)  # shape (k1,)\n",
    "        norm_u = np.linalg.norm(u, axis=1)  # shape (k1,)\n",
    "        norm_v = np.linalg.norm(v[0])  # scalar\n",
    "        return dot_uv / (norm_u * norm_v)\n",
    "\n",
    "    # 2) Otherwise, require the same number of rows\n",
    "    if k1 != k2:\n",
    "        raise ValueError(\n",
    "            f\"For row-wise comparison, u and v must have the same number of rows. \"\n",
    "            f\"(u has {k1}, v has {k2})\"\n",
    "        )\n",
    "    dot_uv = np.sum(u * v, axis=1)  # shape (k1,)\n",
    "    norm_u = np.linalg.norm(u, axis=1)\n",
    "    norm_v = np.linalg.norm(v, axis=1)\n",
    "    return dot_uv / (norm_u * norm_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_vector:\n",
      "  NumPy: 0.0001 seconds (10 runs)\n",
      "  SciPy: 0.0001 seconds (10 runs)\n",
      "matrix_100:\n",
      "  NumPy: 0.0003 seconds (10 runs)\n",
      "  SciPy: 0.0112 seconds (10 runs)\n",
      "matrix_1000:\n",
      "  NumPy: 0.0021 seconds (10 runs)\n",
      "  SciPy: 1.0576 seconds (10 runs)\n",
      "matrix_10000:\n",
      "  NumPy: 0.0230 seconds (10 runs)\n",
      "  SciPy: 102.5846 seconds (10 runs)\n"
     ]
    }
   ],
   "source": [
    "from imbed.util import cosine_similarity, cosine_similarity_scipy\n",
    "import timeit \n",
    "\n",
    "# Function to benchmark performance\n",
    "def benchmark_cosine_similarity():\n",
    "    # Test cases\n",
    "    test_cases = {\n",
    "        \"single_vector\": (np.random.rand(128), np.random.rand(128)),\n",
    "        \"matrix_100\": (np.random.rand(100, 128), np.random.rand(100, 128)),\n",
    "        \"matrix_1000\": (np.random.rand(1000, 128), np.random.rand(1000, 128)),\n",
    "        \"matrix_10000\": (np.random.rand(10000, 128), np.random.rand(10000, 128)),\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for test_name, (u, v) in test_cases.items():\n",
    "        # Measure time for NumPy-based implementation\n",
    "        time_numpy = timeit.timeit(\n",
    "            lambda: cosine_similarity(u, v), number=10\n",
    "        )\n",
    "        # Measure time for SciPy-based implementation\n",
    "        time_scipy = timeit.timeit(\n",
    "            lambda: cosine_similarity_scipy(u, v), number=10\n",
    "        )\n",
    "        results[test_name] = {\n",
    "            \"time_numpy\": time_numpy,\n",
    "            \"time_scipy\": time_scipy,\n",
    "        }\n",
    "\n",
    "    # Print results\n",
    "    for test_name, times in results.items():\n",
    "        print(\n",
    "            f\"{test_name}:\\n\"\n",
    "            f\"  NumPy: {times['time_numpy']:.4f} seconds (10 runs)\\n\"\n",
    "            f\"  SciPy: {times['time_scipy']:.4f} seconds (10 runs)\"\n",
    "        )\n",
    "\n",
    "\n",
    "benchmark_cosine_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
