{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Batch Embeddings Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed.examples.batch_embeddings_examples import (\n",
    "    simple_example,\n",
    "    non_blocking_example,\n",
    "    context_manager_example,\n",
    "    pandas_example,\n",
    "    error_handling_example\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:43:27,803 - __main__ - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 14:43:28,676 - __main__ - INFO - Submitted 1 batches\n",
      "2025-03-28 14:43:28,677 - __main__ - INFO - Monitoring 1 batches\n",
      "2025-03-28 14:43:39,379 - __main__ - INFO - Batch Batch(id='batch_67e6a7805d9c819095b5dd403940995c', completion_window='24h', created_at=1743169408, endpoint='/v1/embeddings', input_file_id='file-LHUkkNvQVgQa9rRub4wbaY', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743255808, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 14:43:39,382 - __main__ - INFO - Batch processing complete: 1 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 embeddings\n",
      "First embedding (first 5 dimensions): [-0.018423624, -0.0072260704, 0.003638412, -0.054205045, -0.022725008]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = simple_example()\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:46:06,021 - __main__ - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 14:46:07,017 - __main__ - INFO - Submitted 1 batches\n",
      "2025-03-28 14:46:07,018 - __main__ - INFO - Monitoring 1 batches\n",
      "2025-03-28 14:46:12,767 - __main__ - INFO - Batch Batch(id='batch_67e6a81ebcec81908d48c10743f1ad83', completion_window='24h', created_at=1743169566, endpoint='/v1/embeddings', input_file_id='file-WFYDs5SBpJLbF3xiHJkziM', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743255966, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 14:46:12,770 - __main__ - INFO - Batch processing complete: 1 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 embeddings\n",
      "First embedding (first 5 dimensions): [-0.018421143, -0.007218754, 0.0036062053, -0.054197744, -0.022721948]\n"
     ]
    }
   ],
   "source": [
    "segments, embeddings = simple_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumps over the lazy dog.',\n",
       " 'Machine learning models transform input data into useful representations.',\n",
       " 'Embeddings capture semantic meaning in dense vector spaces.',\n",
       " 'Natural language processing enables computers to understand human language.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.018421143, -0.007218754, 0.0036062053, -0.054197744, -0.022721948]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:57:35,443 - imbed.oa_batch_embeddings - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 14:57:36,784 - imbed.oa_batch_embeddings - DEBUG - Submitted batch batch_67e6aad079b08190a0e2b45e1aecd628 with 2 segments\n",
      "2025-03-28 14:57:37,819 - imbed.oa_batch_embeddings - DEBUG - Submitted batch batch_67e6aad18d5081909ec022687e474f65 with 2 segments\n",
      "2025-03-28 14:57:37,820 - imbed.oa_batch_embeddings - INFO - Submitted 2 batches\n",
      "2025-03-28 14:57:37,820 - imbed.oa_batch_embeddings - INFO - Monitoring 2 batches\n",
      "2025-03-28 14:57:38,001 - imbed.oa_batch_embeddings - DEBUG - Batch Batch(id='batch_67e6aad079b08190a0e2b45e1aecd628', completion_window='24h', created_at=1743170256, endpoint='/v1/embeddings', input_file_id='file-E5GXa9wne4UxRPn6YSeJAV', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256656, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) status: in_progress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial status summary: {'validating': 2, 'completed': 0, 'failed': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:57:38,419 - imbed.oa_batch_embeddings - DEBUG - Batch Batch(id='batch_67e6aad18d5081909ec022687e474f65', completion_window='24h', created_at=1743170257, endpoint='/v1/embeddings', input_file_id='file-V78FMHmz8xNkhfRtzkkBSP', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256657, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) status: validating\n",
      "2025-03-28 14:57:41,589 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6aad079b08190a0e2b45e1aecd628', completion_window='24h', created_at=1743170256, endpoint='/v1/embeddings', input_file_id='file-E5GXa9wne4UxRPn6YSeJAV', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256656, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 14:57:41,793 - imbed.oa_batch_embeddings - DEBUG - Batch Batch(id='batch_67e6aad18d5081909ec022687e474f65', completion_window='24h', created_at=1743170257, endpoint='/v1/embeddings', input_file_id='file-V78FMHmz8xNkhfRtzkkBSP', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256657, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) status: in_progress\n",
      "2025-03-28 14:57:43,999 - imbed.oa_batch_embeddings - DEBUG - Batch Batch(id='batch_67e6aad18d5081909ec022687e474f65', completion_window='24h', created_at=1743170257, endpoint='/v1/embeddings', input_file_id='file-V78FMHmz8xNkhfRtzkkBSP', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256657, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) status: finalizing\n",
      "2025-03-28 14:57:47,555 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6aad18d5081909ec022687e474f65', completion_window='24h', created_at=1743170257, endpoint='/v1/embeddings', input_file_id='file-V78FMHmz8xNkhfRtzkkBSP', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256657, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 14:57:47,556 - imbed.oa_batch_embeddings - INFO - Batch processing complete: 2 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 embeddings for keys: ['fox', 'ml', 'embeddings', 'nlp']\n"
     ]
    }
   ],
   "source": [
    "segment_keys, embeddings = non_blocking_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fox', 'ml', 'embeddings', 'nlp']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segment_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, embeddings = context_manager_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:07:43,617 - imbed.oa_batch_embeddings - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 15:07:45,843 - imbed.oa_batch_embeddings - INFO - Submitted 2 batches\n",
      "2025-03-28 15:07:45,844 - imbed.oa_batch_embeddings - INFO - Monitoring 2 batches\n",
      "2025-03-28 15:07:51,844 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6ad3190048190ad587e2edd65ea33', completion_window='24h', created_at=1743170865, endpoint='/v1/embeddings', input_file_id='file-QwvooujNxuuPrqBz1NoKY9', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743257265, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 15:09:36,698 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6ad306948819095e79cabd8263f0c', completion_window='24h', created_at=1743170864, endpoint='/v1/embeddings', input_file_id='file-LU634VDsP3ZfQ7xHAJrWAK', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743257264, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 15:09:36,700 - imbed.oa_batch_embeddings - INFO - Batch processing complete: 2 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (4, 2)\n",
      "DataFrame index: ['fox', 'ml', 'embeddings', 'nlp']\n",
      "First row segment: The quick brown fox jumps over the lazy dog.\n",
      "First row embedding (first 5 dims): [4.308471e-05, -0.006475493, -0.00071540475, 0.018186275, 0.023950174]\n",
      "                                                      segment  \\\n",
      "fox              The quick brown fox jumps over the lazy dog.   \n",
      "ml          Machine learning models transform input data i...   \n",
      "embeddings  Embeddings capture semantic meaning in dense v...   \n",
      "nlp         Natural language processing enables computers ...   \n",
      "\n",
      "                                                    embedding  \n",
      "fox         [4.308471e-05, -0.006475493, -0.00071540475, 0...  \n",
      "ml          [-0.021480283, 0.02021441, 0.012085131, 0.0159...  \n",
      "embeddings  [-0.018421143, -0.007218754, 0.0036062053, -0....  \n",
      "nlp         [0.015456875, 0.0016184314, 0.012820516, -0.04...  \n"
     ]
    }
   ],
   "source": [
    "segment_and_embedding_df = pandas_example()\n",
    "print(segment_and_embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:13:39,827 - imbed.oa_batch_embeddings - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 15:13:39,828 - imbed.oa_batch_embeddings - INFO - Submitting batches for 2 segments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected error: TypeError: argument 'text': 'int' object cannot be converted to 'PyString'\n",
      "Correcting and continuing with valid segments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:13:40,891 - imbed.oa_batch_embeddings - INFO - Submitted 1 batches\n",
      "2025-03-28 15:13:40,892 - imbed.oa_batch_embeddings - INFO - Monitoring 1 batches\n",
      "2025-03-28 15:13:56,657 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6ae94932c819092092eb1bf91f3c9', completion_window='24h', created_at=1743171220, endpoint='/v1/embeddings', input_file_id='file-8wTtrPv345yPe1HUTgMCKj', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743257620, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 15:13:56,659 - imbed.oa_batch_embeddings - INFO - Batch processing complete: 1 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated 2 embeddings after correction\n",
      "len(result_segments)=2, len(embeddings)=2\n"
     ]
    }
   ],
   "source": [
    "result_segments, embeddings = error_handling_example()\n",
    "print(f\"{len(result_segments)=}, {len(embeddings)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a persistent backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/thorwhalen/Dropbox/_odata/app_data/imbed/batches/testing'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "from imbed.oa_batch_embeddings import ProcessingMall, JsonFiles, PickleFiles\n",
    "\n",
    "mall = ProcessingMall.with_folder('testing', PickleFiles)\n",
    "mall.rootdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['current', 'segments', 'finished', 'erred', 'embeddings']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 18:59:42,395 - imbed.oa_batch_embeddings - INFO - Submitting batches for 4 segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 18:59:43,746 - imbed.oa_batch_embeddings - DEBUG - Submitted batch batch_67e8350f530c8190bbb5cb99e42c7fbf with 2 segments\n",
      "2025-03-29 18:59:44,781 - imbed.oa_batch_embeddings - DEBUG - Submitted batch batch_67e835107c40819089287b0ca7d4e0e8 with 2 segments\n",
      "2025-03-29 18:59:44,782 - imbed.oa_batch_embeddings - INFO - Submitted 2 batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial status summary: {'validating': 2, 'completed': 0, 'failed': 0}\n"
     ]
    }
   ],
   "source": [
    "from imbed.oa_batch_embeddings import compute_embeddings\n",
    "\n",
    "# Sample text segments as a DICTIONARY\n",
    "segments = {\n",
    "    \"fox\": \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"ml\": \"Machine learning models transform input data into useful representations.\",\n",
    "    \"embeddings\": \"Embeddings capture semantic meaning in dense vector spaces.\",\n",
    "    \"nlp\": \"Natural language processing enables computers to understand human language.\",\n",
    "}\n",
    "\n",
    "# Get a process object instead of results\n",
    "process = compute_embeddings(\n",
    "    segments=segments,\n",
    "    processing_mall=mall,\n",
    "    verbosity=2,  # Show detailed progress information\n",
    "    batch_size=2,  # Split into multiple batches\n",
    "    poll_interval=2.0,  # Check status every 3 seconds\n",
    "    return_process=True,  # Return the process instead of results\n",
    ")\n",
    "\n",
    "# Submit batches\n",
    "process.submit_batches()\n",
    "\n",
    "# Check status without blocking\n",
    "print(\"Initial status summary:\", process.get_status_summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_67e8350f530c8190bbb5cb99e42c7fbf',\n",
       " 'batch_67e835107c40819089287b0ca7d4e0e8']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_67e8350f530c8190bbb5cb99e42c7fbf',\n",
       " 'batch_67e835107c40819089287b0ca7d4e0e8']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:01:51,773 - imbed.oa_batch_embeddings - INFO - Monitoring 2 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:01:52,595 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e8350f530c8190bbb5cb99e42c7fbf', completion_window='24h', created_at=1743271183, endpoint='/v1/embeddings', input_file_id='file-DrMLaqVzMvQ3zokvcmxxfL', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743357583, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-29 19:01:53,329 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e835107c40819089287b0ca7d4e0e8', completion_window='24h', created_at=1743271184, endpoint='/v1/embeddings', input_file_id='file-JdXpQUJZE7Lgn5e2vTXzhW', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743357584, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-29 19:01:53,331 - imbed.oa_batch_embeddings - INFO - Batch processing complete: 2 successful, 0 failed\n"
     ]
    }
   ],
   "source": [
    "# Now monitor until completion (this will block)\n",
    "process.monitor_batches()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:01:56,342 - imbed.oa_batch_embeddings - WARNING - No batches to monitor\n"
     ]
    }
   ],
   "source": [
    "process.monitor_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_67e8350f530c8190bbb5cb99e42c7fbf',\n",
       " 'batch_67e835107c40819089287b0ca7d4e0e8']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_67e8350f530c8190bbb5cb99e42c7fbf',\n",
       " 'batch_67e835107c40819089287b0ca7d4e0e8']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The quick brown fox jumps over the lazy dog.',\n",
       "  'Machine learning models transform input data into useful representations.'],\n",
       " ['Embeddings capture semantic meaning in dense vector spaces.',\n",
       "  'Natural language processing enables computers to understand human language.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall.segments.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and print results\n",
    "segment_keys, embeddings = process.aggregate_results()\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings for keys: {segment_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/thorwhalen/Dropbox/_odata/app_data/imbed/batches/testing'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.rootdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from imbed.oa_batch_embeddings import EmbeddingsBatchProcess\n",
    "\n",
    "proc = EmbeddingsBatchProcess(\n",
    "    processing_mall='/Users/thorwhalen/Dropbox/_odata/app_data/imbed/batches/testing'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completed': 2, 'failed': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.get_status_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc.monitor_batches()  # TODO: Need this, or _is_complete won't know (default is False). Change\n",
    "# segment_keys, embeddings = proc.processes()\n",
    "\n",
    "# print(f\"Generated {len(embeddings)} embeddings for keys: {segment_keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare pickle, json, parquet, and numpy encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                         | type    |   size |\n",
      "|:-----------------------------|:--------|-------:|\n",
      "| parquet                      | texts   |   1654 |\n",
      "| single_column_parquet_encode | texts   |   1718 |\n",
      "| pickle                       | texts   |   2060 |\n",
      "| single_column_parquet_encode | vectors |   2060 |\n",
      "| pickle                       | vectors |   2092 |\n",
      "| parquet                      | vectors |   5533 |\n",
      "| json                         | vectors |  45000 |\n",
      "| json                         | texts   |  47000 |\n",
      "| numpy                        | vectors |  72128 |\n",
      "| numpy                        | texts   | 172128 |\n"
     ]
    }
   ],
   "source": [
    "import pickle, json, pandas as pd, numpy as np\n",
    "import dol \n",
    "\n",
    "texts = ['Some text that will be repeated many times.'] * 1000\n",
    "vectors = [[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 0.9]] * 1000\n",
    "\n",
    "pickle_encode = pickle.dumps\n",
    "json_encode = json.dumps\n",
    "numpy_encode = dol.written_bytes(np.save, obj_arg_position_in_writer=1)\n",
    "parquet_encode = dol.written_bytes(pd.DataFrame.to_parquet, obj_arg_position_in_writer=0)\n",
    "\n",
    "def single_column_parquet_encode(datas):\n",
    "    return pd.DataFrame({'data': datas}).to_parquet()\n",
    "\n",
    "print(pd.DataFrame([\n",
    "    {'name': 'pickle', 'type': 'texts', 'size': len(pickle_encode(texts))},\n",
    "    {'name': 'json', 'type': 'texts', 'size': len(json_encode(texts))},\n",
    "    {'name': 'parquet', 'type': 'texts', 'size': len(parquet_encode(pd.DataFrame(texts)))},\n",
    "    {'name': 'single_column_parquet_encode', 'type': 'texts', 'size': len(single_column_parquet_encode(texts))},\n",
    "    {'name': 'numpy', 'type': 'texts', 'size': len(numpy_encode(np.array(texts)))},\n",
    "    {'name': 'pickle', 'type': 'vectors', 'size': len(pickle_encode(vectors))},\n",
    "    {'name': 'json', 'type': 'vectors', 'size': len(json_encode(vectors))},\n",
    "    {'name': 'parquet', 'type': 'vectors', 'size': len(parquet_encode(pd.DataFrame(vectors)))},\n",
    "    {'name': 'single_column_parquet_encode', 'type': 'vectors', 'size': len(single_column_parquet_encode(vectors))},\n",
    "    {'name': 'numpy', 'type': 'vectors', 'size': len(numpy_encode(np.array(vectors)))}\n",
    "]).sort_values('size').reset_index(drop=True).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, 4, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence\n",
       "0     [1, 2]\n",
       "1  [3, 4, 5]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabled\n",
    "\n",
    "tabled.get_table(encoded_1, ext='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import pandas as pd \n",
    "\n",
    "def single_column_parquet_encode(sequences):\n",
    "    return pd.DataFrame({'sequence': sequences}).to_parquet()\n",
    "\n",
    "def single_column_parquet_decode(b: bytes):\n",
    "    return pd.read_parquet(io.BytesIO(b)).sequence.values\n",
    "\n",
    "sequences_1 = [[1, 2], [3, 4, 5]]\n",
    "encoded_1 = single_column_parquet_encode(sequences_1)\n",
    "decoded_1 = single_column_parquet_decode(encoded_1)\n",
    "assert all((x == y).all() for x, y in zip(decoded_1, sequences_1))\n",
    "\n",
    "sequences_2 = [['one', 'two'], ['three', 'four', 'five']]\n",
    "encoded_2 = single_column_parquet_encode(sequences_2)\n",
    "decoded_2 = single_column_parquet_decode(encoded_2)\n",
    "assert all((x == y).all() for x, y in zip(decoded_2, sequences_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed.examples.batch_embeddings_examples import (\n",
    "    simple_example,\n",
    "    non_blocking_example,\n",
    "    context_manager_example,\n",
    "    pandas_example,\n",
    "    error_handling_example\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:43:27,803 - __main__ - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 14:43:28,676 - __main__ - INFO - Submitted 1 batches\n",
      "2025-03-28 14:43:28,677 - __main__ - INFO - Monitoring 1 batches\n",
      "2025-03-28 14:43:39,379 - __main__ - INFO - Batch Batch(id='batch_67e6a7805d9c819095b5dd403940995c', completion_window='24h', created_at=1743169408, endpoint='/v1/embeddings', input_file_id='file-LHUkkNvQVgQa9rRub4wbaY', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743255808, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 14:43:39,382 - __main__ - INFO - Batch processing complete: 1 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 embeddings\n",
      "First embedding (first 5 dimensions): [-0.018423624, -0.0072260704, 0.003638412, -0.054205045, -0.022725008]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = simple_example()\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:46:06,021 - __main__ - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 14:46:07,017 - __main__ - INFO - Submitted 1 batches\n",
      "2025-03-28 14:46:07,018 - __main__ - INFO - Monitoring 1 batches\n",
      "2025-03-28 14:46:12,767 - __main__ - INFO - Batch Batch(id='batch_67e6a81ebcec81908d48c10743f1ad83', completion_window='24h', created_at=1743169566, endpoint='/v1/embeddings', input_file_id='file-WFYDs5SBpJLbF3xiHJkziM', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743255966, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 14:46:12,770 - __main__ - INFO - Batch processing complete: 1 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 embeddings\n",
      "First embedding (first 5 dimensions): [-0.018421143, -0.007218754, 0.0036062053, -0.054197744, -0.022721948]\n"
     ]
    }
   ],
   "source": [
    "segments, embeddings = simple_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumps over the lazy dog.',\n",
       " 'Machine learning models transform input data into useful representations.',\n",
       " 'Embeddings capture semantic meaning in dense vector spaces.',\n",
       " 'Natural language processing enables computers to understand human language.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.018421143, -0.007218754, 0.0036062053, -0.054197744, -0.022721948]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:57:35,443 - imbed.oa_batch_embeddings - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 14:57:36,784 - imbed.oa_batch_embeddings - DEBUG - Submitted batch batch_67e6aad079b08190a0e2b45e1aecd628 with 2 segments\n",
      "2025-03-28 14:57:37,819 - imbed.oa_batch_embeddings - DEBUG - Submitted batch batch_67e6aad18d5081909ec022687e474f65 with 2 segments\n",
      "2025-03-28 14:57:37,820 - imbed.oa_batch_embeddings - INFO - Submitted 2 batches\n",
      "2025-03-28 14:57:37,820 - imbed.oa_batch_embeddings - INFO - Monitoring 2 batches\n",
      "2025-03-28 14:57:38,001 - imbed.oa_batch_embeddings - DEBUG - Batch Batch(id='batch_67e6aad079b08190a0e2b45e1aecd628', completion_window='24h', created_at=1743170256, endpoint='/v1/embeddings', input_file_id='file-E5GXa9wne4UxRPn6YSeJAV', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256656, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) status: in_progress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial status summary: {'validating': 2, 'completed': 0, 'failed': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:57:38,419 - imbed.oa_batch_embeddings - DEBUG - Batch Batch(id='batch_67e6aad18d5081909ec022687e474f65', completion_window='24h', created_at=1743170257, endpoint='/v1/embeddings', input_file_id='file-V78FMHmz8xNkhfRtzkkBSP', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256657, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) status: validating\n",
      "2025-03-28 14:57:41,589 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6aad079b08190a0e2b45e1aecd628', completion_window='24h', created_at=1743170256, endpoint='/v1/embeddings', input_file_id='file-E5GXa9wne4UxRPn6YSeJAV', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256656, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 14:57:41,793 - imbed.oa_batch_embeddings - DEBUG - Batch Batch(id='batch_67e6aad18d5081909ec022687e474f65', completion_window='24h', created_at=1743170257, endpoint='/v1/embeddings', input_file_id='file-V78FMHmz8xNkhfRtzkkBSP', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256657, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) status: in_progress\n",
      "2025-03-28 14:57:43,999 - imbed.oa_batch_embeddings - DEBUG - Batch Batch(id='batch_67e6aad18d5081909ec022687e474f65', completion_window='24h', created_at=1743170257, endpoint='/v1/embeddings', input_file_id='file-V78FMHmz8xNkhfRtzkkBSP', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256657, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) status: finalizing\n",
      "2025-03-28 14:57:47,555 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6aad18d5081909ec022687e474f65', completion_window='24h', created_at=1743170257, endpoint='/v1/embeddings', input_file_id='file-V78FMHmz8xNkhfRtzkkBSP', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743256657, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 14:57:47,556 - imbed.oa_batch_embeddings - INFO - Batch processing complete: 2 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 embeddings for keys: ['fox', 'ml', 'embeddings', 'nlp']\n"
     ]
    }
   ],
   "source": [
    "segment_keys, embeddings = non_blocking_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fox', 'ml', 'embeddings', 'nlp']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segment_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, embeddings = context_manager_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:07:43,617 - imbed.oa_batch_embeddings - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 15:07:45,843 - imbed.oa_batch_embeddings - INFO - Submitted 2 batches\n",
      "2025-03-28 15:07:45,844 - imbed.oa_batch_embeddings - INFO - Monitoring 2 batches\n",
      "2025-03-28 15:07:51,844 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6ad3190048190ad587e2edd65ea33', completion_window='24h', created_at=1743170865, endpoint='/v1/embeddings', input_file_id='file-QwvooujNxuuPrqBz1NoKY9', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743257265, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 15:09:36,698 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6ad306948819095e79cabd8263f0c', completion_window='24h', created_at=1743170864, endpoint='/v1/embeddings', input_file_id='file-LU634VDsP3ZfQ7xHAJrWAK', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743257264, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 15:09:36,700 - imbed.oa_batch_embeddings - INFO - Batch processing complete: 2 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (4, 2)\n",
      "DataFrame index: ['fox', 'ml', 'embeddings', 'nlp']\n",
      "First row segment: The quick brown fox jumps over the lazy dog.\n",
      "First row embedding (first 5 dims): [4.308471e-05, -0.006475493, -0.00071540475, 0.018186275, 0.023950174]\n",
      "                                                      segment  \\\n",
      "fox              The quick brown fox jumps over the lazy dog.   \n",
      "ml          Machine learning models transform input data i...   \n",
      "embeddings  Embeddings capture semantic meaning in dense v...   \n",
      "nlp         Natural language processing enables computers ...   \n",
      "\n",
      "                                                    embedding  \n",
      "fox         [4.308471e-05, -0.006475493, -0.00071540475, 0...  \n",
      "ml          [-0.021480283, 0.02021441, 0.012085131, 0.0159...  \n",
      "embeddings  [-0.018421143, -0.007218754, 0.0036062053, -0....  \n",
      "nlp         [0.015456875, 0.0016184314, 0.012820516, -0.04...  \n"
     ]
    }
   ],
   "source": [
    "segment_and_embedding_df = pandas_example()\n",
    "print(segment_and_embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:13:39,827 - imbed.oa_batch_embeddings - INFO - Submitting batches for 4 segments\n",
      "2025-03-28 15:13:39,828 - imbed.oa_batch_embeddings - INFO - Submitting batches for 2 segments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected error: TypeError: argument 'text': 'int' object cannot be converted to 'PyString'\n",
      "Correcting and continuing with valid segments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:13:40,891 - imbed.oa_batch_embeddings - INFO - Submitted 1 batches\n",
      "2025-03-28 15:13:40,892 - imbed.oa_batch_embeddings - INFO - Monitoring 1 batches\n",
      "2025-03-28 15:13:56,657 - imbed.oa_batch_embeddings - INFO - Batch Batch(id='batch_67e6ae94932c819092092eb1bf91f3c9', completion_window='24h', created_at=1743171220, endpoint='/v1/embeddings', input_file_id='file-8wTtrPv345yPe1HUTgMCKj', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1743257620, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)) completed successfully\n",
      "2025-03-28 15:13:56,659 - imbed.oa_batch_embeddings - INFO - Batch processing complete: 1 successful, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated 2 embeddings after correction\n",
      "len(result_segments)=2, len(embeddings)=2\n"
     ]
    }
   ],
   "source": [
    "result_segments, embeddings = error_handling_example()\n",
    "print(f\"{len(result_segments)=}, {len(embeddings)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = dol.written_bytes(np.save, obj_arg_position_in_writer=1)\n",
    "f(texts) == written_numpy_bytes(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_encode(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "A load persistent id instruction was encountered,\nbut no persistent_load function was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpandas_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/p10/lib/python3.10/site-packages/pandas/io/pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;66;03m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: A load persistent id instruction was encountered,\nbut no persistent_load function was specified."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: OpenAI backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single word openai embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll compute openai embeddings for the most frequent English words and uplaod them to a github repository in various formats (which we will compare): csv, zipped csv, pickle, and possibly recode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = lambda seq, size: (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "from oa import openai\n",
    "\n",
    "def oa_embeddings(terms, engine='text-embedding-ada-002'):\n",
    "    if isinstance(terms, str):\n",
    "        terms = [terms]\n",
    "    responses = openai.Embedding.create(input=terms, engine=engine)\n",
    "    embeddings = {term: response['embedding'] for term, response in zip(terms, responses['data'])}\n",
    "    return embeddings\n",
    "\n",
    "from py2store import PickleStore\n",
    "\n",
    "def get_and_save_embeddings(terms, save_store= PickleStore('.'), chk_size=2000):\n",
    "    save_store = PickleStore('.')\n",
    "\n",
    "    from lkj import print_progress\n",
    "\n",
    "    chk_size = 2000\n",
    "    n = int(len(terms) / chk_size)\n",
    "    for i, chk in enumerate(chunker(list(terms), chk_size)):\n",
    "        print_progress(f\"({i}/{n})\")\n",
    "        new_embeddings = oa_embeddings(chk)\n",
    "        first = i * chk_size\n",
    "        last = (i + 1) * chk_size\n",
    "        save_store[f'openai_word_embeddings_{first}_{last}.pkl'] = new_embeddings\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'of', 'and', 'to', 'a', 'in', 'for', 'is', 'on', 'that']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from idiom import most_frequent_words\n",
    "\n",
    "words = most_frequent_words()\n",
    "list(words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 23135851162),\n",
       " ('of', 13151942776),\n",
       " ('and', 12997637966),\n",
       " ('to', 12136980858),\n",
       " ('a', 9081174698),\n",
       " ('in', 8469404971),\n",
       " ('for', 5933321709),\n",
       " ('is', 4705743816),\n",
       " ('on', 3750423199),\n",
       " ('that', 3400031103)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(words.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_and_save_embeddings(words)\n",
    "# 3m41s to run on my 100_000 word list!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping, MutableMapping\n",
    "# go through all src data, chunked by 5, dict-merging the datas, and saving the result in targ \n",
    "def rechunk_and_save(\n",
    "        src: Mapping, \n",
    "        targ: MutableMapping, \n",
    "        *,\n",
    "        aggregate_chk_size = 5,\n",
    "        original_chk_size = 2000\n",
    "):\n",
    "    src_keys = list(src)\n",
    "    new_chunk_size = original_chk_size * aggregate_chk_size\n",
    "    for i, chk in enumerate(chunker(range(len(src)), aggregate_chk_size)):\n",
    "        d = dict()\n",
    "        for first, last in src_keys[slice(chk[0], chk[-1] + 1)]:\n",
    "            d.update(src[(first, last)])\n",
    "        targ[i * new_chunk_size, (i + 1) * new_chunk_size] = d\n",
    "\n",
    "\n",
    "from dol import KeyTemplate\n",
    "\n",
    "st = KeyTemplate(\n",
    "    'openai_word_embeddings_{first}_{last}.pkl', field_patterns=dict(first='[0-9]+', last='[0-9]+')\n",
    ")\n",
    "\n",
    "from py2store import PickleStore\n",
    "from dol import wrap_kvs, filt_iter, Pipe, cached_keys\n",
    "\n",
    "embeddings_wrapper = Pipe(\n",
    "    filt_iter(filt=lambda k: k.endswith('.pkl')),\n",
    "    wrap_kvs(\n",
    "        key_of_id=lambda x: tuple(map(int, st.str_to_tuple(x))), \n",
    "        id_of_key=st.tuple_to_str\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = embeddings_wrapper(PickleStore('./embeddings'))\n",
    "src = cached_keys(src, keys_cache=sorted)\n",
    "targ = embeddings_wrapper(PickleStore('./embeddings_2'))\n",
    "\n",
    "# rechunk_and_save(src, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dol import wrap_kvs\n",
    "\n",
    "wordvec_store = embeddings_wrapper(PickleStore('./embeddings'))\n",
    "wordvec = dict(**wordvec_store[0, 10000], **wordvec_store[10000, 20000], **wordvec_store[20000, 30000])\n",
    "# wordvec = wrap_kvs(wordvec, obj_of_data=np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"king\" and \"queen\" similarity: 0.9155\n",
      "\"king\" and \"man\" similarity: 0.8138\n",
      "\"queen\" and \"man\" similarity: 0.8259\n",
      "\"queen\" and \"woman\" similarity: 0.8799\n",
      "\"man\" and \"woman\" similarity: 0.9029\n",
      "\n",
      "New vector and \"king\" similarity: 0.9155\n",
      "New vector and \"man\" similarity: 0.6542\n",
      "New vector and \"woman\" similarity: 0.8342\n",
      "New vector and \"queen\" similarity: 0.8848\n",
      "\n",
      "\n",
      "\"paris\" and \"rome\" similarity: 0.8460\n",
      "\"paris\" and \"france\" similarity: 0.8926\n",
      "\"rome\" and \"france\" similarity: 0.8258\n",
      "\"rome\" and \"italy\" similarity: 0.8579\n",
      "\"france\" and \"italy\" similarity: 0.8816\n",
      "\n",
      "New vector and \"paris\" similarity: 0.8903\n",
      "New vector and \"france\" similarity: 0.7291\n",
      "New vector and \"italy\" similarity: 0.9006\n",
      "New vector and \"rome\" similarity: 0.8270\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Mapping\n",
    "\n",
    "Word2Vec = Mapping[str, list]\n",
    "\n",
    "def try_wordvec_arthimetic(\n",
    "        wordvec: Mapping,\n",
    "        obj_word_1 = 'king',\n",
    "        obj_word_2 = 'queen',\n",
    "        feature_word_1 = 'man',\n",
    "        feature_word_2 = 'woman',\n",
    "):\n",
    "    from scipy.spatial.distance import cosine\n",
    "    import numpy as np\n",
    "\n",
    "    def cosine_similarity(vec1, vec2):\n",
    "        return 1 - cosine(vec1, vec2)\n",
    "\n",
    "\n",
    "    print(f'\"{obj_word_1}\" and \"{obj_word_2}\" similarity: {cosine_similarity(wordvec[obj_word_1], wordvec[obj_word_2]):.4f}')\n",
    "    print(f'\"{obj_word_1}\" and \"{feature_word_1}\" similarity: {cosine_similarity(wordvec[obj_word_1], wordvec[feature_word_1]):.4f}')\n",
    "    print(f'\"{obj_word_2}\" and \"{feature_word_1}\" similarity: {cosine_similarity(wordvec[obj_word_2], wordvec[feature_word_1]):.4f}')\n",
    "    print(f'\"{obj_word_2}\" and \"{feature_word_2}\" similarity: {cosine_similarity(wordvec[obj_word_2], wordvec[feature_word_2]):.4f}')\n",
    "    print(f'\"{feature_word_1}\" and \"{feature_word_2}\" similarity: {cosine_similarity(wordvec[feature_word_1], wordvec[feature_word_2]):.4f}')\n",
    "    print(\"\")\n",
    "    v = np.array(wordvec[obj_word_1]) - np.array(wordvec[feature_word_1]) + np.array(wordvec[feature_word_2])\n",
    "\n",
    "    print(f'New vector and \"{obj_word_1}\" similarity: {cosine_similarity(v, wordvec[obj_word_1]):.4f}')\n",
    "    print(f'New vector and \"{feature_word_1}\" similarity: {cosine_similarity(v, wordvec[feature_word_1]):.4f}')\n",
    "    print(f'New vector and \"{feature_word_2}\" similarity: {cosine_similarity(v, wordvec[feature_word_2]):.4f}')\n",
    "    print(f'New vector and \"{obj_word_2}\" similarity: {cosine_similarity(v, wordvec[obj_word_2]):.4f}')\n",
    "    print(\"\\n\")\n",
    "\n",
    "try_wordvec_arthimetic(wordvec)\n",
    "try_wordvec_arthimetic(wordvec, 'paris', 'rome', 'france', 'italy')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(t['king'], t['queen'])=0.9154539883981325\n",
      "cosine_similarity(t['king'], t['man'])=0.8138182688759626\n",
      "cosine_similarity(t['queen'], t['man'])=0.8259629343785966\n",
      "cosine_similarity(t['queen'], t['woman'])=0.8798956693397046\n",
      "cosine_similarity(t['man'], t['woman'])=0.9029889578791404\n",
      "\n",
      "cosine_similarity(v, t['king'])=0.9156055782123844\n",
      "cosine_similarity(v, t['man'])=0.6543302273978167\n",
      "cosine_similarity(v, t['woman'])=0.8342070103171549\n",
      "cosine_similarity(v, t['queen'])=0.8848948703426839\n"
     ]
    }
   ],
   "source": [
    "from typing import Mapping\n",
    "\n",
    "Word2Vec = Mapping[str, list]\n",
    "\n",
    "def try_wordvec_arthimetic(t: Mapping):\n",
    "    from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "    def cosine_similarity(vec1, vec2):\n",
    "        return 1 - cosine(vec1, vec2)\n",
    "\n",
    "\n",
    "    print(f\"{cosine_similarity(t['king'], t['queen'])=}\")\n",
    "    print(f\"{cosine_similarity(t['king'], t['man'])=}\")\n",
    "    print(f\"{cosine_similarity(t['queen'], t['man'])=}\")\n",
    "    print(f\"{cosine_similarity(t['queen'], t['woman'])=}\")\n",
    "    print(f\"{cosine_similarity(t['man'], t['woman'])=}\")\n",
    "    print(\"\")\n",
    "    v = np.array(t['king']) - np.array(t['man']) + np.array(t['woman'])\n",
    "\n",
    "    print(f\"{cosine_similarity(v, t['king'])=}\")\n",
    "    print(f\"{cosine_similarity(v, t['man'])=}\")\n",
    "    print(f\"{cosine_similarity(v, t['woman'])=}\")\n",
    "    print(f\"{cosine_similarity(v, t['queen'])=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "def get_default_codecs():\n",
    "    codecs = {}\n",
    "\n",
    "    # Attempt to add gzipped pickle codec\n",
    "    try:\n",
    "        import pickle\n",
    "        import gzip\n",
    "        codecs['gzipped_pickle'] = {\n",
    "            'encoder': lambda f, d: pickle.dump(d, gzip.open(f, 'wb')),\n",
    "            'decoder': lambda f: pickle.load(gzip.open(f, 'rb'))\n",
    "        }\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    # Attempt to add numpy npz codec\n",
    "    try:\n",
    "        import numpy as np\n",
    "        codecs['numpy_npz'] = {\n",
    "            'encoder': lambda f, d: np.savez_compressed(f, d),\n",
    "            'decoder': lambda f: {k: v for k, v in np.load(f).items()}\n",
    "        }\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    # Attempt to add hdf5 codec\n",
    "    # try:\n",
    "    #     import h5py\n",
    "    #     def _hdf5_encode(data, filename):\n",
    "    #         with h5py.File(filename, 'w') as f:\n",
    "    #             for key, values in data.items():\n",
    "    #                 f.create_dataset(key, data=values, compression=\"gzip\")\n",
    "\n",
    "    #     def _hdf5_decode(filename):\n",
    "    #         with h5py.File(filename, 'r') as f:\n",
    "    #             return {key: f[key][()] for key in f.keys()}\n",
    "\n",
    "    #     codecs['hdf5'] = {\n",
    "    #         'encoder': lambda f, d: _hdf5_encode(d, f),\n",
    "    #         'decoder': lambda f: _hdf5_decode(f)\n",
    "    #     }\n",
    "    # except ImportError:\n",
    "    #     pass\n",
    "\n",
    "    # Attempt to add parquet codec\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        codecs['parquet'] = {\n",
    "            'encoder': lambda f, d: pd.DataFrame.from_dict(d, orient='index').transpose().to_parquet(f, compression='gzip'),\n",
    "            'decoder': lambda f: pd.read_parquet(f).to_dict(orient='list')\n",
    "        }\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    return codecs\n",
    "\n",
    "\n",
    "# You can then use this function in your benchmark_storage function\n",
    "# codecs = get_default_codecs()\n",
    "# results = benchmark_storage(data, codecs)\n",
    "\n",
    "\n",
    "def benchmark_storage(data, codecs=None, *, verbose=True):\n",
    "    from lkj import print_progress, clog\n",
    "    from functools import partial\n",
    "\n",
    "    _clog = partial(clog, verbose, log_func=print_progress)\n",
    "\n",
    "    if codecs is None:\n",
    "        codecs = get_default_codecs()\n",
    "\n",
    "    results = {}\n",
    "    for name, codec in codecs.items():\n",
    "        _clog(f'Benchmarking {name}')\n",
    "\n",
    "        filename = f'temp_{name}.data'\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            codec['encoder'](filename, data)\n",
    "            encoding_time = time.time() - start_time\n",
    "\n",
    "            encoded_size = os.path.getsize(filename)\n",
    "\n",
    "            start_time = time.time()\n",
    "            decoded_data = codec['decoder'](filename)\n",
    "            decoding_time = time.time() - start_time\n",
    "\n",
    "            decoded_size = sum([len(v) * 8 for v in decoded_data.values()])  # Assuming float64 (8 bytes per float)\n",
    "\n",
    "            results[name] = {\n",
    "                'decoded_n_bytes': decoded_size,\n",
    "                'encoded_n_bytes': encoded_size,\n",
    "                'encoding_time_in_seconds': encoding_time,\n",
    "                'decoding_time_in_seconds': decoding_time\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "            os.remove(filename)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# data = {\"key1\": [0.1, 0.2, ...], \"key2\": [1.1, 1.2, ...]}\n",
    "# results = benchmark_storage(data)\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gzipped_csv</th>\n",
       "      <th>gzipped_pickle</th>\n",
       "      <th>parquet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decoded_n_bytes</th>\n",
       "      <td>1.310808e+06</td>\n",
       "      <td>1.310808e+06</td>\n",
       "      <td>1.310808e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoded_n_bytes</th>\n",
       "      <td>3.925119e+08</td>\n",
       "      <td>1.761167e+08</td>\n",
       "      <td>2.718476e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoding_time_in_seconds</th>\n",
       "      <td>1.388668e+02</td>\n",
       "      <td>2.779556e+02</td>\n",
       "      <td>3.537151e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoding_time_in_seconds</th>\n",
       "      <td>8.359523e+00</td>\n",
       "      <td>2.618939e+00</td>\n",
       "      <td>5.103618e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           gzipped_csv  gzipped_pickle       parquet\n",
       "decoded_n_bytes           1.310808e+06    1.310808e+06  1.310808e+06\n",
       "encoded_n_bytes           3.925119e+08    1.761167e+08  2.718476e+08\n",
       "encoding_time_in_seconds  1.388668e+02    2.779556e+02  3.537151e+01\n",
       "decoding_time_in_seconds  8.359523e+00    2.618939e+00  5.103618e+00"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# results = benchmark_storage(wordvec)\n",
    "# pd.DataFrame.from_dict(results)\n",
    "\n",
    "# \t                        gzipped_csv\tgzipped_pickle\tparquet\n",
    "# decoded_n_bytes\t            1.310808e+06\t1.310808e+06\t1.310808e+06\n",
    "# encoded_n_bytes\t            3.925119e+08\t1.761167e+08\t2.718476e+08\n",
    "# encoding_time_in_seconds\t1.388668e+02\t2.779556e+02\t3.537151e+01\n",
    "# decoding_time_in_seconds\t8.359523e+00\t2.618939e+00\t5.103618e+00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dol import ValueCodecs, Pipe, Files, KeyTemplate\n",
    "\n",
    "# decoder here will unpickle data and remove remove the .pkl extension from the key\n",
    "src_wrap = Pipe(\n",
    "    KeyTemplate(\n",
    "        'openai_word_embeddings_{from_word:05.0f:\\d+}_{to_word:05.0f:\\d+}.pkl.gz',\n",
    "        from_str_funcs=dict(from_word=int, to_word=int),\n",
    "    ).key_codec(), \n",
    "    ValueCodecs.pickle() + ValueCodecs.gzip()\n",
    ")\n",
    "\n",
    "targ_wrap = Pipe(\n",
    "    KeyTemplate(\n",
    "        'openai_word_embeddings_{from_word:06.0f:\\d+}_{to_word:06.0f:\\d+}.pkl.gz',\n",
    "        from_str_funcs=dict(from_word=int, to_word=int),\n",
    "    ).key_codec(), \n",
    "    ValueCodecs.pickle() + ValueCodecs.gzip()\n",
    ")\n",
    "\n",
    "src = src_wrap(Files('./embeddings'))\n",
    "targ = targ_wrap(Files('./embeddings_2'))\n",
    "k, v = src.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Files(rootdir='./embeddings_2', subpath='', pattern_for_field=None, max_levels=None, include_hidden=False, assert_rootdir_existence=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thorwhalen/Dropbox/py/proj/o/slang/slang/util.py:95: RuntimeWarning: invalid value encountered in cast\n",
      "  snip_of_unichr_code = (nan * ones(unichr_code_of_snip.max() + 1)).astype(int)\n"
     ]
    }
   ],
   "source": [
    "from slang import fixed_step_chunker\n",
    "from functools import partial\n",
    "\n",
    "chk_size = 2500\n",
    "chunker = partial(fixed_step_chunker, chk_size=chk_size)\n",
    "for k in sorted(src):\n",
    "    v = src[k]\n",
    "    start_idx, _ = k\n",
    "    for i, chk in enumerate(chunker(v.items())):\n",
    "        new_start_idx = start_idx + i * chk_size\n",
    "        new_end_idx = new_start_idx + chk_size\n",
    "        targ[new_start_idx, new_end_idx] = dict(chk)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(90000, 100000),\n",
       " (0, 10000),\n",
       " (50000, 60000),\n",
       " (60000, 70000),\n",
       " (70000, 80000),\n",
       " (10000, 20000),\n",
       " (40000, 50000),\n",
       " (30000, 40000),\n",
       " (80000, 90000),\n",
       " (20000, 30000)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "t  = src[0, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Encoding', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_tiktoken', 'core', 'encoding_for_model', 'encoding_name_for_model', 'get_encoding', 'list_encoding_names', 'model', 'registry']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "print(dir(tiktoken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6151, 856, 836, 374, 3276, 1965, 10663, 278]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "num_tokens('hi my name is anticonstitutional')\n",
    "\n",
    "\n",
    "tiktoken.encoding_for_model(GPT_MODEL).encode('hi my name is anticonstitutional')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1820, 387, 311, 315, 323]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken.encoding_for_model(GPT_MODEL).encode('the be to of and')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_core_bpe',\n",
       " '_encode_bytes',\n",
       " '_encode_only_native_bpe',\n",
       " '_encode_single_piece',\n",
       " '_mergeable_ranks',\n",
       " '_pat_str',\n",
       " '_special_tokens',\n",
       " 'decode',\n",
       " 'decode_batch',\n",
       " 'decode_bytes',\n",
       " 'decode_bytes_batch',\n",
       " 'decode_single_token_bytes',\n",
       " 'decode_tokens_bytes',\n",
       " 'decode_with_offsets',\n",
       " 'encode',\n",
       " 'encode_batch',\n",
       " 'encode_ordinary',\n",
       " 'encode_ordinary_batch',\n",
       " 'encode_single_token',\n",
       " 'encode_with_unstable',\n",
       " 'eot_token',\n",
       " 'max_token_value',\n",
       " 'n_vocab',\n",
       " 'name',\n",
       " 'special_tokens_set',\n",
       " 'token_byte_values']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tiktoken.encoding_for_model(GPT_MODEL)\n",
    "dir(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.max_token_value=100276, t.n_vocab=100277\n"
     ]
    }
   ],
   "source": [
    "print(f\"{t.max_token_value=}, {t.n_vocab=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.decode(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as',\n",
       " 'el',\n",
       " 'ct',\n",
       " 'nd',\n",
       " ' in',\n",
       " ' h',\n",
       " 'ent',\n",
       " 'id',\n",
       " ' n',\n",
       " 'am',\n",
       " '           ',\n",
       " ' to',\n",
       " ' re',\n",
       " '--',\n",
       " ' {',\n",
       " ' of',\n",
       " 'om',\n",
       " ');\\n',\n",
       " 'im',\n",
       " '\\r\\n',\n",
       " ' (',\n",
       " 'il',\n",
       " '//',\n",
       " ' and',\n",
       " 'ur',\n",
       " 'se',\n",
       " ' l',\n",
       " 'ex',\n",
       " ' S',\n",
       " 'ad',\n",
       " ' \"',\n",
       " 'ch',\n",
       " 'ut',\n",
       " 'if',\n",
       " '**',\n",
       " ' }',\n",
       " 'em',\n",
       " 'ol',\n",
       " '                ',\n",
       " 'th',\n",
       " ')\\n',\n",
       " ' {\\n',\n",
       " ' g',\n",
       " 'ig',\n",
       " 'iv',\n",
       " ',\\n',\n",
       " 'ce',\n",
       " 'od',\n",
       " ' v',\n",
       " 'ate',\n",
       " ' T',\n",
       " 'ag',\n",
       " 'ay',\n",
       " ' *',\n",
       " 'ot',\n",
       " 'us',\n",
       " ' C',\n",
       " ' st',\n",
       " ' I',\n",
       " 'un',\n",
       " 'ul',\n",
       " 'ue',\n",
       " ' A',\n",
       " 'ow',\n",
       " \" '\",\n",
       " 'ew',\n",
       " ' <',\n",
       " 'ation',\n",
       " '()',\n",
       " ' for',\n",
       " 'ab',\n",
       " 'ort',\n",
       " 'um',\n",
       " 'ame',\n",
       " ' is',\n",
       " 'pe',\n",
       " 'tr',\n",
       " 'ck',\n",
       " '',\n",
       " ' y',\n",
       " 'ist',\n",
       " '----',\n",
       " '.\\n\\n',\n",
       " 'he',\n",
       " ' e',\n",
       " 'lo',\n",
       " ' M',\n",
       " ' be',\n",
       " 'ers',\n",
       " ' on',\n",
       " ' con',\n",
       " 'ap',\n",
       " 'ub',\n",
       " ' P',\n",
       " '               ',\n",
       " 'ass',\n",
       " 'int',\n",
       " '>\\n',\n",
       " 'ly',\n",
       " 'urn']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: t.decode([x]), (range(300, 400))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the be to of and'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.decode([1820, 387, 311, 315, 323])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
